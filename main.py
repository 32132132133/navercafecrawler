#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ë„¤ì´ë²„ ì¹´í˜ í¬ë¡¤ëŸ¬ ë©”ì¸ ì‹¤í–‰ íŒŒì¼
í–¥ìƒëœ ê²€ìƒ‰ ê¸°ëŠ¥ê³¼ ë‚´ìš©/ëŒ“ê¸€ ìˆ˜ì§‘ ì§€ì›

ì‚¬ìš©ë²•:
    python main.py --keyword="í‚¤ì›Œë“œ"
    python main.py --cafe="ì¹´í˜URL" --keyword="í‚¤ì›Œë“œ1,í‚¤ì›Œë“œ2"
    python main.py --help
"""

import sys
import argparse
from cafe_crawler_migrated import CafeCrawlerMigrated as NaverCafeCrawler
from utils import safe_wait
from config import Config
import os

def print_banner():
    """ì‹œì‘ ë°°ë„ˆ ì¶œë ¥"""
    print("=" * 80)
    print("ğŸ”¥ ë„¤ì´ë²„ ì¹´í˜ ê³ ê¸‰ í¬ë¡¤ëŸ¬ v3.0")
    print("   ğŸ“Š 1000ê°œ ê²Œì‹œê¸€ ìˆ˜ì§‘ | ğŸ“ ë‚´ìš© ë¶„ì„ | ğŸ’¬ ëŒ“ê¸€ ìˆ˜ì§‘")
    print("   ğŸ” ë„¤ì´ë²„ ì¹´í˜ ê³ ê¸‰ ê²€ìƒ‰ ê¸°ëŠ¥ ì™„ì „ í™œìš©")
    print("=" * 80)

def print_config_info():
    """í˜„ì¬ ì„¤ì • ì •ë³´ ì¶œë ¥"""
    print(f"ğŸ“‹ í˜„ì¬ í¬ë¡¤ë§ ì„¤ì •:")
    print(f"   ğŸ¯ ìµœëŒ€ ìˆ˜ì§‘ëŸ‰: {Config.MAX_TOTAL_POSTS}ê°œ ê²Œì‹œê¸€")
    print(f"   ğŸ“„ ìµœëŒ€ í˜ì´ì§€: {Config.MAX_PAGES}í˜ì´ì§€")
    print(f"   ğŸ“ ê²Œì‹œê¸€ ë‚´ìš©: {'ìˆ˜ì§‘í•¨' if Config.EXTRACT_FULL_CONTENT else 'ìˆ˜ì§‘ ì•ˆí•¨'}")
    print(f"   ğŸ’¬ ëŒ“ê¸€ ìˆ˜ì§‘: {'ìˆ˜ì§‘í•¨' if Config.EXTRACT_COMMENTS else 'ìˆ˜ì§‘ ì•ˆí•¨'}")
    print(f"   ğŸ–¼ï¸ ì´ë¯¸ì§€ ì •ë³´: {'ìˆ˜ì§‘í•¨' if Config.EXTRACT_IMAGES else 'ìˆ˜ì§‘ ì•ˆí•¨'}")
    print(f"   ğŸ” ê³ ê¸‰ ê²€ìƒ‰: {'í™œì„±í™”' if Config.USE_ADVANCED_SEARCH else 'ë¹„í™œì„±í™”'}")
    print(f"   âš™ï¸ ë¸Œë¼ìš°ì € ëª¨ë“œ: {'ë°±ê·¸ë¼ìš´ë“œ' if Config.HEADLESS else 'í™”ë©´ í‘œì‹œ'}")
    print()

def validate_environment():
    """ì‹¤í–‰ í™˜ê²½ ê²€ì¦"""
    print("ğŸ” ì‹¤í–‰ í™˜ê²½ ê²€ì¦ ì¤‘...")
    
    # í™˜ê²½ë³€ìˆ˜ í™•ì¸
    if not Config.NAVER_ID or not Config.NAVER_PASSWORD:
        print("âš ï¸ ë„¤ì´ë²„ ë¡œê·¸ì¸ ì •ë³´ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("   .env íŒŒì¼ì„ í™•ì¸í•˜ê±°ë‚˜ ìˆ˜ë™ ë¡œê·¸ì¸ì„ ì§„í–‰í•˜ì„¸ìš”.")
        print()
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ í™•ì¸
    if not os.path.exists(Config.OUTPUT_DIR):
        print(f"ğŸ“ ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±: {Config.OUTPUT_DIR}")
        os.makedirs(Config.OUTPUT_DIR, exist_ok=True)
    
    print("âœ… í™˜ê²½ ê²€ì¦ ì™„ë£Œ")
    print()

def parse_arguments():
    """ëª…ë ¹í–‰ ì¸ìˆ˜ íŒŒì‹±"""
    parser = argparse.ArgumentParser(
        description="ë„¤ì´ë²„ ì¹´í˜ ê³ ê¸‰ í¬ë¡¤ëŸ¬ - ë‚´ìš© ë° ëŒ“ê¸€ ìˆ˜ì§‘",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  python main.py --keyword="ê°€ìŠ¤ê³µì‚¬"
  python main.py --keyword="ê°€ìŠ¤ê³µì‚¬,ê³µê¸°ì—…,ì±„ìš©" --max-posts=500
  python main.py --cafe="https://cafe.naver.com/studentstudyhard" --keyword="ì·¨ì—…"
  python main.py --keyword="ê³µë¬´ì›" --no-comments --headless
  
ì£¼ìš” ê¸°ëŠ¥:
  - ë„¤ì´ë²„ ì¹´í˜ ë‚´ì¥ ê²€ìƒ‰ì—”ì§„ í™œìš©
  - ê²Œì‹œê¸€ ì „ì²´ ë‚´ìš© ìˆ˜ì§‘
  - ëŒ“ê¸€ ë° ëŒ€ëŒ“ê¸€ ìˆ˜ì§‘
  - ì´ë¯¸ì§€ ë° ì²¨ë¶€íŒŒì¼ ì •ë³´ ìˆ˜ì§‘
  - ì—‘ì…€ íŒŒì¼ë¡œ ì²´ê³„ì  ì •ë¦¬
  - í†µê³„ ë¶„ì„ ìë™ ìƒì„±
        """
    )
    
    parser.add_argument('--keyword', '-k', 
                       help='ê²€ìƒ‰í•  í‚¤ì›Œë“œ (ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ ì—¬ëŸ¬ ê°œ ê°€ëŠ¥)')
    
    parser.add_argument('--cafe', '-c',
                       default=Config.DEFAULT_CAFE_URL,
                       help=f'ëŒ€ìƒ ì¹´í˜ URL (ê¸°ë³¸ê°’: {Config.DEFAULT_CAFE_URL})')
    
    parser.add_argument('--max-posts', '-m',
                       type=int,
                       default=Config.MAX_TOTAL_POSTS,
                       help=f'ìµœëŒ€ ìˆ˜ì§‘ ê²Œì‹œê¸€ ìˆ˜ (ê¸°ë³¸ê°’: {Config.MAX_TOTAL_POSTS})')
    
    parser.add_argument('--max-pages', '-p',
                       type=int,
                       default=Config.MAX_PAGES,
                       help=f'ìµœëŒ€ íƒìƒ‰ í˜ì´ì§€ ìˆ˜ (ê¸°ë³¸ê°’: {Config.MAX_PAGES})')
    
    parser.add_argument('--no-content',
                       action='store_true',
                       help='ê²Œì‹œê¸€ ë‚´ìš© ìˆ˜ì§‘í•˜ì§€ ì•ŠìŒ')
    
    parser.add_argument('--no-comments',
                       action='store_true',
                       help='ëŒ“ê¸€ ìˆ˜ì§‘í•˜ì§€ ì•ŠìŒ')
    
    parser.add_argument('--with-images',
                       action='store_true',
                       help='ì´ë¯¸ì§€ ì •ë³´ ìˆ˜ì§‘')
    
    parser.add_argument('--headless',
                       action='store_true',
                       help='ë¸Œë¼ìš°ì € ì°½ ìˆ¨ê¹€ ëª¨ë“œ')
    
    parser.add_argument('--output', '-o',
                       help='ì¶œë ¥ íŒŒì¼ëª… (ê¸°ë³¸ê°’: ìë™ ìƒì„±)')
    
    parser.add_argument('--verbose', '-v',
                       action='store_true',
                       help='ìƒì„¸ ë¡œê·¸ ì¶œë ¥')
    
    return parser.parse_args()

def apply_arguments(args):
    """ëª…ë ¹í–‰ ì¸ìˆ˜ë¥¼ ì„¤ì •ì— ì ìš©"""
    
    # ìˆ˜ì§‘ ì„¤ì • ì—…ë°ì´íŠ¸ (setattr ì‚¬ìš©í•˜ì—¬ ì•ˆì „í•˜ê²Œ ë³€ê²½)
    if args.max_posts:
        setattr(Config, 'MAX_TOTAL_POSTS', args.max_posts)
    
    if args.max_pages:
        setattr(Config, 'MAX_PAGES', args.max_pages)
    
    if args.no_content:
        setattr(Config, 'EXTRACT_FULL_CONTENT', False)
        setattr(Config, 'INCLUDE_CONTENT', False)
    
    if args.no_comments:
        setattr(Config, 'EXTRACT_COMMENTS', False)
        setattr(Config, 'INCLUDE_COMMENTS', False)
    
    if args.with_images:
        setattr(Config, 'EXTRACT_IMAGES', True)
    
    if args.headless:
        setattr(Config, 'HEADLESS', True)
    
    if args.verbose:
        setattr(Config, 'VERBOSE_SEARCH_LOGGING', True)

def interactive_keyword_input():
    """í‚¤ì›Œë“œ ëŒ€í™”ì‹ ì…ë ¥"""
    print("ğŸ¯ ê²€ìƒ‰í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    print("   (ì—¬ëŸ¬ í‚¤ì›Œë“œëŠ” ì‰¼í‘œë¡œ êµ¬ë¶„, ì˜ˆ: ê°€ìŠ¤ê³µì‚¬,ê³µê¸°ì—…,ì±„ìš©)")
    print()
    
    while True:
        keyword_input = input("í‚¤ì›Œë“œ: ").strip()
        
        if keyword_input:
            keywords = [k.strip() for k in keyword_input.split(',') if k.strip()]
            if keywords:
                return keywords
        
        print("âŒ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    try:
        # ë°°ë„ˆ ì¶œë ¥
        print_banner()
        
        # í™˜ê²½ ê²€ì¦
        validate_environment()
        
        # ëª…ë ¹í–‰ ì¸ìˆ˜ íŒŒì‹±
        args = parse_arguments()
        
        # ì„¤ì • ì ìš©
        apply_arguments(args)
        
        # ì„¤ì • ì •ë³´ ì¶œë ¥
        print_config_info()
        
        # í‚¤ì›Œë“œ ì²˜ë¦¬
        keywords = None
        if args.keyword:
            keywords = [k.strip() for k in args.keyword.split(',') if k.strip()]
            print(f"ğŸ¯ ê²€ìƒ‰ í‚¤ì›Œë“œ: {', '.join(keywords)}")
        else:
            keywords = interactive_keyword_input()
            print(f"ğŸ¯ ì…ë ¥ëœ í‚¤ì›Œë“œ: {', '.join(keywords)}")
        
        print(f"ğŸ“ ëŒ€ìƒ ì¹´í˜: {args.cafe}")
        print()
    
        # í¬ë¡¤ëŸ¬ ì´ˆê¸°í™” ë° ì‹¤í–‰
        crawler = NaverCafeCrawler()
        
        print("ğŸš€ í¬ë¡¤ë§ ì‹œì‘...")
        print("   (ë¡œê·¸ì¸ì´ í•„ìš”í•œ ê²½ìš° ë¸Œë¼ìš°ì €ì—ì„œ ìˆ˜ë™ìœ¼ë¡œ ì§„í–‰í•˜ì„¸ìš”)")
        print()
        
        # ë“œë¼ì´ë²„ ì„¤ì •
        if not crawler.setup_driver():
            print("âŒ ë¸Œë¼ìš°ì € ì´ˆê¸°í™” ì‹¤íŒ¨")
            return False
        
        # ë¡œê·¸ì¸ ì‹œë„
        if Config.NAVER_ID and Config.NAVER_PASSWORD:
            print("ğŸ” ìë™ ë¡œê·¸ì¸ ì‹œë„ ì¤‘...")
            if not crawler.login_naver():
                print("âš ï¸ ìë™ ë¡œê·¸ì¸ ì‹¤íŒ¨ - ìˆ˜ë™ ë¡œê·¸ì¸ ì§„í–‰")
                input("ë¸Œë¼ìš°ì €ì—ì„œ ë¡œê·¸ì¸ ì™„ë£Œ í›„ Enterë¥¼ ëˆŒëŸ¬ì£¼ì„¸ìš”...")
        else:
            print("ğŸ” ìˆ˜ë™ ë¡œê·¸ì¸ ëª¨ë“œ")
            input("ë¸Œë¼ìš°ì €ì—ì„œ ë„¤ì´ë²„ ë¡œê·¸ì¸ ì™„ë£Œ í›„ Enterë¥¼ ëˆŒëŸ¬ì£¼ì„¸ìš”...")
        
        # í¬ë¡¤ë§ ì‹¤í–‰
        all_posts = crawler.crawl_cafe(args.cafe, keywords)  # type: ignore
        
        if all_posts:
            print(f"\nğŸ‰ í¬ë¡¤ë§ ì„±ê³µ!")
            print(f"   ğŸ“Š ì´ ìˆ˜ì§‘ ê²Œì‹œê¸€: {len(all_posts)}ê°œ")
            
            # ë°ì´í„° ì €ì¥
            crawler.posts_data = all_posts  # í¬ë¡¤ëŸ¬ì— ë°ì´í„° ì„¤ì • (ê¸°ì¡´ ìœ ì§€)

            from exporter import CafeDataExporter
            output_file = args.output
            saved_file = CafeDataExporter.save_all(all_posts, output_file)
            
            if saved_file and isinstance(saved_file, str):
                print(f"\nğŸ’¾ ë°ì´í„° ì €ì¥ ì™„ë£Œ!")
                print(f"   ğŸ“ íŒŒì¼ ìœ„ì¹˜: {saved_file}")
                print(f"   ğŸ“Š í¬í•¨ëœ ë°ì´í„°:")
                print(f"      - ê²Œì‹œê¸€ ì •ë³´: {len(all_posts)}ê°œ")
                print(f"      - ëŒ“ê¸€ ì •ë³´: {sum(len(post.get('comments', [])) for post in all_posts)}ê°œ")
                print(f"      - ì´ë¯¸ì§€ ì •ë³´: {sum(len(post.get('images', [])) for post in all_posts)}ê°œ")
                print(f"      - í†µê³„ ë¶„ì„: ìë™ ìƒì„±")
                
                # íŒŒì¼ íƒìƒ‰ê¸°ì—ì„œ ì—´ê¸° (Windows)
                if sys.platform == "win32":
                    print(f"\nğŸ“‚ íŒŒì¼ íƒìƒ‰ê¸°ì—ì„œ ê²°ê³¼ í™•ì¸:")
                    print(f"   explorer {os.path.dirname(saved_file)}")
        
                    # ìë™ìœ¼ë¡œ í´ë” ì—´ê¸° (ì„ íƒì‚¬í•­)
                    try:
                        import subprocess
                        subprocess.run(['explorer', os.path.dirname(saved_file)])
                    except:
                        pass
            else:
                print("âŒ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨")
        else:
            print(f"\nâš ï¸ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            print(f"   - í‚¤ì›Œë“œë¥¼ ë‹¤ì‹œ í™•ì¸í•´ë³´ì„¸ìš”: {', '.join(keywords)}")
            print(f"   - ì¹´í˜ URLì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•´ë³´ì„¸ìš”: {args.cafe}")
            print(f"   - ë¡œê·¸ì¸ ìƒíƒœë¥¼ í™•ì¸í•´ë³´ì„¸ìš”.")
        
        return True
        
    except KeyboardInterrupt:
        print(f"\nâš ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return False
            
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        if args.verbose if 'args' in locals() else False:
            import traceback
            traceback.print_exc()
        return False
        
    finally:
        # ë¸Œë¼ìš°ì € ì •ë¦¬
        try:
            if 'crawler' in locals() and crawler.driver:
                print("\nğŸ§¹ ë¸Œë¼ìš°ì € ì •ë¦¬ ì¤‘...")
                crawler.driver.quit()
        except:
            pass

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1) 