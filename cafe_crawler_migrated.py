"""
ë„¤ì´ë²„ ì¹´í˜ í¬ë¡¤ëŸ¬ - ì ì§„ì  ë§ˆì´ê·¸ë ˆì´ì…˜ ë²„ì „
ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ë¥¼ 100% í˜¸í™˜í•˜ë©´ì„œ ìƒˆë¡œìš´ ëª¨ë“ˆí™”ëœ êµ¬ì¡°ë¥¼ ì‚¬ìš©
"""
# Disclaimer: use at your own risk. The authors take no responsibility for misuse.

import time
import re
from typing import Optional, List, Dict, Any, Tuple
import os
import pandas as pd
from datetime import datetime
import random

# ê¸°ì¡´ imports ?ï¿½ï¿½?
from config import Config
from utils import clean_text, safe_wait, get_timestamp, print_progress, extract_post_number
from exporter import CafeDataExporter

# ?ï¿½ë¡œ??ëª¨ë“ˆ??import
try:
    from core.exceptions import (
        CrawlerException, DriverNotInitializedException,
        LoginFailedException, NavigationFailedException,
        ExtractionFailedException, SearchFailedException
    )
    from core.driver_manager import DriverManager
    from core.auth_manager import AuthManager
    from utils.constants import (
        DEFAULT_WINDOW_SIZE, DEFAULT_TIMEOUT, NAVER_LOGIN_URL,
        POST_SELECTORS, TITLE_SELECTORS, AUTHOR_SELECTORS
    )
    NEW_MODULES_AVAILABLE = True
except ImportError as e:
    print(f"?ï¿½ï¸ ?ï¿½ë¡œ??ëª¨ë“ˆ??ì°¾ì„ ???ï¿½ìŠµ?ï¿½ë‹¤: {e}")
    print("ê¸°ì¡´ ëª¨ë“ˆï¿½??ï¿½ìš©?ï¿½ì—¬ ?ï¿½ì‘?ï¿½ë‹ˆ??")
    NEW_MODULES_AVAILABLE = False

    # ê¸°ì¡´ selenium imports
    from selenium import webdriver
    from selenium.webdriver.common.by import By
    from selenium.webdriver.support.wait import WebDriverWait
    from selenium.webdriver.support import expected_conditions as EC
    from selenium.common.exceptions import TimeoutException, NoSuchElementException


class CafeCrawlerMigrated:
    """
    ?ï¿½ì§„??ë§ˆì´ê·¸ë ˆ?ï¿½ì…˜??ì¹´í˜ ?ï¿½ë¡¤??    - ê¸°ì¡´ ?ï¿½í„°?ï¿½ì´??100% ?ï¿½í™˜
    - ?ï¿½ë¡œ??ëª¨ë“ˆ???ï¿½ìœ¼ï¿½??ï¿½ìš©, ?ï¿½ìœ¼ï¿½?ê¸°ì¡´ ë°©ì‹?ï¿½ë¡œ fallback
    - ?ï¿½ì „?ï¿½ê³¼ ?ï¿½ï¿½?ë³´ìˆ˜???ï¿½ìƒ
    """

    def __init__(self):
        """í¬ë¡¤ëŸ¬ ì´ˆê¸°í™” - ê¸°ì¡´ê³¼ ë™ì¼í•œ ì¸í„°í˜ì´ìŠ¤"""
        # ê¸°ì¡´ ?ï¿½í™˜?ï¿½ì„ ?ï¿½í•œ ?ï¿½ì„±??        self.driver: Optional[Any] = None
        self.posts_data = []
        self.current_cafe_url = ""
        self.search_results = []

        if NEW_MODULES_AVAILABLE:
            # ?ï¿½ë¡œ??ëª¨ë“ˆ ë§¤ë‹ˆ?ï¿½??            self._driver_manager: Optional[DriverManager] = None
            self._auth_manager: Optional[AuthManager] = None

        # ?ï¿½ï¿½? ?ï¿½íƒœ ê´€ï¿½?        self._is_logged_in = False
        self._current_cafe_id = None
        self._cafe_metadata = {}

        print("??CafeCrawler (Migration Version) ì´ˆê¸°???ï¿½ë£Œ")

    def setup_driver(self):
        """Driver setup - maintains existing interface, improves internal implementation"""
        try:
            if NEW_MODULES_AVAILABLE:
                # ìƒˆë¡œìš´ ë“œë¼ì´ë²„ ë§¤ë‹ˆì € ì‚¬ìš©
                self._driver_manager = DriverManager()
                if self._driver_manager.create_driver():
                    self.driver = self._driver_manager.driver
                self._auth_manager = AuthManager(self._driver_manager)
            else:
                # ê¸°ì¡´ ë°©ì‹ fallback
                from driver import create_driver
                self.driver = create_driver()

            print("âœ… ë“œë¼ì´ë²„ ì„¤ì • ì™„ë£Œ")
            return True

        except Exception as e:
            print(f"âŒ ë“œë¼ì´ë²„ ì„¤ì • ì‹¤íŒ¨: {e}")
            if NEW_MODULES_AVAILABLE:
                raise DriverNotInitializedException(f"ë“œë¼ì´ë²„ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            else:
                raise Exception(f"ë“œë¼ì´ë²„ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

    def login_naver(self):
        """ë„¤ì´ë²„ ë¡œê·¸ì¸ - í–¥ìƒëœ ì•ˆì „ì„±"""
        try:
            if not self.driver:
                self.setup_driver()

            print("ğŸ” ë„¤ì´ë²„ ë¡œê·¸ì¸ì„ ì§„í–‰í•©ë‹ˆë‹¤...")

            if NEW_MODULES_AVAILABLE and self._auth_manager:
                # ìƒˆë¡œìš´ ì¸ì¦ ë§¤ë‹ˆì € ì‚¬ìš©
                login_success = self._auth_manager.login_naver()

                if login_success:
                    self._is_logged_in = True
                    print("??ë¡œê·¸???ï¿½ê³µ")
                    return True
                else:
                    raise LoginFailedException("ë¡œê·¸???ï¿½íŒ¨")
            else:
                # ê¸°ì¡´ ë°©ì‹ fallback
                return self._legacy_login()

        except Exception as e:
            print(f"??ë¡œê·¸???ï¿½íŒ¨: {e}")
            return False

    def _legacy_login(self):
        """ê¸°ì¡´ ë¡œê·¸??ë°©ì‹ (fallback)"""
        try:
            # ?ï¿½ì´ï¿½?ë¡œê·¸???ï¿½ì´ì§€ï¿½??ï¿½ë™
            self.driver.get("https://nid.naver.com/nidlogin.login")

            print("?ï¿½ï¿½ ?ï¿½ë™ ë¡œê·¸?ï¿½ì„ ì§„í–‰?ï¿½ì£¼?ï¿½ìš”...")
            print("ë¡œê·¸???ï¿½ë£Œ ???ï¿½ë¬´ ?ï¿½ë‚˜ ?ï¿½ë¥´?ï¿½ìš”...")
            input()

            # ë¡œê·¸???ï¿½ê³µ ?ï¿½ì¸
            current_url = self.driver.current_url
            if "naver.com" in current_url and "login" not in current_url:
                self._is_logged_in = True
                print("??ë¡œê·¸???ï¿½ê³µ")
                return True
            else:
                print("??ë¡œê·¸???ï¿½íŒ¨")
                return False

        except Exception as e:
            print(f"??ê¸°ì¡´ ë¡œê·¸??ë°©ì‹ ?ï¿½íŒ¨: {e}")
            return False

    def navigate_to_cafe(self, cafe_url: str):
        """ì¹´í˜ ì´ë™ - í–¥ìƒëœ ì•ˆì „ì„±ê³¼ êµ¬ì¡° ë¶„ì„"""
        try:
            if not self.driver:
                if NEW_MODULES_AVAILABLE:
                    raise DriverNotInitializedException("ë“œë¼ì´ë²„ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
                else:
                    raise Exception("ë“œë¼ì´ë²„ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

            print(f"?ï¿½ï¿½ ì¹´í˜ï¿½??ï¿½ë™ ï¿½? {cafe_url}")

            # ?ï¿½ì „???ï¿½ì´ì§€ ?ï¿½ë™
            if NEW_MODULES_AVAILABLE and self._driver_manager:
                self._driver_manager.driver.get(cafe_url)
            else:
                self.driver.get(cafe_url)

            self.current_cafe_url = cafe_url
            safe_wait(self.driver, 3)

            # ì¹´í˜ êµ¬ì¡° ë¶„ì„
            self._analyze_cafe_structure()

            print("??ì¹´í˜ ?ï¿½ë™ ?ï¿½ë£Œ")
            return True

        except Exception as e:
            print(f"??ì¹´í˜ ?ï¿½ë™ ?ï¿½íŒ¨: {e}")
            if NEW_MODULES_AVAILABLE:
                raise NavigationFailedException(f"ì¹´í˜ ?ï¿½ë™ ?ï¿½íŒ¨: {e}")
            else:
                raise Exception(f"ì¹´í˜ ?ï¿½ë™ ?ï¿½íŒ¨: {e}")

    def search_posts(self, keyword: str, max_pages: int = 5) -> List[Dict]:
        """ê²Œì‹œê¸€ ê²€ìƒ‰ - í–¥ìƒëœ ê²€ìƒ‰ ì „ëµ"""
        try:
            if not self.driver:
                if NEW_MODULES_AVAILABLE:
                    raise DriverNotInitializedException("ë“œë¼ì´ë²„ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
                else:
                    raise Exception("ë“œë¼ì´ë²„ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

            print(f"?ï¿½ï¿½ ?ï¿½ì›Œ??'{keyword}' ê²€???ï¿½ì‘ (ìµœï¿½? {max_pages}?ï¿½ì´ì§€)")

            # ê²€???ï¿½ëµ ?ï¿½íƒ
            if NEW_MODULES_AVAILABLE:
                search_results = self._perform_enhanced_search(keyword, max_pages)
                self.search_results = self._convert_to_legacy_format(search_results)
            else:
                self.search_results = self._legacy_search(keyword, max_pages)

            print(f"??ê²€???ï¿½ë£Œ: {len(self.search_results)}ï¿½?ê²Œì‹œê¸€ ë°œê²¬")
            return self.search_results

        except Exception as e:
            print(f"??ê²€???ï¿½íŒ¨: {e}")
            if NEW_MODULES_AVAILABLE:
                raise SearchFailedException(f"ê²€???ï¿½íŒ¨: {e}")
            else:
                raise Exception(f"ê²€???ï¿½íŒ¨: {e}")

    def _legacy_search(self, keyword: str, max_pages: int) -> List[Dict]:
        """ê¸°ì¡´ ê²€??ë°©ì‹ (fallback)"""
        try:
            search_results = []

            # ê¸°ë³¸?ï¿½ì¸ ê²€???ï¿½ë„
            search_strategies = [
                self._try_cafe_search_function,
                self._try_direct_search_url,
                self._try_basic_navigation
            ]

            for strategy in search_strategies:
                try:
                    results = strategy(keyword, max_pages)
                    if results:
                        search_results.extend(results)
                        break
                except Exception as e:
                    print(f"  ?ï¿½ï¸ ê²€???ï¿½ëµ ?ï¿½íŒ¨: {e}")
                    continue

            return search_results

        except Exception as e:
            print(f"??ê¸°ì¡´ ê²€??ë°©ì‹ ?ï¿½íŒ¨: {e}")
            return []

    def _try_cafe_search_function(self, keyword: str, max_pages: int) -> List[Dict]:
        """ì¹´í˜ ê³ ì¥ ê²€ìƒ‰ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
        try:
            # ê²€?ï¿½ì°½ ì°¾ê¸°
            search_selectors = [
                "input[placeholder*='ê²€??]",
                "input[name*='search']",
                ".search-input input",
                "#cafe-search input"
            ]

            search_input = None
            for selector in search_selectors:
                try:
                    search_input = self.driver.find_element(By.CSS_SELECTOR, selector)
                    if search_input.is_displayed():
                        break
                except:
                    continue

            if search_input:
                search_input.clear()
                search_input.send_keys(keyword)

                # ê²€??ë²„íŠ¼ ?ï¿½ë¦­
                search_button_selectors = [
                    "button[type='submit']",
                    ".search-btn",
                    ".btn-search",
                    "input[type='submit']"
                ]

                for selector in search_button_selectors:
                    try:
                        button = self.driver.find_element(By.CSS_SELECTOR, selector)
                        if button.is_displayed():
                            button.click()
                            break
                    except:
                        continue

                safe_wait(self.driver, 3)
                return self._extract_search_results(max_pages)

            return []

        except Exception as e:
            print(f"??ì¹´í˜ ê²€??ê¸°ëŠ¥ ?ï¿½íŒ¨: {e}")
            return []

    def _try_direct_search_url(self, keyword: str, max_pages: int) -> List[Dict]:
        """ì§ì ‘ ê²€ìƒ‰ URL êµ¬ì„± ì‹œë„"""
        try:
            if self._current_cafe_id:
                search_url = f"https://cafe.naver.com/ArticleSearchList.nhn?search.clubid={self._current_cafe_id}&search.searchBy=0&search.query={keyword}"
                self.driver.get(search_url)
                safe_wait(self.driver, 3)
                return self._extract_search_results(max_pages)

            return []

        except Exception as e:
            print(f"??ì§ì ‘ URL ê²€???ï¿½íŒ¨: {e}")
            return []

    def _try_basic_navigation(self, keyword: str, max_pages: int) -> List[Dict]:
        """ê¸°ë³¸ ë„¤ë¹„ê²Œì´ì…˜ ì‹œë„"""
        try:
            # ê¸°ë³¸?ï¿½ì¸ ê²Œì‹œê¸€ ëª©ë¡?ï¿½ì„œ ?ï¿½ì›Œ??ë§¤ì¹­
            post_results = []

            # ê²Œì‹œê¸€ ë§í¬??ì°¾ê¸°
            post_selectors = [
                "a[href*='ArticleRead']",
                ".article-board a",
                ".board-list a",
                "a[href*='/article/']"
            ]

            for selector in post_selectors:
                try:
                    post_links = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    for link in post_links[:20]:  # ìµœï¿½? 20ê°œë§Œ ì²´í¬
                        try:
                            title = clean_text(link.text or link.get_attribute("title") or "")
                            if keyword.lower() in title.lower():
                                post_data = {
                                    'title': title,
                                    'url': link.get_attribute("href"),
                                    'author': '',
                                    'date': '',
                                    'views': 0,
                                    'likes': 0,
                                    'content': ''
                                }
                                post_results.append(post_data)
                        except:
                            continue

                    if post_results:
                        break

                except:
                    continue

            return post_results

        except Exception as e:
            print(f"??ê¸°ë³¸ ?ï¿½ë¹„ê²Œì´???ï¿½íŒ¨: {e}")
            return []

    def _extract_search_results(self, max_pages: int) -> List[Dict]:
        """ê²€??ê²°ê³¼ ì¶”ì¶œ"""
        try:
            results = []

            for page in range(max_pages):
                print(f"  ?ï¿½ï¿½ {page + 1}/{max_pages} ?ï¿½ì´ì§€ ì²˜ë¦¬ ï¿½?..")

                # ?ï¿½ì¬ ?ï¿½ì´ì§€??ê²Œì‹œê¸€ ì¶”ì¶œ
                page_results = self._extract_posts_from_current_page()
                results.extend(page_results)

                # ?ï¿½ìŒ ?ï¿½ì´ì§€ï¿½??ï¿½ë™
                if page < max_pages - 1:
                    if not self._go_to_next_page():
                        print("  ?ï¿½ï¸ ???ï¿½ìƒ ?ï¿½ì´ì§€ê°€ ?ï¿½ìŠµ?ï¿½ë‹¤")
                        break

                safe_wait(self.driver, 2)

            return results

        except Exception as e:
            print(f"??ê²€??ê²°ê³¼ ì¶”ì¶œ ?ï¿½íŒ¨: {e}")
            return []

    def _extract_posts_from_current_page(self) -> List[Dict]:
        """í˜„ì¬ í˜ì´ì§€ì—ì„œ ê²Œì‹œê¸€ ì¶”ì¶œ"""
        try:
            posts = []

            # ê²Œì‹œê¸€ ?ï¿½ì†Œ??ì°¾ê¸°
            post_selectors = [
                ".article-board tr",
                ".board-list tr",
                ".list-item",
                ".post-item"
            ]

            for selector in post_selectors:
                try:
                    post_elements = self.driver.find_elements(By.CSS_SELECTOR, selector)

                    for element in post_elements:
                        try:
                            post_data = self._extract_single_post_data(element)
                            if post_data and post_data.get('title'):
                                posts.append(post_data)
                        except:
                            continue

                    if posts:
                        break

                except:
                    continue

            return posts

        except Exception as e:
            print(f"???ï¿½ì´ì§€ ê²Œì‹œê¸€ ì¶”ì¶œ ?ï¿½íŒ¨: {e}")
            return []

    def _extract_single_post_data(self, element) -> Optional[Dict]:
        """ë‹¨ì¼ ê²Œì‹œê¸€ ë°ì´í„° ì¶”ì¶œ"""
        try:
            post_data = {
                'title': '',
                'url': '',
                'author': '',
                'date': '',
                'views': 0,
                'likes': 0,
                'content': ''
            }

            # ?ï¿½ëª©ï¿½?URL ì¶”ì¶œ
            title_selectors = ["a[href*='Article']", ".title a", "a.article", "td a"]
            for selector in title_selectors:
                try:
                    title_element = element.find_element(By.CSS_SELECTOR, selector)
                    post_data['title'] = clean_text(title_element.text)
                    post_data['url'] = title_element.get_attribute("href")
                    break
                except:
                    continue

            # ?ï¿½ì„±??ì¶”ì¶œ
            author_selectors = [".author", ".writer", ".name", "td:nth-child(3)"]
            for selector in author_selectors:
                try:
                    author_element = element.find_element(By.CSS_SELECTOR, selector)
                    post_data['author'] = clean_text(author_element.text)
                    break
                except:
                    continue

            # ?ï¿½ì§œ ì¶”ì¶œ
            date_selectors = [".date", ".time", "td:nth-child(4)"]
            for selector in date_selectors:
                try:
                    date_element = element.find_element(By.CSS_SELECTOR, selector)
                    post_data['date'] = clean_text(date_element.text)
                    break
                except:
                    continue

            return post_data if post_data['title'] else None

        except Exception as e:
            return None

    def _go_to_next_page(self) -> bool:
        """ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™"""
        try:
            # ë‹¤ì–‘í•œ "ë‹¤ìŒ í˜ì´ì§€" íŒ¨í„´ë“¤
            next_patterns = [
                # ?ï¿½ë°˜?ï¿½ì¸ ?ï¿½í„´
                ".next", ".page-next", ".btn-next",
                "a[title*='?ï¿½ìŒ']", "a[title*='next']",

                # ?ï¿½ìŠ¤??ê¸°ë°˜
                "//a[contains(text(), '?ï¿½ìŒ')]",
                "//a[contains(text(), 'next')]",
                "//a[contains(text(), '>')]",

                # ?ï¿½ì´ì§€ ë²ˆí˜¸ ê¸°ë°˜ (?ï¿½ì¬ ?ï¿½ì´ì§€ + 1)
                ".pagination a", ".paging a", ".page-link"
            ]

            # 1. ì§ì ‘?ï¿½ì¸ "?ï¿½ìŒ" ë²„íŠ¼ ì°¾ê¸°
            for pattern in next_patterns[:5]:  # ì²˜ìŒ 5ï¿½??ï¿½í„´ï¿½??ï¿½ë„
                try:
                    if pattern.startswith("//"):
                        elements = self.driver.find_elements(By.XPATH, pattern)
                    else:
                        elements = self.driver.find_elements(By.CSS_SELECTOR, pattern)

                    for element in elements:
                        if element.is_displayed() and element.is_enabled():
                            # ?ï¿½ë¦­ ê°€?ï¿½í•œì§€ ?ï¿½ì¸
                            if 'disabled' not in element.get_attribute('class').lower():
                                element.click()
                                print(f"        ?ï¿½ï¸ ?ï¿½ìŒ ?ï¿½ì´ì§€ ?ï¿½ë™ ?ï¿½ê³µ: {pattern}")
                                self.safe_wait(self.driver, 2)
                                return True
                except:
                    continue

            # 2. ?ï¿½ì´ì§€ ë²ˆí˜¸ï¿½??ï¿½ë™ ?ï¿½ë„
            try:
                # ?ï¿½ì¬ ?ï¿½ì„± ?ï¿½ì´ì§€ ì°¾ê¸°
                active_selectors = [
                    ".current", ".active", ".selected",
                    ".page-current", ".page-active"
                ]

                current_page = None
                for selector in active_selectors:
                    try:
                        element = self.driver.find_element(By.CSS_SELECTOR, selector)
                        current_page = int(element.text)
                        break
                    except:
                        continue

                if current_page:
                    # ?ï¿½ìŒ ?ï¿½ì´ì§€ ë²ˆí˜¸ ?ï¿½ë¦­ ?ï¿½ë„
                    next_page = current_page + 1
                    page_selectors = [
                        f"a[href*='page={next_page}']",
                        f"//a[text()='{next_page}']",
                        f".pagination a:contains('{next_page}')"
                    ]

                    for selector in page_selectors:
                        try:
                            if selector.startswith("//"):
                                element = self.driver.find_element(By.XPATH, selector)
                            else:
                                element = self.driver.find_element(By.CSS_SELECTOR, selector)

                            if element.is_displayed():
                                element.click()
                                print(f"        ?ï¿½ï¸ ?ï¿½ì´ì§€ {next_page}ï¿½??ï¿½ë™ ?ï¿½ê³µ")
                                self.safe_wait(self.driver, 2)
                                return True
                        except:
                            pass
            except:
                pass

            print("        ?ï¿½ï¸ ?ï¿½ìŒ ?ï¿½ì´ì§€ï¿½?ì°¾ì„ ???ï¿½ìŒ")
            return False

        except Exception as e:
            print(f"        ???ï¿½ìŒ ?ï¿½ì´ì§€ ?ï¿½ë™ ?ï¿½ë¥˜: {e}")
            return False

    def get_post_content(self, post_url):
        """ê²Œì‹œê¸€ ì„¸ë¶€ ë‚´ìš© ë° ëŒ“ê¸€ ì¶”ì¶œ (í–¥ìƒëœ ë²„ì „)"""
        if not post_url or 'cafe.naver.com' not in post_url or not self.driver:
            return {"content": "", "comments": []}

        try:
            print(f"      ?ï¿½ï¿½ ê²Œì‹œê¸€ ?ï¿½ìš© ?ï¿½ì§‘: {post_url[:60]}...")

            # ?ï¿½ì¬ ?ï¿½ë ˆ???ï¿½íƒœ ?ï¿½??            current_frame = None
            try:
                current_frame = self.driver.current_frame
            except:
                pass

            # ê²Œì‹œê¸€ ?ï¿½ì´ì§€ï¿½??ï¿½ë™
            self.driver.get(post_url)
            self.safe_wait(self.driver, 2)

            # iframe ì²˜ë¦¬ (ê²Œì‹œê¸€ ?ï¿½ì„¸ ?ï¿½ì´ì§€??iframe êµ¬ì¡°?????ï¿½ìŒ)
            self.handle_post_detail_iframe()

            # ê²Œì‹œê¸€ ?ï¿½ìš© ì¶”ì¶œ
            content = self.extract_post_content()

            # ?ï¿½ï¿½? ì¶”ì¶œ (?ï¿½ì •???ï¿½ë¼)
            comments = []
            extract_comments = getattr(Config, 'EXTRACT_COMMENTS', True)
            include_comments = getattr(Config, 'INCLUDE_COMMENTS', True)
            if extract_comments and include_comments:
                comments = self.extract_comments()

            print(f"        ğŸ“„ ë‚´ìš©: {len(content)}ì, ëŒ“ê¸€: {len(comments)}ê°œ")

            extract_images = getattr(Config, 'EXTRACT_IMAGES', False)
            extract_attachments = getattr(Config, 'EXTRACT_ATTACHMENTS', False)

            return {
                "content": content,
                "comments": comments,
                "images": self.extract_images() if extract_images else [],
                "attachments": self.extract_attachments() if extract_attachments else []
            }

        except Exception as e:
            print(f"        ??ê²Œì‹œê¸€ ?ï¿½ìš© ?ï¿½ì§‘ ?ï¿½ë¥˜: {e}")
            return {"content": "", "comments": []}

        finally:
            # ?ï¿½ë˜ ?ï¿½ë ˆ?ï¿½ìœ¼ï¿½?ë³µï¿½? ?ï¿½ë„
            try:
                if current_frame and self.driver:
                    self.driver.switch_to.frame(current_frame)
                elif self.driver:
                    self.driver.switch_to.default_content()
            except:
                pass

    def handle_post_detail_iframe(self):
        """ê²Œì‹œê¸€ ì„¸ë¶€ í˜ì´ì§€ì˜ iframe ì²˜ë¦¬"""
        if not self.driver:
            return False

        try:
            current_url = self.driver.current_url

            if 'iframe_url=' in current_url or 'ArticleRead' in current_url:
                # iframe ì°¾ê¸° ï¿½??ï¿½í™˜
                iframe_selectors = [
                    '#cafe_main',
                    'iframe[name="cafe_main"]',
                    'iframe[src*="ArticleRead"]',
                    'iframe[src*="read"]',
                    'iframe'
                ]

                for selector in iframe_selectors:
                    try:
                        iframes = self.driver.find_elements(By.CSS_SELECTOR, selector)
                        for iframe in iframes:
                            if iframe.is_displayed():
                                self.driver.switch_to.frame(iframe)
                                self.safe_wait(self.driver, 1)

                                # iframe ?ï¿½ìš© ?ï¿½ì¸
                                if self.verify_post_detail_page():
                                    return True
                                else:
                                    self.driver.switch_to.default_content()
                    except:
                        pass

            return False

        except Exception as e:
            return False

    def verify_post_detail_page(self):
        """ê²Œì‹œê¸€ ?ï¿½ì„¸ ?ï¿½ì´ì§€?ï¿½ï¿½? ?ï¿½ì¸"""
        if not self.driver:
            return False

        try:
            # ê²Œì‹œê¸€ ?ï¿½ì„¸ ?ï¿½ì´ì§€ ì§€?ï¿½ë“¤
            indicators = [
                '.se-main-container',  # ?ï¿½ë§ˆ?ï¿½ì—?ï¿½í„°
                '.article_container',
                '.post-content',
                '.se-component',
                'div[class*="article"]',
                'div[class*="post"]'
            ]

            for indicator in indicators:
                if self.driver.find_elements(By.CSS_SELECTOR, indicator):
                    return True

            # ?ï¿½ìŠ¤??ê¸°ë°˜ ?ï¿½ì¸
            page_source = self.driver.page_source
            if any(text in page_source for text in ['ê²Œì‹œê¸€', 'ì‘ì„±ì', 'ëŒ“ê¸€', 'ì¶”ì²œ']):
                return True

            return False

        except:
            return False

    def extract_post_content(self):
        """ê²Œì‹œê¸€ ë³¸ë¬¸ ?ï¿½ìš© ì¶”ì¶œ"""
        if not self.driver:
            return ""

        try:
            content_selectors = [
                # ?ï¿½ì´ï¿½?ì¹´í˜ ?ï¿½ë§ˆ?ï¿½ì—?ï¿½í„° ?ï¿½í„´??                '.se-main-container .se-component .se-text',
                '.se-main-container',
                '.article_container .article_viewer',
                '.post-content',
                '.se-component',

                # ?ï¿½ë°˜?ï¿½ì¸ ê²Œì‹œê¸€ ?ï¿½ìš© ?ï¿½í„´??                '.article-content',
                '.post_content',
                '.content',
                'div[class*="content"]',
                'div[class*="article"]',

                # ?ï¿½ì´ï¿½?ê¸°ë°˜ ?ï¿½í„´
                'td.article',
                'td[class*="content"]',

                # ë°±ì—… ?ï¿½í„´ (???ï¿½ï¿½? ë²”ìœ„)
                'div',
                'td'
            ]

            content_parts = []

            for selector in content_selectors:
                try:
                    elements = self.driver.find_elements(By.CSS_SELECTOR, selector)

                    for element in elements:
                        text = element.text.strip()
                        if text and len(text) > 10:  # ìµœì†Œ 10???ï¿½ìƒ
                            # ì¤‘ë³µ ?ï¿½ê±° (?ï¿½ï¿½? ì¶”ï¿½????ï¿½ìš©?ï¿½ï¿½? ?ï¿½ì¸)
                            if not any(text[:50] in part for part in content_parts):
                                content_parts.append(text)

                    # ì¶©ë¶„???ï¿½ìš©??ì°¾ì•˜?ï¿½ë©´ ì¤‘ë‹¨
                    if content_parts and sum(len(part) for part in content_parts) > 100:
                        break

                except Exception as e:
                    continue

            # ?ï¿½ìš© ?ï¿½ì¹˜ï¿½?ï¿½??ï¿½ë¦¬
            full_content = '\\n\\n'.join(content_parts)

            # ?ï¿½ë¬´ ê¸¸ë©´ ?ï¿½ì•½ (10000???ï¿½í•œ)
            if len(full_content) > 10000:
                full_content = full_content[:10000] + "... (?ï¿½ìš© ?ï¿½ëµ)"

            return self.clean_text(full_content) if full_content else ""

        except Exception as e:
            print(f"        ?ï¿½ï¸ ê²Œì‹œê¸€ ?ï¿½ìš© ì¶”ì¶œ ?ï¿½ë¥˜: {e}")
            return ""

    def extract_comments(self):
        """?ï¿½ï¿½? ì¶”ì¶œ (1000ï¿½??ï¿½ï¿½? ?ï¿½ì§‘ ìµœì ??"""
        if not self.driver:
            return []

        try:
            # ?ï¿½ì²´ ?ï¿½ï¿½? ?ï¿½ì§‘ ì¶”ì 
            total_comments_collected = getattr(self, '_total_comments_collected', 0)

            # ?ï¿½ì²´ ?ï¿½ï¿½? ?ï¿½í•œ ?ï¿½ì¸ (ê¸°ë³¸ï¿½??ï¿½ì •)
            max_total_comments = getattr(Config, 'MAX_TOTAL_COMMENTS', 1000)
            if total_comments_collected >= max_total_comments:
                print(f"        ?ï¿½ï¸ ?ï¿½ì²´ ?ï¿½ï¿½? ?ï¿½ì§‘ ?ï¿½í•œ ({max_total_comments}ï¿½? ?ï¿½ë‹¬")
                return []

            print(f"        ?ï¿½ï¿½ ?ï¿½ï¿½? ?ï¿½ì§‘ ï¿½?.. (?ï¿½ì¬: {total_comments_collected}/{max_total_comments})")
            comments = []

            # ë‹¤ì–‘í•œ ë„¤ì´ë²„ ì¹´í˜ ëŒ“ê¸€ íŒ¨í„´ë“¤
            comment_selectors = [
                '.comment_area .comment_box',
                '.cmt_area .comment_item',
                '.reply_area .reply_item',
                'div[class*="comment"]',
                'li[class*="comment"]',
                '.CommentItem',
                '.comment-item',
                '.comment_list li',
                '.comment-list .item',
                '[class*="CommentBox"]',
                '[class*="ReplyBox"]',
                '.comment_wrap .comment',
                '.board_comment .comment'
            ]

            # ?ï¿½ì§‘ ê°€?ï¿½í•œ ?ï¿½ï¿½? ??ê³„ì‚°
            max_comments_per_post = getattr(Config, 'MAX_COMMENTS_PER_POST', 50)
            remaining_quota = max_total_comments - total_comments_collected
            max_collect = min(max_comments_per_post, remaining_quota)

            for selector in comment_selectors:
                try:
                    comment_elements = self.driver.find_elements(By.CSS_SELECTOR, selector)

                    if comment_elements and len(comment_elements) > 0:
                        print(f"        ?ï¿½ï¿½ ?ï¿½ï¿½? ?ï¿½í„´ ë°œê²¬: '{selector}' ({len(comment_elements)}ï¿½?")

                        collected_this_round = 0
                        for i, comment_elem in enumerate(comment_elements):
                            if collected_this_round >= max_collect:
                                break

                            comment_data = self.extract_single_comment_enhanced(comment_elem, total_comments_collected + i + 1)
                            if comment_data:
                                # ìµœì†Œ ê¸¸ì´ ?ï¿½ì¸
                                min_length = getattr(Config, 'COMMENT_CONTENT_MIN_LENGTH', 5)
                                if len(comment_data.get('content', '')) >= min_length:
                                    comments.append(comment_data)
                                    collected_this_round += 1

                        # ?ï¿½ï¿½???ì°¾ì•˜?ï¿½ë©´ ì¤‘ë‹¨
                        if comments:
                            break

                except Exception as e:
                    continue

            # ?ï¿½?ï¿½ï¿½? ?ï¿½ì§‘ (?ï¿½ì •???ï¿½ì„±?ï¿½ëœ ê²½ìš°)
            collect_replies = getattr(Config, 'COLLECT_COMMENT_REPLIES', True)
            if collect_replies and comments and len(comments) < max_collect:
                replies = self.extract_comment_replies_enhanced(max_collect - len(comments))
                comments.extend(replies)

            # ?ï¿½ì²´ ?ï¿½ï¿½? ì¹´ìš´???ï¿½ë°?ï¿½íŠ¸
            self._total_comments_collected = getattr(self, '_total_comments_collected', 0) + len(comments)

            print(f"        ??ï¿½?{len(comments)}ï¿½??ï¿½ï¿½? ?ï¿½ì§‘ ?ï¿½ë£Œ (?ï¿½ì²´: {self._total_comments_collected}/{max_total_comments})")
            return comments

        except Exception as e:
            print(f"        ???ï¿½ï¿½? ì¶”ì¶œ ?ï¿½ë¥˜: {e}")
            return []

    def extract_single_comment_enhanced(self, comment_element, comment_id):
        """ê°œë³„ ?ï¿½ï¿½? ?ï¿½ë³´ ì¶”ì¶œ (1000ï¿½??ï¿½ì§‘ ìµœì ??"""
        try:
            comment_data = {
                'comment_id': comment_id,
                'author': '',
                'content': '',
                'date': '',
                'like_count': 0,
                'depth': 1,
                'parent_id': None
            }

            # ?ï¿½ï¿½? ?ï¿½ì„±??ì¶”ì¶œ (?ï¿½ì¥???ï¿½íƒ??
            author_selectors = [
                '.comment_nick a', '.comment_author', '.nick',
                '.user_nick', '.author', 'strong', '.name',
                '.nickname', '.user-name', '.author-name',
                '[class*="nick"]', '[class*="author"]',
                '.writer', '.userid'
            ]

            for selector in author_selectors:
                try:
                    author_elem = comment_element.find_element(By.CSS_SELECTOR, selector)
                    author_text = self.clean_text(author_elem.text)
                    if author_text and len(author_text) > 0:
                        comment_data['author'] = author_text
                        break
                except:
                    continue

            # ?ï¿½ï¿½? ?ï¿½ìš© ì¶”ì¶œ (?ï¿½ì¥???ï¿½íƒ??
            content_selectors = [
                '.comment_text', '.comment_content', '.text',
                '.content', 'span', 'div', 'p',
                '.comment-text', '.comment-content',
                '[class*="content"]', '[class*="text"]',
                '.message', '.body'
            ]

            for selector in content_selectors:
                try:
                    content_elem = comment_element.find_element(By.CSS_SELECTOR, selector)
                    content_text = self.clean_text(content_elem.text)
                    min_length = getattr(Config, 'COMMENT_CONTENT_MIN_LENGTH', 5)
                    if content_text and len(content_text) >= min_length:
                        comment_data['content'] = content_text
                        break
                except:
                    continue

            # ?ï¿½ï¿½? ?ï¿½ì§œ ì¶”ì¶œ (?ï¿½ì¥???ï¿½íƒ??
            date_selectors = [
                '.comment_date', '.date', '.time', '.created_time',
                '.comment-date', '.comment-time', '.timestamp',
                '[class*="date"]', '[class*="time"]',
                '.regdate', '.writedate'
            ]

            for selector in date_selectors:
                try:
                    date_elem = comment_element.find_element(By.CSS_SELECTOR, selector)
                    date_text = self.clean_text(date_elem.text)
                    if date_text:
                        comment_data['date'] = date_text
                        break
                except:
                    continue

            # ì¢‹ì•„????ì¶”ì¶œ
            like_selectors = [
                '.like_count', '.like-count', '.thumbup',
                '[class*="like"]', '[class*="thumb"]',
                '.recommend', '.good'
            ]

            for selector in like_selectors:
                try:
                    like_elem = comment_element.find_element(By.CSS_SELECTOR, selector)
                    like_text = self.clean_text(like_elem.text)
                    if like_text:
                        # ?ï¿½ìï¿½?ì¶”ì¶œ
                        like_numbers = ''.join(filter(str.isdigit, like_text))
                        comment_data['like_count'] = int(like_numbers) if like_numbers else 0
                        break
                except:
                    continue

            # ?ï¿½ï¿½? ê¹Šì´ ?ï¿½ì¸ (?ï¿½?ï¿½ï¿½??ï¿½ï¿½?)
            class_name = comment_element.get_attribute('class').lower()
            if any(keyword in class_name for keyword in ['re-comment', 'reply', 'sub-comment', 'child']):
                comment_data['depth'] = 2

            # ?ï¿½íš¨???ï¿½ï¿½??ï¿½ï¿½? ?ï¿½ì¸
            min_length = getattr(Config, 'COMMENT_CONTENT_MIN_LENGTH', 5)
            if comment_data.get('content') and len(comment_data['content']) >= min_length:
                # ê¸°ë³¸ï¿½??ï¿½ì •
                comment_data.setdefault('author', '?ï¿½ëª…')
                comment_data.setdefault('date', '?ï¿½ì§œ ?ï¿½ìŒ')

                return comment_data

            return None

        except Exception as e:
            return None

    def extract_comment_replies_enhanced(self, max_replies):
        """?ï¿½?ï¿½ï¿½? ?ï¿½ì§‘ (1000ï¿½??ï¿½ï¿½? ?ï¿½ì§‘ ìµœì ??"""
        try:
            collect_replies = getattr(Config, 'COLLECT_COMMENT_REPLIES', True)
            if not collect_replies:
                return []

            replies = []

            # ë‹µê¸€ ì„ íƒì íŒ¨í„´ë“¤
            reply_selectors = [
                '.re-comment', '.reply', '.comment-reply',
                '.sub-comment', '.child-comment', '.reply-item',
                '[class*="reply"]', '[class*="re-comment"]',
                '.comment_reply', '.comment-child'
            ]

            for selector in reply_selectors:
                try:
                    reply_elements = self.driver.find_elements(By.CSS_SELECTOR, selector)

                    if reply_elements:
                        for i, reply_elem in enumerate(reply_elements):
                            if len(replies) >= max_replies:
                                break

                            reply_data = self.extract_single_reply(reply_elem, i + 1)
                            if reply_data:
                                replies.append(reply_data)

                        # ?ï¿½?ï¿½ï¿½???ì°¾ì•˜?ï¿½ë©´ ì¤‘ë‹¨
                        if replies:
                            break

                except Exception as e:
                    continue

            return replies

        except Exception as e:
            return []

    def extract_single_reply(self, reply_element, reply_index):
        """ê°œë³„ ?ï¿½?ï¿½ï¿½? ?ï¿½ë³´ ì¶”ì¶œ"""
        try:
            reply_data = {
                'comment_id': f"reply_{reply_index}",
                'author': '',
                'content': '',
                'date': '',
                'like_count': 0,
                'depth': 2,
                'parent_id': None
            }

            # ë‹µê¸€ ì‘ì„±ì ì„ íƒì
            author_selectors = [
                '.nick', '.author', '.user_nick', '.name',
                '[class*="nick"]', '[class*="author"]'
            ]

            for selector in author_selectors:
                try:
                    author_elem = reply_element.find_element(By.CSS_SELECTOR, selector)
                    author_text = self.clean_text(author_elem.text)
                    if author_text:
                        reply_data['author'] = author_text
                        break
                except:
                    continue

            # ?ï¿½?ï¿½ï¿½? ?ï¿½ìš©
            content_selectors = [
                '.content', '.comment_content', '.text', '[class*="content"]'
            ]

            for selector in content_selectors:
                try:
                    content_elem = reply_element.find_element(By.CSS_SELECTOR, selector)
                    content_text = self.clean_text(content_elem.text)
                    min_length = getattr(Config, 'COMMENT_CONTENT_MIN_LENGTH', 5)
                    if content_text and len(content_text) >= min_length:
                        reply_data['content'] = content_text
                        break
                except:
                    continue

            # ?ï¿½?ï¿½ï¿½? ?ï¿½ì§œ
            date_selectors = ['.date', '.time', '[class*="date"]', '[class*="time"]']

            for selector in date_selectors:
                try:
                    date_elem = reply_element.find_element(By.CSS_SELECTOR, selector)
                    date_text = self.clean_text(date_elem.text)
                    if date_text:
                        reply_data['date'] = date_text
                        break
                except:
                    continue

            # ?ï¿½íš¨???ï¿½?ï¿½ï¿½??ï¿½ï¿½? ?ï¿½ì¸
            min_length = getattr(Config, 'COMMENT_CONTENT_MIN_LENGTH', 5)
            if reply_data.get('content') and len(reply_data['content']) >= min_length:
                reply_data.setdefault('author', '?ï¿½ëª…')
                reply_data.setdefault('date', '?ï¿½ì§œ ?ï¿½ìŒ')
                return reply_data

            return None

        except Exception as e:
            return None

    def extract_images(self):
        """ê²Œì‹œê¸€ ???ï¿½ï¿½?ì§€ URL ì¶”ì¶œ"""
        if not self.driver:
            return []

        try:
            images = []
            img_elements = self.driver.find_elements(By.TAG_NAME, "img")

            for img in img_elements:
                src = img.get_attribute("src")
                alt = img.get_attribute("alt") or ""

                if src and 'http' in src:
                    images.append({
                        'url': src,
                        'alt': self.clean_text(alt),
                        'size': f"{img.size['width']}x{img.size['height']}"
                    })

            return images[:10]  # ìµœï¿½? 10ê°œê¹Œì§€

        except:
            return []

    def extract_attachments(self):
        """ì²¨ï¿½??ï¿½ì¼ ?ï¿½ë³´ ì¶”ì¶œ"""
        if not self.driver:
            return []

        try:
            attachments = []

            # ì²¨ï¿½??ï¿½ì¼ ë§í¬ ?ï¿½í„´??            attachment_selectors = [
                'a[href*="attachment"]', 'a[href*="download"]',
                'a[href*="file"]', '.attachment', '.file'
            ]

            for selector in attachment_selectors:
                try:
                    elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    for elem in elements:
                        href = elem.get_attribute("href")
                        text = self.clean_text(elem.text)

                        if href and text:
                            attachments.append({
                                'name': text,
                                'url': href
                            })
                except:
                    continue

            return attachments[:5]  # ìµœï¿½? 5ê°œê¹Œì§€

        except:
            return []

    # =====================================================================
    # Phase 4: ê³ ê¸‰ ?ï¿½ì´??ì¶”ì¶œ ?ï¿½ìŠ¤??(??ë²ˆì§¸ ê·¸ë£¹ - ê²Œì‹œê¸€ ?ï¿½ìš© ï¿½?êµ¬ì¡° ë¶„ì„)
    # =====================================================================

    def enhance_posts_with_details(self, posts, keyword):
        """ê²Œì‹œê¸€ ?ï¿½ì„¸ ?ï¿½ë³´ ê°•í™” (?ï¿½ìš©, ?ï¿½ï¿½?, ?ï¿½ï¿½?ì§€ ??"""
        try:
            print(f"    ?ï¿½ï¿½ ?ï¿½ì„¸ ?ï¿½ë³´ ?ï¿½ì§‘ ï¿½?.. (ï¿½?{len(posts)}ï¿½?")
            enhanced_posts = []
            max_total_posts = getattr(Config, 'MAX_TOTAL_POSTS', 100)

            for i, post in enumerate(posts[:max_total_posts], 1):
                try:
                    print(f"      ?ï¿½ï¿½ ê²Œì‹œê¸€ {i}/{min(len(posts), max_total_posts)} ì²˜ë¦¬ ï¿½?..")

                    # ?ï¿½ì„¸ ?ï¿½ìš© ?ï¿½ì§‘
                    extract_full_content = getattr(Config, 'EXTRACT_FULL_CONTENT', False)
                    extract_comments = getattr(Config, 'EXTRACT_COMMENTS', False)

                    if extract_full_content or extract_comments:
                        post_url = post.get('url', '')
                        if post_url:
                            detail_data = self.get_post_content(post_url)

                            # ?ï¿½ì„¸ ?ï¿½ë³´ ?ï¿½í•©
                            if detail_data.get('content'):
                                post['full_content'] = detail_data['content']

                            if detail_data.get('comments'):
                                post['comments'] = detail_data['comments']
                                post['comment_count'] = len(detail_data['comments'])

                            if detail_data.get('images'):
                                post['images'] = detail_data['images']

                            if detail_data.get('attachments'):
                                post['attachments'] = detail_data['attachments']

                    # ì¶”ï¿½? ë©”ï¿½??ï¿½ì´??                    post['keyword'] = keyword
                    post['collection_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                    post['enhanced'] = True

                    enhanced_posts.append(post)

                    # ì§„í–‰ï¿½??ï¿½ì‹œ
                    if i % 10 == 0:
                        print(f"      ?ï¿½ï¿½ ì§„í–‰ï¿½? {i}/{min(len(posts), max_total_posts)} ({i/min(len(posts), max_total_posts)*100:.1f}%)")

                except Exception as e:
                    print(f"      ??ê²Œì‹œê¸€ {i} ì²˜ë¦¬ ?ï¿½ë¥˜: {e}")
                    # ê¸°ë³¸ ?ï¿½ë³´?ï¿½ë„ ?ï¿½ï¿½?
                    post['keyword'] = keyword
                    post['collection_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                    post['enhanced'] = False
                    enhanced_posts.append(post)
                    continue

            print(f"    ???ï¿½ì„¸ ?ï¿½ë³´ ?ï¿½ì§‘ ?ï¿½ë£Œ: {len(enhanced_posts)}ï¿½?)
            return enhanced_posts

        except Exception as e:
            print(f"    ???ï¿½ì„¸ ?ï¿½ë³´ ?ï¿½ì§‘ ?ï¿½ë¥˜: {e}")
            return posts

    def get_posts_data(self):
        """?ï¿½ì§‘??ê²Œì‹œê¸€ ?ï¿½ì´??ë°˜í™˜"""
        return getattr(self, 'posts_data', [])

    def analyze_page_structure_for_posts(self):
        """ê²Œì‹œê¸€ ì¶”ì¶œ???ï¿½í•œ ?ï¿½ì´ì§€ êµ¬ì¡° ë¶„ì„"""
        structure = {}

        try:
            # ?ï¿½ì´ï¿½?ê¸°ë°˜ êµ¬ì¡° ?ï¿½ì¸
            tables = self.driver.find_elements(By.CSS_SELECTOR, "table")
            structure['table_count'] = len(tables)

            # ë¦¬ìŠ¤??ê¸°ë°˜ êµ¬ì¡° ?ï¿½ì¸
            lists = self.driver.find_elements(By.CSS_SELECTOR, "ul, ol")
            structure['list_count'] = len(lists)

            # div ê¸°ë°˜ êµ¬ì¡° ?ï¿½ì¸
            divs = self.driver.find_elements(By.CSS_SELECTOR, "div[class*='article'], div[class*='post'], div[class*='board']")
            structure['div_count'] = len(divs)

            # ë§í¬ ?ï¿½ì†Œ ?ï¿½ì¸
            links = self.driver.find_elements(By.CSS_SELECTOR, "a[href*='read']")
            structure['link_count'] = len(links)

            print(f"      ?ï¿½ï¿½ ?ï¿½ì´ì§€ êµ¬ì¡°: ?ï¿½ì´ï¿½?{structure['table_count']}, ë¦¬ìŠ¤??{structure['list_count']}, div {structure['div_count']}, ë§í¬ {structure['link_count']}")

            return structure

        except Exception as e:
            print(f"      ?ï¿½ï¸ ?ï¿½ì´ì§€ êµ¬ì¡° ë¶„ì„ ?ï¿½ë¥˜: {e}")
            return {}

    # =====================================================================
    # Phase 6: êµ¬ì¡° ë¶„ì„ ï¿½??ï¿½ìƒ‰ ?ï¿½ìŠ¤??(ï¿½?ë²ˆì§¸ ê·¸ë£¹ - ê¸°ë³¸ ë¶„ì„)
    # =====================================================================

    def analyze_current_page(self):
        """?ï¿½ì¬ ?ï¿½ì´ì§€ ?ï¿½íƒœ ë¶„ì„"""
        analysis = {}

        try:
            # ?ï¿½ì´ì§€ ?ï¿½??ê°ï¿½?
            page_indicators = {
                'board_list': ['.article-board', '.post-list', '.board-content'],
                'search_result': ['.search-result', '.search-list'],
                'main_page': ['.cafe-main', '.main-content'],
                'single_post': ['.post-view', '.article-view']
            }

            analysis['page_type'] = 'unknown'
            for page_type, selectors in page_indicators.items():
                for selector in selectors:
                    try:
                        if self.driver.find_elements(By.CSS_SELECTOR, selector):
                            analysis['page_type'] = page_type
                            break
                    except:
                        continue
                if analysis['page_type'] != 'unknown':
                    break

            # ê²Œì‹œê¸€ ??ê³„ì‚°
            post_selectors = [
                '.article-board tbody tr',
                '.post-item',
                '.board-item'
            ]

            analysis['post_count'] = 0
            for selector in post_selectors:
                try:
                    posts = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    analysis['post_count'] = len(posts)
                    if analysis['post_count'] > 0:
                        break
                except:
                    continue

            print(f"      ?ï¿½ï¿½ ?ï¿½ì´ì§€ ë¶„ì„: ?ï¿½??{analysis['page_type']}, ê²Œì‹œê¸€??{analysis['post_count']}")

            return analysis

        except Exception as e:
            print(f"      ?ï¿½ï¸ ?ï¿½ì´ì§€ ë¶„ì„ ?ï¿½ë¥˜: {e}")
            return {'page_type': 'unknown', 'post_count': 0}

    def debug_page_structure(self):
        """?ï¿½ì´ì§€ êµ¬ì¡° ?ï¿½ë²„ï¿½?""
        try:
            print("      ?ï¿½ï¿½ ?ï¿½ì´ì§€ êµ¬ì¡° ?ï¿½ë²„ï¿½?ï¿½?..")

            # ?ï¿½ì¬ URLï¿½??ï¿½ëª©
            current_url = self.driver.current_url
            page_title = self.driver.title
            print(f"        URL: {current_url}")
            print(f"        ?ï¿½ëª©: {page_title}")

            # ì£¼ìš” ?ï¿½ì†Œ??ê°œìˆ˜ ?ï¿½ì¸
            elements_info = {
                "?ï¿½ì´ï¿½?: len(self.driver.find_elements(By.TAG_NAME, "table")),
                "??tr)": len(self.driver.find_elements(By.TAG_NAME, "tr")),
                "ë§í¬(a)": len(self.driver.find_elements(By.TAG_NAME, "a")),
                "ë¦¬ìŠ¤??li)": len(self.driver.find_elements(By.TAG_NAME, "li")),
                "div": len(self.driver.find_elements(By.TAG_NAME, "div"))
            }

            for name, count in elements_info.items():
                print(f"        {name}: {count}ï¿½?)

            # ë§í¬ ?ï¿½í”Œ ?ï¿½ì¸
            links = self.driver.find_elements(By.CSS_SELECTOR, "a[href]")[:10]
            print(f"        ë§í¬ ?ï¿½í”Œ (ì²˜ìŒ 10ï¿½?:")
            for i, link in enumerate(links):
                try:
                    text = link.text.strip()[:30] if link.text else "(?ï¿½ìŠ¤???ï¿½ìŒ)"
                    href = link.get_attribute("href")[:50] if link.get_attribute("href") else "(href ?ï¿½ìŒ)"
                    print(f"          {i+1}. {text} -> {href}")
                except:
                    print(f"          {i+1}. (?ï¿½ë¥˜)")

        except Exception as e:
            print(f"        ???ï¿½ë²„ï¿½??ï¿½ë¥˜: {e}")

    # =====================================================================
    # Phase 6: êµ¬ì¡° ë¶„ì„ ï¿½??ï¿½ìƒ‰ ?ï¿½ìŠ¤??(??ë²ˆì§¸ ê·¸ë£¹ - ?ï¿½ì „ ?ï¿½ìƒ‰)
    # =====================================================================

    def explore_cafe_completely(self, cafe_url, keywords=None):
        """?ï¿½ï¿½ ?ï¿½ì´ï¿½?ì¹´í˜ ?ï¿½ì „ ?ï¿½ìƒ‰ ?ï¿½ìŠ¤??""
        print(f"\n?? ?ï¿½ì´ï¿½?ì¹´í˜ ?ï¿½ì „ ?ï¿½ìƒ‰ ?ï¿½ì‘!")
        print(f"?ï¿½ï¿½ ?ï¿½??ì¹´í˜: {cafe_url}")
        print(f"?ï¿½ï¿½ ?ï¿½ìƒ‰ ëª¨ë“œ: ?ï¿½ì²´ ê²€??ê¸°ëŠ¥ + ëª¨ë“  ê²Œì‹œ??)
        print("=" * 80)

        exploration_results = {
            'cafe_metadata': {},
            'all_boards': [],
            'search_results': {},
            'statistics': {},
            'total_posts': 0,
            'total_comments': 0
        }

        try:
            # 1?ï¿½ê³„: ì¹´í˜ ?ï¿½ì† ï¿½?ê¸°ë³¸ ë¶„ì„
            print(f"?ï¿½ï¿½ 1?ï¿½ê³„: ì¹´í˜ ?ï¿½ì† ï¿½?êµ¬ì¡° ë¶„ì„")
            self.driver.get(cafe_url)
            self.safe_wait(self.driver, 3)

            # ë¡œê·¸???ï¿½ì¸
            if not self.check_login_status():
                print("??ë¡œê·¸?ï¿½ì´ ?ï¿½ìš”?ï¿½ë‹ˆ??")
                return exploration_results

            # 2?ï¿½ê³„: ì¹´í˜ ë©”ï¿½??ï¿½ì´???ï¿½ì§‘
            if getattr(Config, 'COLLECT_CAFE_METADATA', True):
                print(f"?ï¿½ï¿½ 2?ï¿½ê³„: ì¹´í˜ ë©”ï¿½??ï¿½ì´???ï¿½ì§‘")
                exploration_results['cafe_metadata'] = self.collect_cafe_metadata()

            # 3?ï¿½ê³„: ëª¨ë“  ê²Œì‹œ??ë°œê²¬ ï¿½?ë¶„ì„
            if getattr(Config, 'EXPLORE_ALL_BOARDS', True):
                print(f"?ï¿½ï¿½ï¿½?3?ï¿½ê³„: ëª¨ë“  ê²Œì‹œ??ë°œê²¬ ï¿½?ë¶„ì„")
                exploration_results['all_boards'] = self.discover_all_boards()

            # 4?ï¿½ê³„: ?ï¿½ì´ï¿½?ì¹´í˜ ?ï¿½ï¿½? ê²€??ê¸°ëŠ¥ ?ï¿½ì „ ?ï¿½ìš©
            if keywords:
                print(f"?ï¿½ï¿½ 4?ï¿½ê³„: ?ï¿½ï¿½? ê²€??ê¸°ëŠ¥ ?ï¿½ì „ ?ï¿½ìš©")
                exploration_results['search_results'] = self.comprehensive_search_exploration(keywords)

            # 5?ï¿½ê³„: ëª¨ë“  ê²Œì‹œ?ï¿½ë³„ ?ï¿½ìƒ‰
            print(f"?ï¿½ï¿½ 5?ï¿½ê³„: ëª¨ë“  ê²Œì‹œ??ê°œë³„ ?ï¿½ìƒ‰")
            board_results = self.explore_all_boards_individually(exploration_results['all_boards'])
            exploration_results.update(board_results)

            # 6?ï¿½ê³„: ?ï¿½ê³„ ï¿½?ë¶„ì„
            print(f"?ï¿½ï¿½ 6?ï¿½ê³„: ì¢…í•© ?ï¿½ê³„ ?ï¿½ì„±")
            exploration_results['statistics'] = self.generate_exploration_statistics(exploration_results)

            print(f"\n?ï¿½ï¿½ ?ï¿½ì „ ?ï¿½ìƒ‰ ?ï¿½ë£Œ!")
            print(f"?ï¿½ï¿½ ë°œê²¬??ê²Œì‹œ?? {len(exploration_results['all_boards'])}ï¿½?)
            print(f"?ï¿½ï¿½ ?ï¿½ì§‘??ê²Œì‹œê¸€: {exploration_results['total_posts']}ï¿½?)
            print(f"?ï¿½ï¿½ ?ï¿½ì§‘???ï¿½ï¿½?: {exploration_results['total_comments']}ï¿½?)

            return exploration_results

        except Exception as e:
            print(f"???ï¿½ì „ ?ï¿½ìƒ‰ ï¿½??ï¿½ë¥˜: {e}")
            return exploration_results

    def collect_cafe_metadata(self):
        """ì¹´í˜ ë©”ï¿½??ï¿½ì´???ï¿½ì§‘"""
        try:
            print(f"    ?ï¿½ï¿½ ì¹´í˜ ê¸°ë³¸ ?ï¿½ë³´ ?ï¿½ì§‘ ï¿½?..")
            metadata = {
                'cafe_name': '',
                'cafe_url': '',
                'member_count': 0,
                'category': '',
                'description': '',
                'creation_date': '',
                'cafe_level': '',
                'cafe_type': '',
                'rules': [],
                'admin_info': {},
                'activity_stats': {}
            }

            # ì¹´í˜ ?ï¿½ë¦„ ì¶”ì¶œ
            cafe_name_selectors = [
                '.cafe-name', '.cafe_name', 'h1', '.title',
                '[class*="cafe"]', '[class*="title"]'
            ]

            for selector in cafe_name_selectors:
                try:
                    element = self.driver.find_element(By.CSS_SELECTOR, selector)
                    cafe_name = self.clean_text(element.text)
                    if cafe_name and len(cafe_name) > 2:
                        metadata['cafe_name'] = cafe_name
                        break
                except:
                    continue

            # ë©¤ë²„ ??ì¶”ì¶œ
            member_selectors = [
                '[class*="member"]', '[class*="count"]',
                '.member-count', '.cafe-member'
            ]

            for selector in member_selectors:
                try:
                    elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    for element in elements:
                        text = element.text
                        numbers = ''.join(filter(str.isdigit, text))
                        if numbers and int(numbers) > 10:  # ?ï¿½ì œ ë©¤ë²„ ?ï¿½ë¡œ ë³´ì´??ê²½ìš°
                            metadata['member_count'] = int(numbers)
                            break
                    if metadata['member_count'] > 0:
                        break
                except:
                    continue

            # ?ï¿½ì¬ URL ?ï¿½??            metadata['cafe_url'] = self.driver.current_url

            # ì¹´í˜ ?ï¿½ëª… ì¶”ì¶œ
            description_selectors = [
                '.cafe-description', '.description',
                '[class*="intro"]', '[class*="desc"]'
            ]

            for selector in description_selectors:
                try:
                    element = self.driver.find_element(By.CSS_SELECTOR, selector)
                    desc_text = self.clean_text(element.text)
                    if desc_text and len(desc_text) > 10:
                        metadata['description'] = desc_text[:500]  # ìµœï¿½? 500??                        break
                except:
                    continue

            print(f"        ??ì¹´í˜ï¿½? {metadata['cafe_name']}")
            print(f"        ?ï¿½ï¿½ ë©¤ë²„?? {metadata['member_count']:,}ï¿½?)
            print(f"        ?ï¿½ï¿½ ?ï¿½ëª…: {metadata['description'][:50]}..." if metadata['description'] else "        ?ï¿½ï¿½ ?ï¿½ëª…: ?ï¿½ìŒ")

            return metadata

        except Exception as e:
            print(f"        ??ë©”ï¿½??ï¿½ì´???ï¿½ì§‘ ?ï¿½ë¥˜: {e}")
            return {}

    def comprehensive_search_exploration(self, keywords):
        """?ï¿½ï¿½ ?ï¿½ì´ï¿½?ì¹´í˜ ?ï¿½ï¿½? ê²€??ê¸°ëŠ¥ ?ï¿½ì „ ?ï¿½ìš©"""
        try:
            print(f"    ?ï¿½ï¿½ ?ï¿½ì›Œ?? {keywords}")
            search_results = {
                'total_searches': 0,
                'successful_searches': 0,
                'failed_searches': 0,
                'all_posts': [],
                'search_strategies': {}
            }

            # ?ï¿½ì›Œ?ï¿½ï¿½? ë¬¸ì?ï¿½ì¸ ê²½ìš° ë¦¬ìŠ¤?ï¿½ë¡œ ë³€??            if isinstance(keywords, str):
                keyword_list = [keywords]
            else:
                keyword_list = keywords

            for keyword in keyword_list:
                print(f"        ?ï¿½ï¿½ '{keyword}' ê²€???ï¿½ì‘...")

                # 1. ?ï¿½í•© ê²€??                if getattr(Config, 'USE_INTEGRATED_SEARCH', True):
                    result = self.perform_integrated_search(keyword)
                    search_results['search_strategies']['integrated'] = result
                    search_results['total_searches'] += 1
                    if result.get('posts'):
                        search_results['successful_searches'] += 1
                        search_results['all_posts'].extend(result['posts'])

                # 2. ?ï¿½ì¤‘ ë²”ìœ„ ê²€??(?ï¿½ëª©, ?ï¿½ìš©, ?ï¿½ì„±????
                if hasattr(Config, 'COMPREHENSIVE_SEARCH_SCOPES'):
                    for scope in Config.COMPREHENSIVE_SEARCH_SCOPES:
                        result = self.perform_scope_specific_search(keyword, scope)
                        search_results['search_strategies'][f'scope_{scope}'] = result
                        search_results['total_searches'] += 1
                        if result.get('posts'):
                            search_results['successful_searches'] += 1
                            search_results['all_posts'].extend(result['posts'])

                # 3. ?ï¿½ì¤‘ ?ï¿½ë ¬ ê²€??                if hasattr(Config, 'COMPREHENSIVE_SORT_METHODS'):
                    for sort_method in Config.COMPREHENSIVE_SORT_METHODS:
                        result = self.perform_sort_specific_search(keyword, sort_method)
                        search_results['search_strategies'][f'sort_{sort_method}'] = result
                        search_results['total_searches'] += 1
                        if result.get('posts'):
                            search_results['successful_searches'] += 1
                            search_results['all_posts'].extend(result['posts'])

                # 4. ê¸°ê°„ï¿½?ê²€??                if hasattr(Config, 'COMPREHENSIVE_DATE_FILTERS'):
                    for date_filter in Config.COMPREHENSIVE_DATE_FILTERS:
                        result = self.perform_date_specific_search(keyword, date_filter)
                        search_results['search_strategies'][f'date_{date_filter}'] = result
                        search_results['total_searches'] += 1
                        if result.get('posts'):
                            search_results['successful_searches'] += 1
                            search_results['all_posts'].extend(result['posts'])

            # ì¤‘ë³µ ?ï¿½ê±°
            search_results['all_posts'] = self.deduplicate_posts(search_results['all_posts'])
            search_results['failed_searches'] = search_results['total_searches'] - search_results['successful_searches']

            print(f"        ??ê²€???ï¿½ë£Œ: {len(search_results['all_posts'])}ï¿½?ê²Œì‹œê¸€ ë°œê²¬")
            return search_results

        except Exception as e:
            print(f"        ??ì¢…í•© ê²€???ï¿½ë¥˜: {e}")
            return {'all_posts': [], 'search_strategies': {}}

    # =====================================================================
    # Phase 6: êµ¬ì¡° ë¶„ì„ ï¿½??ï¿½ìƒ‰ ?ï¿½ìŠ¤??(??ë²ˆì§¸ ê·¸ë£¹ - ê°œë³„ ê²Œì‹œ???ï¿½ìƒ‰)
    # =====================================================================

    def explore_all_boards_individually(self, boards):
        """ëª¨ë“  ê²Œì‹œ??ê°œë³„ ?ï¿½ìƒ‰"""
        try:
            print(f"    ?ï¿½ï¿½ ê°œë³„ ê²Œì‹œ???ï¿½ìƒ‰ ï¿½?.. ({len(boards)}ï¿½?")

            board_results = {
                'board_results': {},
                'active_boards': [],
                'inactive_boards': [],
                'total_posts': 0,
                'total_comments': 0
            }

            for i, board in enumerate(boards):
                try:
                    board_name = board.get('name', f'Board_{i+1}')
                    board_url = board.get('url', '')

                    print(f"        ?ï¿½ï¿½ {i+1}/{len(boards)}: {board_name}")

                    if not board_url:
                        print(f"            ?ï¿½ï¸ URL ?ï¿½ìŒ, ê±´ë„ˆ?ï¿½ê¸°")
                        continue

                    # ê²Œì‹œ?ï¿½ìœ¼ï¿½??ï¿½ë™
                    self.driver.get(board_url)
                    self.safe_wait(self.driver, 2)

                    # ê²Œì‹œê¸€ ì¶”ì¶œ
                    board_posts = self.extract_board_posts(board)

                    # ?ï¿½ê³„ ê³„ì‚°
                    board_info = {
                        'board_info': board,
                        'posts': board_posts,
                        'post_count': len(board_posts),
                        'comment_count': sum(len(post.get('comments', [])) for post in board_posts),
                        'last_activity': self.get_board_last_activity(board_posts),
                        'activity_score': self.calculate_board_activity_score(board_posts)
                    }

                    board_results['board_results'][board_name] = board_info

                    # ?ï¿½ë™??ë¶„ë¥˜
                    if board_info['activity_score'] > 10:
                        board_results['active_boards'].append(board)
                    else:
                        board_results['inactive_boards'].append(board)

                    # ?ï¿½ì²´ ?ï¿½ê³„ ?ï¿½ë°?ï¿½íŠ¸
                    board_results['total_posts'] += board_info['post_count']
                    board_results['total_comments'] += board_info['comment_count']

                    print(f"            ??ê²Œì‹œê¸€: {board_info['post_count']}ï¿½? ?ï¿½ï¿½?: {board_info['comment_count']}ï¿½?)

                    # ?ï¿½ë¬´ ë¹ ë¥¸ ?ï¿½ì²­ ë°©ï¿½?
                    self.adaptive_delay()

                except Exception as e:
                    print(f"            ??ê²Œì‹œ???ï¿½ìƒ‰ ?ï¿½ë¥˜: {e}")
                    continue

            print(f"    ??ê°œë³„ ê²Œì‹œ???ï¿½ìƒ‰ ?ï¿½ë£Œ")
            print(f"        ?ï¿½ì„± ê²Œì‹œ?? {len(board_results['active_boards'])}ï¿½?)
            print(f"        ë¹„í™œ??ê²Œì‹œ?? {len(board_results['inactive_boards'])}ï¿½?)

            return board_results

        except Exception as e:
            print(f"    ??ê°œë³„ ê²Œì‹œ???ï¿½ìƒ‰ ?ï¿½ë¥˜: {e}")
            return {'board_results': {}, 'total_posts': 0, 'total_comments': 0}

    def extract_board_posts(self, board):
        """ê²Œì‹œ?ï¿½ì—??ê²Œì‹œê¸€ ì¶”ì¶œ"""
        try:
            # ê¸°ì¡´ extract_posts ë©”ì„œ???ï¿½ìš©
            posts = self.extract_posts()

            # ê²Œì‹œ???ï¿½ë³´ ì¶”ï¿½?
            for post in posts:
                post['board_name'] = board.get('name', '')
                post['board_type'] = board.get('board_type', 'unknown')
                post['board_url'] = board.get('url', '')

            return posts

        except Exception as e:
            return []

    def get_board_last_activity(self, posts):
        """ê²Œì‹œ??ìµœê·¼ ?ï¿½ë™ ?ï¿½ê°„ ê³„ì‚°"""
        try:
            if not posts:
                return ""

            # ê°€??ìµœê·¼ ê²Œì‹œê¸€???ï¿½ì„±?ï¿½ê°„ ë°˜í™˜
            latest_date = ""
            for post in posts:
                post_date = post.get('date', '')
                if post_date and (not latest_date or post_date > latest_date):
                    latest_date = post_date

            return latest_date

        except Exception as e:
            return ""

    def calculate_board_activity_score(self, posts):
        """ê²Œì‹œ???ï¿½ë™???ï¿½ìˆ˜ ê³„ì‚°"""
        try:
            if not posts:
                return 0

            # ê¸°ë³¸ ?ï¿½ìˆ˜: ê²Œì‹œê¸€ ??            score = len(posts)

            # ?ï¿½ï¿½? ??ê°€?ï¿½ì 
            total_comments = sum(len(post.get('comments', [])) for post in posts)
            score += total_comments * 0.5

            # ì¡°íšŒ??ê°€?ï¿½ì 
            total_views = sum(post.get('views', 0) for post in posts)
            score += total_views * 0.001

            # ìµœê·¼ ?ï¿½ë™ ê°€?ï¿½ì  (ìµœê·¼ ?ï¿½ë™?ï¿½ìˆ˜ï¿½??ï¿½ï¿½? ?ï¿½ìˆ˜)
            recent_posts = sum(1 for post in posts if self.is_recent_post(post))
            score += recent_posts * 2

            return round(score, 2)

        except Exception as e:
            return 0

    def is_recent_post(self, post):
        """ìµœê·¼ ê²Œì‹œê¸€?ï¿½ï¿½? ?ï¿½ì¸ (7???ï¿½ë‚´)"""
        try:
            from datetime import datetime, timedelta

            post_date_str = post.get('date', '')
            if not post_date_str:
                return False

            # ?ï¿½ì§œ ?ï¿½ì‹ ?ï¿½ì‹± ?ï¿½ë„
            try:
                # ?ï¿½ì–‘???ï¿½ì§œ ?ï¿½ì‹ ì²˜ë¦¬
                for date_format in ['%Y.%m.%d', '%Y-%m-%d', '%m.%d', '%m-%d']:
                    try:
                        post_date = datetime.strptime(post_date_str, date_format)
                        if date_format in ['%m.%d', '%m-%d']:  # ?ï¿½ë„ê°€ ?ï¿½ëŠ” ê²½ìš° ?ï¿½ì¬ ?ï¿½ë„ ?ï¿½ìš©
                            post_date = post_date.replace(year=datetime.now().year)
                        break
                    except:
                        continue
                else:
                    return False

                # 7???ï¿½ë‚´?ï¿½ï¿½? ?ï¿½ì¸
                week_ago = datetime.now() - timedelta(days=7)
                return post_date >= week_ago

            except:
                return False

        except Exception as e:
            return False

    def generate_exploration_statistics(self, exploration_results):
        """?ï¿½ìƒ‰ ?ï¿½ê³„ ?ï¿½ì„±"""
        try:
            print(f"    ?ï¿½ï¿½ ?ï¿½ê³„ ë¶„ì„ ï¿½?..")

            stats = {
                'exploration_summary': {},
                'board_statistics': {},
                'content_statistics': {},
                'activity_analysis': {},
                'top_boards': [],
                'content_distribution': {}
            }

            # ê¸°ë³¸ ?ï¿½ê³„
            total_boards = len(exploration_results.get('all_boards', []))
            total_posts = exploration_results.get('total_posts', 0)
            total_comments = exploration_results.get('total_comments', 0)

            stats['exploration_summary'] = {
                'total_boards_discovered': total_boards,
                'total_posts_collected': total_posts,
                'total_comments_collected': total_comments,
                'active_boards_count': len(exploration_results.get('active_boards', [])),
                'inactive_boards_count': len(exploration_results.get('inactive_boards', [])),
                'search_strategies_used': len(exploration_results.get('search_results', {}).get('search_strategies', {})),
                'cafe_metadata_collected': bool(exploration_results.get('cafe_metadata', {}))
            }

            # ê²Œì‹œ???ï¿½ê³„
            board_results = exploration_results.get('board_results', {})
            if board_results:
                board_stats = []
                for board_name, board_data in board_results.items():
                    board_stats.append({
                        'name': board_name,
                        'post_count': board_data.get('post_count', 0),
                        'comment_count': board_data.get('comment_count', 0),
                        'activity_score': board_data.get('activity_score', 0),
                        'board_type': board_data.get('board_info', {}).get('board_type', 'unknown')
                    })

                # ?ï¿½ë™?????ï¿½ë ¬
                board_stats.sort(key=lambda x: x['activity_score'], reverse=True)
                stats['top_boards'] = board_stats[:10]  # ?ï¿½ìœ„ 10ï¿½?ê²Œì‹œ??
                # ê²Œì‹œ???ï¿½í˜•ï¿½?ë¶„í¬
                board_type_dist = {}
                for board_stat in board_stats:
                    board_type = board_stat['board_type']
                    if board_type not in board_type_dist:
                        board_type_dist[board_type] = 0
                    board_type_dist[board_type] += 1

                stats['board_statistics'] = {
                    'total_boards_with_content': len(board_stats),
                    'board_type_distribution': board_type_dist,
                    'average_posts_per_board': round(total_posts / len(board_stats), 2) if board_stats else 0,
                    'average_comments_per_board': round(total_comments / len(board_stats), 2) if board_stats else 0
                }

            # ê²€??ê²°ê³¼ ?ï¿½ê³„
            search_results = exploration_results.get('search_results', {})
            if search_results:
                stats['content_statistics'] = {
                    'total_searches_performed': search_results.get('total_searches', 0),
                    'successful_searches': search_results.get('successful_searches', 0),
                    'failed_searches': search_results.get('failed_searches', 0),
                    'search_success_rate': round((search_results.get('successful_searches', 0) / max(search_results.get('total_searches', 1), 1)) * 100, 2),
                    'unique_posts_from_search': len(search_results.get('all_posts', []))
                }

            print(f"        ???ï¿½ê³„ ?ï¿½ì„± ?ï¿½ë£Œ")
            return stats

        except Exception as e:
            print(f"        ???ï¿½ê³„ ?ï¿½ì„± ?ï¿½ë¥˜: {e}")
            return {}

    # =====================================================================
    # CRITICAL MISSING METHODS - Phase 1: iframe ì²˜ë¦¬ ?ï¿½ìŠ¤??    # =====================================================================

    def auto_navigate_frames(self):
        """?ï¿½ë ˆ??êµ¬ì¡° ?ï¿½ë™ ê°ï¿½? ï¿½?ìµœì  ?ï¿½ë ˆ?ï¿½ìœ¼ï¿½??ï¿½í™˜"""
        try:
            if not self.driver:
                return False
            iframes = self.driver.find_elements(By.TAG_NAME, "iframe")
            if not iframes:
                print("  ?ï¿½ï¿½ ?ï¿½ì¼ ?ï¿½ì´ì§€ êµ¬ì¡° (iframe ?ï¿½ìŒ)")
                return True

            print(f"  ?ï¿½ï¿½ï¿½?{len(iframes)}ï¿½?iframe ë°œê²¬, ìµœì  ?ï¿½ë ˆ??ì°¾ëŠ” ì¤‘ï¿½?)
            best_frame, best_score = None, 0
            for i, iframe in enumerate(iframes):
                try:
                    frame_id = iframe.get_attribute("id") or f"frame_{i}"
                    frame_src = iframe.get_attribute("src") or ""
                    frame_name = iframe.get_attribute("name") or ""

                    score = self.calculate_frame_score(frame_id, frame_src, frame_name)
                    if score > best_score:
                        best_score = score
                        best_frame = iframe
                except:
                    continue

            if best_frame:
                try:
                    self.driver.switch_to.frame(best_frame)
                    if self.verify_frame_content():
                        print(f"  ??ìµœì  ?ï¿½ë ˆ?ï¿½ìœ¼ï¿½??ï¿½í™˜ ?ï¿½ë£Œ (?ï¿½ìˆ˜: {best_score})")
                        return True
                    else:
                        self.driver.switch_to.default_content()
                except:
                    self.driver.switch_to.default_content()

            print(f"  ?ï¿½ï¿½ ë©”ì¸ ?ï¿½ì´ì§€?ï¿½ì„œ ê³„ì† ì§„í–‰")
            return True
        except Exception as e:
            print(f"  ???ï¿½ë ˆ???ï¿½ë¹„ê²Œì´???ï¿½ë¥˜: {e}")
            return False

    def calculate_frame_score(self, frame_id, frame_src, frame_name):
        """?ï¿½ë ˆ???ï¿½ì„ ?ï¿½ìœ„ ?ï¿½ìˆ˜ ê³„ì‚°"""
        score = 0
        # ì¹´í˜ ê´€???ï¿½ì›Œ?ï¿½ë¡œ ?ï¿½ìˆ˜ ë¶€??        cafe_keywords = ['cafe', 'main', 'content', 'board', 'article']
        for keyword in cafe_keywords:
            if keyword in frame_id.lower() or keyword in frame_src.lower() or keyword in frame_name.lower():
                score += 10

        # ë©”ì¸ ?ï¿½ë ˆ???ï¿½ì„ 
        if 'main' in frame_id.lower() or 'main' in frame_name.lower():
            score += 20

        return score

    def verify_frame_content(self):
        """?ï¿½ì¬ ?ï¿½ë ˆ?ï¿½ì— ?ï¿½ìš©??ì½˜í…ì¸ ï¿½? ?ï¿½ëŠ”ì§€ ?ï¿½ì¸"""
        try:
            # ê²Œì‹œê¸€ ëª©ë¡ ?ï¿½ì†Œ ?ï¿½ì¸
            post_indicators = ['.article-board', '.post-list', '.board-list', 'table', '.cafe-content']
            for indicator in post_indicators:
                if self.driver.find_elements(By.CSS_SELECTOR, indicator):
                    return True
            return False
        except:
            return False

    def handle_search_iframe(self):
        """ê²€??ê²°ê³¼ ?ï¿½ì´ì§€??iframe ì²˜ë¦¬"""
        try:
            search_iframes = self.driver.find_elements(By.CSS_SELECTOR, "iframe[src*='search'], iframe[name*='search']")
            if search_iframes:
                self.driver.switch_to.frame(search_iframes[0])
                return True
            return self.auto_navigate_frames()
        except:
            return False

    def navigate_to_all_posts_iframe(self):
        """?ï¿½ì²´ê¸€ë³´ê¸° iframe?ï¿½ë¡œ ?ï¿½ë™"""
        try:
            all_post_iframes = self.driver.find_elements(By.CSS_SELECTOR, "iframe[src*='ArticleList'], iframe[name*='cafe_main']")
            if all_post_iframes:
                self.driver.switch_to.frame(all_post_iframes[0])
                return True
            return self.auto_navigate_frames()
        except:
            return False

    # =====================================================================
    # CRITICAL MISSING METHODS - Phase 2: ê³ ê¸‰ ê²€???ï¿½ìŠ¤???ï¿½ì‹¬ ë©”ì„œ?ï¿½ë“¤
    # =====================================================================

    def search_with_cafe_function(self, keyword, max_pages):
        """ì¹´í˜ ??ê²€??ê¸°ëŠ¥???ï¿½ìš©??ê³ ê¸‰ ê²€??""
        try:
            if not self.driver:
                return []
            print(f"  ?ï¿½ï¿½ ?ï¿½ì´ï¿½?ì¹´í˜ ê³ ê¸‰ ê²€??ê¸°ëŠ¥?ï¿½ë¡œ '{keyword}' ê²€??..")

            # 1. ì§ì ‘ ê²€??URL êµ¬ì„± ë°©ì‹ ?ï¿½ë„
            search_url_found = self.try_direct_search_url(keyword)
            if search_url_found:
                return self.collect_search_results(keyword, max_pages)

            # 2. ì¹´í˜ ??ê²€??ê¸°ëŠ¥ ?ï¿½ìš©
            if self.use_cafe_search_interface(keyword):
                return self.collect_search_results(keyword, max_pages)

            return []
        except Exception as e:
            print(f"  ??ì¹´í˜ ê²€??ê¸°ëŠ¥ ?ï¿½ë¥˜: {e}")
            return []

    def try_direct_search_url(self, keyword):
        """ì§ì ‘ ê²€??URL êµ¬ì„±"""
        try:
            club_id = self.get_cafe_club_id()
            if club_id:
                search_url = f"https://cafe.naver.com/ArticleSearchList.nhn?search.clubid={club_id}&search.query={keyword}"
                self.driver.get(search_url)
                self.safe_wait(self.driver, 2)
                return True
            return False
        except:
            return False

    def use_cafe_search_interface(self, keyword):
        """ì¹´í˜ ê²€???ï¿½í„°?ï¿½ì´???ï¿½ìš©"""
        try:
            search_selectors = ['.search-box input', '#search-input', '[name=\"query\"]', '.cafe-search input']
            for selector in search_selectors:
                try:
                    search_box = self.driver.find_element(By.CSS_SELECTOR, selector)
                    search_box.clear()
                    search_box.send_keys(keyword)
                    search_box.send_keys(Keys.RETURN)
                    self.safe_wait(self.driver, 2)
                    return True
                except:
                    continue
            return False
        except:
            return False

    def collect_search_results(self, keyword, max_pages):
        """ê²€??ê²°ê³¼ ?ï¿½ì§‘"""
        try:
            all_posts = []
            for page in range(max_pages):
                posts = self.extract_search_result_posts(keyword)
                if not posts:
                    break
                all_posts.extend(posts)
                if not self._go_to_next_page():
                    break
            return all_posts
        except:
            return []

    def get_cafe_club_id(self):
        """ì¹´í˜ Club ID ì¶”ì¶œ"""
        try:
            url = self.driver.current_url
            if 'cafe.naver.com' in url:
                # URL?ï¿½ì„œ ì¹´í˜ï¿½?ì¶”ì¶œ ??Club ID ì¡°íšŒ
                cafe_name = url.split('cafe.naver.com/')[-1].split('/')[0]
                return cafe_name
            return None
        except:
            return None

    def extract_search_result_posts(self, keyword=None):
        """ê²€??ê²°ê³¼?ï¿½ì„œ ê²Œì‹œê¸€ ì¶”ì¶œ"""
        try:
            return self._extract_posts_from_current_page()
        except:
            return []

    # =====================================================================
    # CRITICAL MISSING METHODS - Phase 3: ê²Œì‹œ???ï¿½ï¿½? ?ï¿½ìŠ¤??    # =====================================================================

    def get_all_boards(self):
        """ì¹´í˜??ëª¨ë“  ê²Œì‹œ??ëª©ë¡ ?ï¿½ë™ ë¶„ì„ ï¿½??ï¿½ì§‘"""
        boards = []
        try:
            print("  ?ï¿½ï¿½ ?ï¿½í˜?ï¿½ï¿½? êµ¬ì¡° ?ï¿½ë™ ë¶„ì„ ï¿½?..")

            # 1. ê¸°ë³¸ ê²Œì‹œ???ï¿½í„´ ê²€??            basic_boards = self.find_basic_board_patterns()
            boards.extend(basic_boards)

            # 2. ê³ ê¸‰ ?ï¿½í„´ ê²€??            advanced_boards = self.find_advanced_patterns()
            boards.extend(advanced_boards)

            # 3. ì¤‘ë³µ ?ï¿½ê±° ï¿½?ê²€ï¿½?            unique_boards = self.validate_board_list(boards)

            print(f"  ??ï¿½?{len(unique_boards)}ï¿½?ê²Œì‹œ??ë°œê²¬")
            return unique_boards

        except Exception as e:
            print(f"  ??ê²Œì‹œ??ë¶„ì„ ?ï¿½ë¥˜: {e}")
            return []

    def find_basic_board_patterns(self):
        """ê¸°ë³¸ ê²Œì‹œ???ï¿½í„´ ì°¾ê¸°"""
        boards = []
        try:
            basic_selectors = [
                'a[href*=\"menuType=1\"]',  # ê²Œì‹œ??ë©”ë‰´
                'a[href*=\"boardtype\"]',   # ê²Œì‹œ???ï¿½??                '.menu-list a', '.board-menu a',  # ë©”ë‰´ ë§í¬
                'nav a', '.navigation a'  # ?ï¿½ë¹„ê²Œì´??ë§í¬
            ]

            for selector in basic_selectors:
                try:
                    elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    for element in elements:
                        name = element.text.strip()
                        href = element.get_attribute('href')
                        if self.is_valid_board(name, href):
                            boards.append((name, href))
                except:
                    continue
            return boards
        except:
            return []

    def find_advanced_patterns(self):
        """ê³ ê¸‰ ê²Œì‹œ???ï¿½í„´ ì°¾ê¸°"""
        boards = []
        try:
            # ?ï¿½ìŠ¤??ê¸°ë°˜ ë§í¬ ê²€??            all_links = self.driver.find_elements(By.TAG_NAME, 'a')
            for link in all_links:
                try:
                    text = link.text.strip()
                    href = link.get_attribute('href')
                    # ê²Œì‹œ??ê´€???ï¿½ì›Œ???ï¿½í„°ï¿½?                    board_keywords = ['ê²Œì‹œ??, '?ï¿½ìœ ', '?ï¿½ë³´', 'ì§ˆë¬¸', '?ï¿½ê¸°', 'ê³µï¿½?', '?ï¿½ë²¤??]
                    if any(keyword in text for keyword in board_keywords) and self.is_valid_board(text, href):
                        boards.append((text, href))
                except:
                    continue
            return boards
        except:
            return []

    def is_valid_board(self, name, href):
        """?ï¿½íš¨??ê²Œì‹œ?ï¿½ì¸ì§€ ?ï¿½ì¸"""
        if not name or not href or len(name) < 2:
            return False
        if 'cafe.naver.com' not in href:
            return False
        if any(word in name.lower() for word in ['ë¡œê·¸??, 'login', '?ï¿½ì›ê°€??, '?ï¿½ì •']):
            return False
        return True

    def validate_board_list(self, boards):
        """ê²Œì‹œ??ëª©ë¡ ê²€ï¿½?ï¿½?ì¤‘ë³µ ?ï¿½ê±°"""
        try:
            unique_boards = []
            seen_urls = set()
            seen_names = set()

            for name, url in boards:
                if url not in seen_urls and name not in seen_names:
                    unique_boards.append({'name': name, 'url': url})
                    seen_urls.add(url)
                    seen_names.add(name)

            return unique_boards
        except:
            return []

    # =====================================================================
    # CRITICAL MISSING METHODS - Phase 5: ?ï¿½ì´ì§€ ?ï¿½ë¹„ê²Œì´???ï¿½ìŠ¤??    # =====================================================================

    def navigate_to_all_posts(self):
        """?ï¿½ì²´ê¸€ë³´ê¸° ?ï¿½ì´ì§€ï¿½??ï¿½ë™"""
        try:
            all_post_selectors = [
                'a[href*=\"ArticleList\"]',
                'a[title*=\"?ï¿½ì²´ê¸€\"]',
                'a[title*=\"?ï¿½ì²´\"]',
                '.all-posts', '.board-all'
            ]

            for selector in all_post_selectors:
                try:
                    element = self.driver.find_element(By.CSS_SELECTOR, selector)
                    element.click()
                    self.safe_wait(self.driver, 2)
                    self.auto_navigate_frames()
                    return True
                except:
                    continue
            return False
        except:
            return False

    def smart_page_navigation(self, target_type="all_posts"):
        """?ï¿½ë§ˆ???ï¿½ì´ì§€ ?ï¿½ë¹„ê²Œì´??""
        try:
            if target_type == "all_posts":
                return self.navigate_to_all_posts()
            return False
        except:
            return False

    def wait_for_dynamic_content(self):
        """?ï¿½ì  ì»¨í…ï¿½?ë¡œë”© ?ï¿½ï¿½?""
        try:
            # JavaScript ë¡œë”© ?ï¿½ë£Œ ?ï¿½ï¿½?            self.safe_wait(self.driver, 2)

            # jQuery ?ï¿½ë£Œ ?ï¿½ï¿½?(?ï¿½ëŠ” ê²½ìš°)
            try:
                WebDriverWait(self.driver, 3).until(
                    lambda driver: driver.execute_script("return jQuery.active == 0") if
                    driver.execute_script("return typeof jQuery !== 'undefined'") else True
                )
            except:
                pass

            return True
        except:
            return False

    def adaptive_delay(self):
        """?ï¿½ì‘???ï¿½ë ˆ??(?ï¿½ë²„ ë¶€??ê³ ë ¤)"""
        try:
            base_delay = 1.0  # ê¸°ë³¸ ?ï¿½ë ˆ??
            # ?ï¿½ì´ì§€ ë¡œë”© ?ï¿½ê°„ ì¸¡ì •
            start_time = time.time()
            self.wait_for_page_load()
            load_time = time.time() - start_time

            # ë¡œë”© ?ï¿½ê°„???ï¿½ë¥¸ ?ï¿½ì‘???ï¿½ë ˆ??            if load_time > 3:
                # ë¡œë”©???ï¿½ë˜ ê±¸ë¦¬ï¿½???ï¿½??ï¿½ë ˆ??                delay = base_delay * 1.5
            elif load_time < 1:
                # ë¡œë”©??ë¹ ë¥´ï¿½?ê¸°ë³¸ ?ï¿½ë ˆ??                delay = base_delay
            else:
                # ì¤‘ê°„ ?ï¿½ë„ï¿½??ï¿½ê°„ ï¿½??ï¿½ë ˆ??                delay = base_delay * 1.2

            time.sleep(delay)

        except Exception as e:
            # ?ï¿½ë¥˜ ??ê¸°ë³¸ ?ï¿½ë ˆ??            time.sleep(1.0)

    def safe_find_elements(self, by, value):
        """?ï¿½ì „???ï¿½ì†Œ ì°¾ê¸°"""
        try:
            return self.driver.find_elements(by, value)
        except:
            return []

    def safe_get_page_source(self):
        """?ï¿½ì „???ï¿½ì´ì§€ ?ï¿½ìŠ¤ ê°€?ï¿½ì˜¤ï¿½?""
        try:
            return self.driver.page_source
        except:
            return ""

    def safe_get_current_url(self):
        """?ï¿½ì „???ï¿½ì¬ URL ê°€?ï¿½ì˜¤ï¿½?""
        try:
            return self.driver.current_url
        except:
            return ""

    def safe_get_title(self):
        """?ï¿½ì „???ï¿½ì´ì§€ ?ï¿½ëª© ê°€?ï¿½ì˜¤ï¿½?""
        try:
            return self.driver.title
        except:
            return ""

    def safe_driver_get(self, url):
        """?ï¿½ì „???ï¿½ì´ì§€ ?ï¿½ë™"""
        try:
            self.driver.get(url)
            return True
        except:
            return False

    def safe_execute_script(self, script):
        """?ï¿½ì „???ï¿½í¬ë¦½íŠ¸ ?ï¿½í–‰"""
        try:
            return self.driver.execute_script(script)
        except:
            return None

    # =====================================================================
    # Phase 7A: ì¹´í˜ êµ¬ì¡° ë¶„ì„ ï¿½?ê¸°ë³¸ ?ï¿½ë¹„ê²Œì´??ë©”ì„œ??    # =====================================================================

    def analyze_cafe_structure(self):
        """ì¹´í˜ ?ï¿½ì´ì§€ êµ¬ì¡° ?ï¿½ë™ ë¶„ì„"""
        structure_info = {}
        try:
            if not self.driver:
                return {}

            print("  ?ï¿½ï¿½ ?ï¿½ì´ì§€ êµ¬ì¡° ë¶„ì„ ì¤‘ï¿½?)
            structure_info["title"] = self.driver.title
            structure_info["url"] = self.driver.current_url
            structure_info["has_frames"] = bool(self.driver.find_elements(By.TAG_NAME, "iframe"))

            # ë©”ë‰´ êµ¬ì¡° ë¶„ì„
            menu_patterns = [
                (".cafe-menu", "ì¹´í˜ ë©”ë‰´"),
                (".board-list", "ê²Œì‹œ??ëª©ë¡"),
                (".left-menu", "?ï¿½ìª½ ë©”ë‰´"),
                (".nav-menu", "?ï¿½ë¹„ê²Œì´??ë©”ë‰´"),
                (".sidebar", "?ï¿½ì´?ï¿½ë°”"),
                ("#menuList", "ë©”ë‰´ ë¦¬ìŠ¤??),
            ]
            structure_info["menus"] = []
            for selector, name in menu_patterns:
                try:
                    elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    if elements:
                        structure_info["menus"].append({"name": name, "selector": selector, "count": len(elements)})
                        print(f"    ?ï¿½ï¿½ {name} ë°œê²¬: {len(elements)}ï¿½?)
                except Exception:
                    continue

            # ì»¨í…ï¿½??ï¿½ì—­ ë¶„ì„
            content_patterns = [
                (".content", "ë©”ì¸ ì»¨í…ï¿½?),
                (".article-board", "ê²Œì‹œ??),
                (".post-list", "ê²Œì‹œê¸€ ëª©ë¡"),
                (".board-content", "ê²Œì‹œ??ì»¨í…ï¿½?),
            ]
            structure_info["content_areas"] = []
            for selector, name in content_patterns:
                try:
                    elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    if elements:
                        structure_info["content_areas"].append({"name": name, "selector": selector, "count": len(elements)})
                except Exception:
                    continue
            print(
                f"    ??êµ¬ì¡° ë¶„ì„ ?ï¿½ë£Œ: {len(structure_info['menus'])}ï¿½?ë©”ë‰´, "
                f"{len(structure_info['content_areas'])}ï¿½?ì»¨í…ï¿½??ï¿½ì—­"
            )
            return structure_info
        except Exception as e:
            print(f"    ?ï¿½ï¸ êµ¬ì¡° ë¶„ì„ ?ï¿½ë¥˜: {e}")
            return structure_info

    def optimize_view_mode(self):
        """ìµœì ??ë³´ê¸° ëª¨ë“œï¿½??ï¿½í™˜"""
        try:
            print("      ?ï¿½ï¿½ ìµœì  ë³´ê¸° ëª¨ë“œ ?ï¿½ì • ï¿½?..")

            # ë¦¬ìŠ¤??ë³´ê¸°ï¿½??ï¿½í™˜ (???ï¿½íƒœê°€ ?ï¿½ë¡¤ë§í•˜ï¿½?ì¢‹ìŒ)
            list_view_selectors = [
                ".list-view", ".table-view", ".board-view",
                "a[href*='listStyle=list']",
                "button[data-view='list']"
            ]

            for selector in list_view_selectors:
                try:
                    view_btn = self.driver.find_element(By.CSS_SELECTOR, selector)
                    if view_btn.is_displayed():
                        view_btn.click()
                        time.sleep(1)
                        print(f"        ??ë¦¬ìŠ¤??ë³´ê¸°ï¿½??ï¿½í™˜: {selector}")
                        break
                except:
                    continue

            # ?ï¿½ì´ì§€???ï¿½ì‹œ ê°œìˆ˜ ìµœï¿½???            items_per_page_selectors = [
                "select[name='listStyle']",
                ".items-per-page select",
                "select[name='pageSize']"
            ]

            for selector in items_per_page_selectors:
                try:
                    select_element = self.driver.find_element(By.CSS_SELECTOR, selector)
                    # ê°€????ï¿½??ï¿½íƒ (ë³´í†µ 50 ?ï¿½ëŠ” 100)
                    from selenium.webdriver.support.ui import Select
                    select = Select(select_element)

                    # ?ï¿½ì…˜ ï¿½?ê°€?????ï¿½ì ì°¾ê¸°
                    options = select.options
                    max_value = 0
                    max_option = None

                    for option in options:
                        try:
                            value = int(option.get_attribute('value'))
                            if value > max_value:
                                max_value = value
                                max_option = option
                        except:
                            continue

                    if max_option:
                        select.select_by_value(str(max_value))
                        print(f"        ???ï¿½ì´ì§€???ï¿½ì‹œ ê°œìˆ˜: {max_value}ê°œë¡œ ?ï¿½ì •")
                        time.sleep(2)
                        break

                except:
                    pass

        except Exception as e:
            print(f"      ?ï¿½ï¸ ë³´ê¸° ëª¨ë“œ ìµœì ???ï¿½ë¥˜: {e}")

    def wait_for_page_load(self):
        """?ï¿½ì´ì§€ ë¡œë”© ?ï¿½ë£Œ ?ï¿½ï¿½?(?ï¿½ìƒ??ë²„ì „)"""
        try:
            # 1. ê¸°ë³¸ ë¡œë”© ?ï¿½ï¿½?            time.sleep(1)

            # 2. JavaScript ?ï¿½í–‰ ?ï¿½ë£Œ ?ï¿½ï¿½?            try:
                WebDriverWait(self.driver, 5).until(
                    lambda driver: driver.execute_script("return document.readyState") == "complete"
                )
            except:
                pass

            # 3. Ajax ?ï¿½ì²­ ?ï¿½ë£Œ ?ï¿½ï¿½?(jQueryê°€ ?ï¿½ëŠ” ê²½ìš°)
            try:
                WebDriverWait(self.driver, 3).until(
                    lambda driver: driver.execute_script("return jQuery.active == 0") if
                    driver.execute_script("return typeof jQuery !== 'undefined'") else True
                )
            except:
                pass

            # 4. ?ï¿½ì • ë¡œë”© ?ï¿½ì†Œ?ï¿½ì´ ?ï¿½ë¼ï¿½??ï¿½ê¹Œì§€ ?ï¿½ï¿½?            loading_indicators = [
                '.loading', '.spinner', '.ajax-loading',
                '[style*="loading"]', '.progress-bar'
            ]

            for indicator in loading_indicators:
                try:
                    WebDriverWait(self.driver, 2).until_not(
                        EC.presence_of_element_located((By.CSS_SELECTOR, indicator))
                    )
                except:
                    continue

        except Exception as e:
            pass  # ë¡œë”© ?ï¿½ï¿½??ï¿½ë¥˜??ë¬´ì‹œ?ï¿½ê³  ì§„í–‰

    def smart_next_page(self):
        """?ï¿½ë§ˆ???ï¿½ìŒ ?ï¿½ì´ì§€ ?ï¿½ë™"""
        try:
            # ?ï¿½ì–‘??"?ï¿½ìŒ ?ï¿½ì´ì§€" ?ï¿½í„´??            next_patterns = [
                # ?ï¿½ë°˜?ï¿½ì¸ ?ï¿½í„´
                ".next", ".page-next", ".btn-next",
                "a[title*='?ï¿½ìŒ']", "a[title*='next']",

                # ?ï¿½ìŠ¤??ê¸°ë°˜
                "//a[contains(text(), '?ï¿½ìŒ')]",
                "//a[contains(text(), 'next')]",
                "//a[contains(text(), '>')]",

                # ?ï¿½ì´ì§€ ë²ˆí˜¸ ê¸°ë°˜ (?ï¿½ì¬ ?ï¿½ì´ì§€ + 1)
                ".pagination a", ".paging a", ".page-link"
            ]

            # 1. ì§ì ‘?ï¿½ì¸ "?ï¿½ìŒ" ë²„íŠ¼ ì°¾ê¸°
            for pattern in next_patterns[:5]:  # ì²˜ìŒ 5ï¿½??ï¿½í„´ï¿½??ï¿½ë„
                try:
                    if pattern.startswith("//"):
                        elements = self.driver.find_elements(By.XPATH, pattern)
                    else:
                        elements = self.driver.find_elements(By.CSS_SELECTOR, pattern)

                    for element in elements:
                        if element.is_displayed() and element.is_enabled():
                            # ?ï¿½ë¦­ ê°€?ï¿½í•œì§€ ?ï¿½ì¸
                            if 'disabled' not in element.get_attribute('class').lower():
                                element.click()
                                print(f"        ?ï¿½ï¸ ?ï¿½ìŒ ?ï¿½ì´ì§€ ?ï¿½ë™ ?ï¿½ê³µ: {pattern}")
                                time.sleep(2)
                                return True
                except:
                    continue

            # 2. ?ï¿½ì´ì§€ ë²ˆí˜¸ï¿½??ï¿½ë™ ?ï¿½ë„
            try:
                # ?ï¿½ì¬ ?ï¿½ì„± ?ï¿½ì´ì§€ ì°¾ê¸°
                active_selectors = [
                    ".current", ".active", ".selected",
                    ".page-current", ".page-active"
                ]

                current_page = None
                for selector in active_selectors:
                    try:
                        element = self.driver.find_element(By.CSS_SELECTOR, selector)
                        current_page = int(element.text)
                        break
                    except:
                        continue

                if current_page:
                    # ?ï¿½ìŒ ?ï¿½ì´ì§€ ë²ˆí˜¸ ?ï¿½ë¦­ ?ï¿½ë„
                    next_page = current_page + 1
                    page_selectors = [
                        f"a[href*='page={next_page}']",
                        f"//a[text()='{next_page}']",
                        f".pagination a:contains('{next_page}')"
                    ]

                    for selector in page_selectors:
                        try:
                            if selector.startswith("//"):
                                element = self.driver.find_element(By.XPATH, selector)
                            else:
                                element = self.driver.find_element(By.CSS_SELECTOR, selector)

                            if element.is_displayed():
                                element.click()
                                print(f"        ?ï¿½ï¸ ?ï¿½ì´ì§€ {next_page}ï¿½??ï¿½ë™ ?ï¿½ê³µ")
                                time.sleep(2)
                                return True
                        except:
                            pass
            except:
                pass

            print("        ?ï¿½ï¸ ?ï¿½ìŒ ?ï¿½ì´ì§€ï¿½?ì°¾ì„ ???ï¿½ìŒ")
            return False

        except Exception as e:
            print(f"        ???ï¿½ìŒ ?ï¿½ì´ì§€ ?ï¿½ë™ ?ï¿½ë¥˜: {e}")
            return False

    def go_to_next_page(self):
        """?ï¿½ìŒ ?ï¿½ì´ì§€ï¿½??ï¿½ë™"""
        try:
            return self.smart_next_page()
        except Exception as e:
            print(f"?ï¿½ìŒ ?ï¿½ì´ì§€ ?ï¿½ë™ ?ï¿½íŒ¨: {e}")
            return False

    # =====================================================================
    # Phase 7C: ê²Œì‹œê¸€ ?ï¿½ì„¸ ?ï¿½ë³´ ì¶”ì¶œ ë©”ì„œ??(7ï¿½?
    # =====================================================================

    def extract_title_and_url(self, element):
        """?ï¿½ëª©ï¿½?URL ì¶”ì¶œ"""
        if not element:
            return None

        title_patterns = [
            # ?ï¿½ë°˜?ï¿½ì¸ ?ï¿½í„´
            ".article a", ".title a", ".subject a",
            "a[href*='read']", "a[href*='article']",

            # ?ï¿½ì´ï¿½?ê¸°ë°˜
            "td a", ".td_article a", ".td_subject a",

            # div ê¸°ë°˜
            ".post-title a", ".board-title a",

            # ?ï¿½ìˆœ ?ï¿½í„´
            "a"
        ]

        for pattern in title_patterns:
            try:
                title_element = element.find_element(By.CSS_SELECTOR, pattern)
                title = clean_text(title_element.text)
                url = title_element.get_attribute("href")

                # ?ï¿½íš¨???ï¿½ëª©ï¿½?URL?ï¿½ï¿½? ?ï¿½ì¸
                if title and url and len(title.strip()) > 0:
                    if 'read' in url or 'article' in url or 'cafe.naver.com' in url:
                        return {'title': title, 'url': url}

            except Exception:
                continue

        return None

    def extract_author(self, element):
        """?ï¿½ì„±??ì¶”ì¶œ"""
        if not element:
            return "?????ï¿½ìŒ"

        author_patterns = [
            ".p-nick a", ".author a", ".writer a",
            ".td_name a", ".name a", ".nickname a",
            "td:nth-child(3) a", "td:nth-child(4) a"
        ]

        for pattern in author_patterns:
            try:
                author_element = element.find_element(By.CSS_SELECTOR, pattern)
                author = clean_text(author_element.text)
                if author and len(author.strip()) > 0:
                    return author
            except Exception:
                continue

        return "?????ï¿½ìŒ"

    def extract_date(self, element):
        """?ï¿½ì„±??ì¶”ì¶œ"""
        if not element:
            return "?????ï¿½ìŒ"

        date_patterns = [
            ".td_date", ".date", ".time", ".created",
            "td:last-child", "td:nth-last-child(2)",
            "td:nth-child(5)", "td:nth-child(6)"
        ]

        for pattern in date_patterns:
            try:
                date_element = element.find_element(By.CSS_SELECTOR, pattern)
                date = clean_text(date_element.text)
                if date and len(date.strip()) > 0:
                    # ?ï¿½ì§œ ?ï¿½ì‹?ï¿½ï¿½? ê°„ë‹¨???ï¿½ì¸
                    if any(char.isdigit() for char in date):
                        return date
            except Exception:
                continue

        return "?????ï¿½ìŒ"

    def extract_views(self, element):
        """ì¡°íšŒ??ì¶”ì¶œ"""
        if not element:
            return "0"

        view_patterns = [
            ".td_view", ".view", ".views", ".hit",
            "td:nth-last-child(1)", "td:nth-last-child(2)"
        ]

        for pattern in view_patterns:
            try:
                view_element = element.find_element(By.CSS_SELECTOR, pattern)
                views = clean_text(view_element.text)
                if views and views.isdigit():
                    return views
            except Exception:
                continue

        return "0"

    def extract_likes(self, element):
        """ì¶”ì²œ??ì¶”ì¶œ"""
        if not element:
            return "0"

        like_patterns = [
            ".td_good", ".like", ".likes", ".recommend",
            ".good", ".thumb"
        ]

        for pattern in like_patterns:
            try:
                like_element = element.find_element(By.CSS_SELECTOR, pattern)
                likes = clean_text(like_element.text)
                if likes and likes.isdigit():
                    return likes
            except Exception:
                continue

        return "0"

    def debug_page_structure(self):
        """?ï¿½ì´ì§€ êµ¬ì¡° ?ï¿½ë²„ï¿½?""
        try:
            print("      ?ï¿½ï¿½ ?ï¿½ì´ì§€ êµ¬ì¡° ?ï¿½ë²„ï¿½?ï¿½?..")

            # ?ï¿½ì¬ URLï¿½??ï¿½ëª©
            current_url = self.safe_get_current_url()
            page_title = self.safe_get_title()
            print(f"        URL: {current_url}")
            print(f"        ?ï¿½ëª©: {page_title}")

            # ì£¼ìš” ?ï¿½ì†Œ??ê°œìˆ˜ ?ï¿½ì¸
            elements_info = {
                "?ï¿½ì´ï¿½?: len(self.safe_find_elements(By.TAG_NAME, "table")),
                "??tr)": len(self.safe_find_elements(By.TAG_NAME, "tr")),
                "ë§í¬(a)": len(self.safe_find_elements(By.TAG_NAME, "a")),
                "ë¦¬ìŠ¤??li)": len(self.safe_find_elements(By.TAG_NAME, "li")),
                "div": len(self.safe_find_elements(By.TAG_NAME, "div"))
            }

            for name, count in elements_info.items():
                print(f"        {name}: {count}ï¿½?)

            # ë§í¬ ?ï¿½í”Œ ?ï¿½ì¸
            links = self.safe_find_elements(By.CSS_SELECTOR, "a[href]")[:10]
            print(f"        ë§í¬ ?ï¿½í”Œ (ì²˜ìŒ 10ï¿½?:")
            for i, link in enumerate(links):
                try:
                    text = link.text.strip()[:30] if link.text else "(?ï¿½ìŠ¤???ï¿½ìŒ)"
                    href = link.get_attribute("href")[:50] if link.get_attribute("href") else "(href ?ï¿½ìŒ)"
                    print(f"          {i+1}. {text} -> {href}")
                except Exception:
                    print(f"          {i+1}. (?ï¿½ë¥˜)")

        except Exception as e:
            print(f"        ???ï¿½ë²„ï¿½??ï¿½ë¥˜: {e}")

    def save_to_excel(self, filename=None):
        """CafeDataExporterï¿½??ï¿½ì„?ï¿½ì—¬ ?ï¿½ï¿½? ?ï¿½??""
        try:
            if hasattr(self, 'posts_data') and self.posts_data:
                return CafeDataExporter.save_all(self.posts_data, filename)
            else:
                print("?ï¿½ï¸ ?ï¿½?ï¿½í•  ?ï¿½ì´?ï¿½ï¿½? ?ï¿½ìŠµ?ï¿½ë‹¤.")
                return False
        except Exception as e:
            print(f"???ï¿½ï¿½? ?ï¿½???ï¿½ë¥˜: {e}")
            return False

    # =====================================================================
    # Phase 7D: ê²€??ï¿½??ï¿½ì›Œ??ì²˜ë¦¬ ë©”ì„œ??(10ï¿½?
    # =====================================================================

    def check_keyword_match(self, title, content, keyword):
        """?ï¿½ì›Œ??ë§¤ì¹­ ?ï¿½ì¸ (?ï¿½ìƒ??ë²„ì „)"""
        try:
            if not keyword or not title:
                return False

            # ?ï¿½ìŠ¤???ï¿½ê·œ??            title_clean = clean_text(title).lower()
            keyword_clean = keyword.lower().strip()

            # ?ï¿½ë²„ï¿½??ï¿½ë³´ (ê°€?ï¿½ì”©ï¿½?ì¶œë ¥)
            if random.randint(1, 10) == 1:  # 10% ?ï¿½ë¥ ï¿½??ï¿½ë²„ï¿½?ì¶œë ¥
                print(f"        ?ï¿½ï¿½ ?ï¿½ì›Œ??ë§¤ì¹­ ?ï¿½ë²„ï¿½?")
                print(f"          ?ï¿½ëª©: '{title_clean[:50]}...'")
                print(f"          ?ï¿½ì›Œ?? '{keyword_clean}'")

            # 1. ?ï¿½í™•???ï¿½ì›Œ??ë§¤ì¹­
            if keyword_clean in title_clean:
                return True

            # 2. ë¶€ï¿½?ë§¤ì¹­ (ê³µë°± ?ï¿½ê±°)
            title_no_space = title_clean.replace(" ", "")
            keyword_no_space = keyword_clean.replace(" ", "")
            if keyword_no_space in title_no_space:
                return True

            # 3. ?ï¿½ì›Œ??ë³€???ï¿½ì¸
            if hasattr(Config, 'KEYWORD_VARIATIONS') and Config.KEYWORD_VARIATIONS:
                variations = self.get_keyword_variations(keyword)
                for variation in variations:
                    variation_clean = variation.lower()
                    if variation_clean in title_clean:
                        return True

            # 4. ?ï¿½ìš©?ï¿½ì„œ???ï¿½ì¸ (?ï¿½ëŠ” ê²½ìš°)
            if content:
                content_clean = clean_text(content).lower()
                if keyword_clean in content_clean:
                    return True

            return False

        except Exception as e:
            print(f"        ???ï¿½ì›Œ??ë§¤ì¹­ ?ï¿½ë¥˜: {e}")
            return False

    def get_keyword_variations(self, keyword):
        """?ï¿½ì›Œ??ë³€??ï¿½??ï¿½ì–´ ?ï¿½ì„±"""
        variations = []

        try:
            # ê¸°ë³¸ ë³€??            variations.append(keyword)
            variations.append(keyword.replace(' ', ''))

            # ê³µê¸°??ê´€???ï¿½ì–´ ï¿½?ë³€??            keyword_mappings = {
                '?ï¿½êµ­?ï¿½ë ¥ê³µì‚¬': ['?ï¿½ì „', 'kepco', '?ï¿½ë ¥ê³µì‚¬'],
                '?ï¿½êµ­?ï¿½ì?ï¿½ê³µ??: ['k-water', 'kwater', '?ï¿½ì?ï¿½ê³µ??],
                '?ï¿½êµ­?ï¿½ï¿½?ì£¼íƒê³µì‚¬': ['lhê³µì‚¬', 'lh', '?ï¿½ï¿½?ì£¼íƒê³µì‚¬'],
                '?ï¿½ì²œï¿½?ï¿½ï¿½ê³µí•­ê³µì‚¬': ['ê³µí•­ê³µì‚¬', '?ï¿½ì²œê³µí•­'],
                '?ï¿½êµ­ê°€?ï¿½ê³µ??: ['ê°€?ï¿½ê³µ??, 'kogas'],
                '?ï¿½êµ­?ï¿½ìœ ê³µì‚¬': ['?ï¿½ìœ ê³µì‚¬', 'knoc'],
                '?ï¿½êµ­ê´‘ë¬¼?ï¿½ì›ê³µì‚¬': ['kores', 'ê´‘ë¬¼?ï¿½ì›ê³µì‚¬'],
                '?ï¿½êµ­ì² ë„ê³µì‚¬': ['ì½”ë ˆ??, 'korail', 'ì² ë„ê³µì‚¬'],
                '?ï¿½êµ­?ï¿½ë¡œê³µì‚¬': ['?ï¿½ë¡œê³µì‚¬'],
                'ê³µê¸°??: ['ê³µê³µê¸°ï¿½?', 'ì¤€?ï¿½ï¿½?ê¸°ï¿½?'],
                'ncs': ['ï¿½??ì§ë¬´?ï¿½ë ¥?ï¿½ï¿½?'],
                'ë©´ì ‘': ['ë©´ì ‘?ï¿½ê¸°', 'ë©´ì ‘ê²½í—˜'],
                '?ï¿½ê²©': ['?ï¿½ê²©?ï¿½ê¸°', '?ï¿½ê²©?ï¿½ê¸°'],
                'ì±„ìš©': ['ì±„ìš©ê³µê³ ', 'ì±„ìš©?ï¿½ë³´'],
                '?ï¿½ì†Œ??: ['?ï¿½ê¸°?ï¿½ê°œ??],
                '?ï¿½ê¸°': ['?ï¿½ê¸°?ï¿½í—˜', '?ï¿½ê¸°ì¤€ï¿½?]
            }

            # ?ï¿½ì›Œ??ë§¤í•‘ ?ï¿½ì¸
            keyword_lower = keyword.lower()
            for main_keyword, aliases in keyword_mappings.items():
                if keyword_lower in main_keyword.lower() or main_keyword.lower() in keyword_lower:
                    variations.extend(aliases)
                    variations.append(main_keyword.lower())

                for alias in aliases:
                    if keyword_lower in alias.lower() or alias.lower() in keyword_lower:
                        variations.append(main_keyword.lower())
                        variations.extend([a for a in aliases if a != alias])

            # ì¤‘ë³µ ?ï¿½ê±°
            variations = list(set(variations))

        except Exception as e:
            print(f"        ?ï¿½ì›Œ??ë³€???ï¿½ì„± ?ï¿½ë¥˜: {e}")

        return variations

    def crawl_cafe(self, cafe_url, keywords=None):
        """ë©”ì¸ ?ï¿½ë¡¤ï¿½?ë¡œì§ (1000ï¿½?ê²Œì‹œê¸€ ?ï¿½ì§‘, ?ï¿½ìš© ï¿½??ï¿½ï¿½? ?ï¿½í•¨)"""
        print(f"\n?ï¿½ï¿½ ?ï¿½ì´ï¿½?ì¹´í˜ ê³ ê¸‰ ?ï¿½ë¡¤ï¿½??ï¿½ì‘!")
        print(f"?ï¿½ï¿½ ?ï¿½??ì¹´í˜: {cafe_url}")
        print(f"?ï¿½ï¿½ ?ï¿½ì§‘ ?ï¿½ì›Œ?? {keywords}")
        print(f"?ï¿½ï¿½ ëª©í‘œ ?ï¿½ì§‘?? ìµœï¿½? {Config.MAX_TOTAL_POSTS}ï¿½?ê²Œì‹œê¸€")
        print(f"?ï¿½ï¿½ ?ï¿½ìš© ?ï¿½ì§‘: {'ON' if Config.EXTRACT_FULL_CONTENT else 'OFF'}")
        print(f"?ï¿½ï¿½ ?ï¿½ï¿½? ?ï¿½ì§‘: {'ON' if Config.EXTRACT_COMMENTS else 'OFF'}")
        print("=" * 70)

        all_posts = []
        total_collected = 0

        try:
            print(f"?ï¿½ï¿½ ì¹´í˜ ?ï¿½ì† ï¿½?..")
            self.safe_driver_get(cafe_url)
            safe_wait(self.driver, 3)

            # ë¡œê·¸???ï¿½ì¸
            if not self.driver:
                print("???ï¿½ë¼?ï¿½ë²„ê°€ ì´ˆê¸°?ï¿½ë˜ì§€ ?ï¿½ì•˜?ï¿½ë‹ˆ??")
                return []

            # ?ï¿½ì›Œ?ï¿½ë³„ ê²€???ï¿½í–‰
            if keywords:
                for i, keyword in enumerate(keywords, 1):
                    print(f"\n?ï¿½ï¿½ ?ï¿½ì›Œ??{i}/{len(keywords)}: '{keyword}' ê²€???ï¿½ì‘")
                    print("-" * 50)

                    # ?ï¿½ì›Œ??ê²€??ê²Œì‹œê¸€ ?ï¿½ì§‘
                    keyword_posts = self.search_and_collect_posts(keyword)

                    if keyword_posts:
                        print(f"??'{keyword}' ê²€??ê²°ê³¼: {len(keyword_posts)}ï¿½?ê²Œì‹œê¸€ ?ï¿½ì§‘")
                        all_posts.extend(keyword_posts)
                        total_collected += len(keyword_posts)

                        # ëª©í‘œ ?ï¿½ì§‘???ï¿½ë‹¬ ?ï¿½ì¸
                        if total_collected >= Config.MAX_TOTAL_POSTS:
                            print(f"?ï¿½ï¿½ ëª©í‘œ ?ï¿½ì§‘??{Config.MAX_TOTAL_POSTS}ï¿½??ï¿½ì„±!")
                            break
                    else:
                        print(f"?ï¿½ï¸ '{keyword}' ê²€??ê²°ê³¼ ?ï¿½ìŒ")
            else:
                # ?ï¿½ì›Œ???ï¿½ì´ ?ï¿½ì²´ ìµœì‹  ê²Œì‹œê¸€ ?ï¿½ì§‘
                print(f"?ï¿½ï¿½ ?ï¿½ì²´ ìµœì‹  ê²Œì‹œê¸€ ?ï¿½ì§‘ ëª¨ë“œ")
                all_posts = self.collect_recent_posts()
                total_collected = len(all_posts)

            print(f"\n?ï¿½ï¿½ ìµœì¢… ?ï¿½ì§‘ ê²°ê³¼:")
            print(f"   ?ï¿½ï¿½ ï¿½?ê²Œì‹œê¸€ ?? {total_collected}ï¿½?)
            print(f"   ?ï¿½ï¿½ ?ï¿½ìš© ?ï¿½í•¨: {sum(1 for post in all_posts if post.get('full_content'))}")
            print(f"   ?ï¿½ï¿½ ?ï¿½ï¿½? ?ï¿½í•¨: {sum(1 for post in all_posts if post.get('comments'))}")
            print(f"   ?ï¿½ï¿½ï¿½??ï¿½ï¿½?ì§€ ?ï¿½í•¨: {sum(len(post.get('images', [])) for post in all_posts)}")

            # ?ï¿½ì§‘???ï¿½ì´???ï¿½??            self.posts_data = all_posts

            return all_posts

        except Exception as e:
            print(f"???ï¿½ë¡¤ï¿½?ï¿½??ï¿½ë¥˜ ë°œìƒ: {e}")
            return all_posts

    def search_and_collect_posts(self, keyword):
        """?ï¿½ì›Œ?ï¿½ë¡œ ê²€?ï¿½í•˜??ê²Œì‹œê¸€ ?ï¿½ì§‘ (ê³ ê¸‰ ?ï¿½ì¤‘ ê²€???ï¿½ìš©)"""
        try:
            print(f"?ï¿½ï¿½ ê³ ê¸‰ ê²€???ï¿½ì‘: '{keyword}'")

            # ê³ ê¸‰ ?ï¿½ì¤‘ ê²€???ï¿½ëµ ?ï¿½ìš©
            if hasattr(Config, 'MULTI_SCOPE_SEARCH') and Config.MULTI_SCOPE_SEARCH:
                print("    ?? ê³ ê¸‰ ?ï¿½ì¤‘ ê²€??ëª¨ë“œ ?ï¿½ì„±??")
                posts, metadata = self.advanced_multi_search(keyword)

                if posts:
                    print(f"    ?ï¿½ï¿½ ê³ ê¸‰ ê²€???ï¿½ê³µ: {len(posts)}ï¿½?ê²Œì‹œê¸€ ?ï¿½ì§‘")
                    print(f"    ?ï¿½ï¿½ ?ï¿½ìš©???ï¿½ëµ: {', '.join(metadata.get('strategies_used', []))}")

                    # ?ï¿½ì„¸ ?ï¿½ë³´ ?ï¿½ì§‘ (?ï¿½ìš© ï¿½??ï¿½ï¿½?)
                    if Config.EXTRACT_FULL_CONTENT or Config.EXTRACT_COMMENTS:
                        enhanced_posts = self.enhance_posts_with_details(posts, keyword)
                        return enhanced_posts
                    else:
                        # ê¸°ë³¸ ?ï¿½ë³´??ë©”ï¿½??ï¿½ì´??ì¶”ï¿½?
                        from datetime import datetime
                        for post in posts:
                            post['keyword'] = keyword
                            post['collection_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                            post['search_metadata'] = metadata

                        return posts[:Config.MAX_TOTAL_POSTS]

                else:
                    print(f"    ?ï¿½ï¸ ê³ ê¸‰ ê²€??ê²°ê³¼ ?ï¿½ìŒ - ê¸°ë³¸ ê²€?ï¿½ìœ¼ï¿½??ï¿½í™˜")
                    return self.fallback_basic_search(keyword)

            else:
                # ê¸°ë³¸ ê²€??ë°©ì‹ ?ï¿½ìš©
                print(f"    ?ï¿½ï¿½ ê¸°ë³¸ ê²€??ëª¨ë“œ")
                return self.fallback_basic_search(keyword)

        except Exception as e:
            print(f"    ???ï¿½ì›Œ??ê²€??ï¿½??ï¿½ë¥˜: {e}")
            return self.fallback_basic_search(keyword)

    def enhance_posts_with_details(self, posts, keyword):
        """ê²Œì‹œê¸€ ?ï¿½ì„¸ ?ï¿½ë³´ ê°•í™” (?ï¿½ìš©, ?ï¿½ï¿½?, ?ï¿½ï¿½?ì§€ ??"""
        try:
            print(f"    ?ï¿½ï¿½ ?ï¿½ì„¸ ?ï¿½ë³´ ?ï¿½ì§‘ ï¿½?.. (ï¿½?{len(posts)}ï¿½?")
            enhanced_posts = []

            for i, post in enumerate(posts[:Config.MAX_TOTAL_POSTS], 1):
                try:
                    print(f"      ?ï¿½ï¿½ ê²Œì‹œê¸€ {i}/{min(len(posts), Config.MAX_TOTAL_POSTS)} ì²˜ë¦¬ ï¿½?..")

                    # ?ï¿½ì„¸ ?ï¿½ìš© ?ï¿½ì§‘
                    if Config.EXTRACT_FULL_CONTENT or Config.EXTRACT_COMMENTS:
                        post_url = post.get('url', '')
                        if post_url:
                            detail_data = self.get_post_content(post_url)

                            # ?ï¿½ì„¸ ?ï¿½ë³´ ?ï¿½í•©
                            if detail_data.get('content'):
                                post['full_content'] = detail_data['content']

                            if detail_data.get('comments'):
                                post['comments'] = detail_data['comments']
                                post['comment_count'] = len(detail_data['comments'])

                            if detail_data.get('images'):
                                post['images'] = detail_data['images']

                            if detail_data.get('attachments'):
                                post['attachments'] = detail_data['attachments']

                    # ì¶”ï¿½? ë©”ï¿½??ï¿½ì´??                    from datetime import datetime
                    post['keyword'] = keyword
                    post['collection_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                    post['enhanced'] = True

                    enhanced_posts.append(post)

                    # ì§„í–‰ï¿½??ï¿½ì‹œ
                    if i % 10 == 0:
                        print(f"      ?ï¿½ï¿½ ì§„í–‰ï¿½? {i}/{min(len(posts), Config.MAX_TOTAL_POSTS)} ({i/min(len(posts), Config.MAX_TOTAL_POSTS)*100:.1f}%)")

                except Exception as e:
                    print(f"      ??ê²Œì‹œê¸€ {i} ì²˜ë¦¬ ?ï¿½ë¥˜: {e}")
                    # ê¸°ë³¸ ?ï¿½ë³´?ï¿½ë„ ?ï¿½ï¿½?
                    from datetime import datetime
                    post['keyword'] = keyword
                    post['collection_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                    post['enhanced'] = False
                    enhanced_posts.append(post)
                    continue

            print(f"    ???ï¿½ì„¸ ?ï¿½ë³´ ?ï¿½ì§‘ ?ï¿½ë£Œ: {len(enhanced_posts)}ï¿½?)
            return enhanced_posts

        except Exception as e:
            print(f"    ???ï¿½ì„¸ ?ï¿½ë³´ ?ï¿½ì§‘ ?ï¿½ë¥˜: {e}")
            return posts

    def fallback_basic_search(self, keyword):
        """ê¸°ë³¸ ê²€??ë°©ì‹ (ë°±ì—…?? - ?ï¿½ì„¸ ?ï¿½ë³´ ?ï¿½í•¨"""
        try:
            print(f"    ?ï¿½ï¿½ ê¸°ë³¸ ê²€??ë°©ì‹?ï¿½ë¡œ '{keyword}' ê²€??..")

            # ê¸°ì¡´ search_posts ë©”ì„œ???ï¿½ìš©
            posts = self.search_posts(keyword, max_pages=Config.MAX_PAGES)

            if posts:
                print(f"    ??ê¸°ë³¸ ê²€???ï¿½ë£Œ: {len(posts)}ï¿½?ê²Œì‹œê¸€ ?ï¿½ì§‘")

                # ?ï¿½ì„¸ ?ï¿½ë³´ ?ï¿½ì§‘ (?ï¿½ìš© ï¿½??ï¿½ï¿½?)
                if Config.EXTRACT_FULL_CONTENT or Config.EXTRACT_COMMENTS:
                    print(f"    ?ï¿½ï¿½ ?ï¿½ì„¸ ?ï¿½ë³´ ?ï¿½ì§‘ ï¿½?.. (ï¿½?{len(posts)}ï¿½?")
                    enhanced_posts = self.enhance_posts_with_details(posts, keyword)
                    return enhanced_posts[:Config.MAX_TOTAL_POSTS]
                else:
                    # ê¸°ë³¸ ?ï¿½ë³´ï¿½??ï¿½ì§‘
                    from datetime import datetime
                    for post in posts:
                        post['keyword'] = keyword
                        post['collection_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                        post['search_method'] = 'basic'

                    return posts[:Config.MAX_TOTAL_POSTS]

            else:
                print(f"    ?ï¿½ï¸ '{keyword}' ê¸°ë³¸ ê²€??ê²°ê³¼ ?ï¿½ìŒ")
                return []

        except Exception as e:
            print(f"    ??ê¸°ë³¸ ê²€???ï¿½ë¥˜: {e}")
            return []

    def navigate_to_search_url(self, search_url):
        """ê²€??URLï¿½??ï¿½ë™"""
        try:
            if not search_url:
                return False

            self.safe_driver_get(search_url)
            time.sleep(2)

            # ?ï¿½ì´ì§€ ë¡œë”© ?ï¿½ï¿½?            self.wait_for_page_load()

            # iframe ì²˜ë¦¬
            if self.handle_search_iframe():
                return True

            return True

        except Exception as e:
            print(f"ê²€??URL ?ï¿½ë™ ?ï¿½ë¥˜: {e}")
            return False

    def collect_recent_posts(self):
        """ìµœì‹  ê²Œì‹œê¸€ ?ï¿½ì§‘ (?ï¿½ì›Œ???ï¿½ì´)"""
        posts = []
        current_page = 1

        try:
            print(f"?ï¿½ï¿½ ìµœì‹  ê²Œì‹œê¸€ ?ï¿½ì§‘ ?ï¿½ì‘...")

            # ì¹´í˜ ë©”ì¸ ?ï¿½ì´ì§€???ï¿½ì²´ê¸€ ?ï¿½ì´ì§€ï¿½??ï¿½ë™
            self.navigate_to_all_posts()

            while current_page <= Config.MAX_PAGES and len(posts) < Config.MAX_TOTAL_POSTS:
                print(f"    ?ï¿½ï¿½ ?ï¿½ì´ì§€ {current_page} ?ï¿½ì§‘ ï¿½?..")

                page_posts = self.extract_posts()

                if not page_posts:
                    print(f"    ?ï¿½ï¸ ?ï¿½ì´ì§€ {current_page}?ï¿½ì„œ ê²Œì‹œê¸€??ì°¾ì„ ???ï¿½ìŠµ?ï¿½ë‹¤.")
                    break

                # ?ï¿½ì„¸ ?ï¿½ë³´ ?ï¿½ì§‘ (?ï¿½ìš”??
                if Config.EXTRACT_FULL_CONTENT or Config.EXTRACT_COMMENTS:
                    detailed_posts = self.enhance_posts_with_details(page_posts, keyword=None)
                    posts.extend(detailed_posts)
                else:
                    posts.extend(page_posts)

                print(f"    ???ï¿½ì´ì§€ {current_page}: {len(page_posts)}ï¿½?ê²Œì‹œê¸€ ?ï¿½ì§‘ (ï¿½?{len(posts)}ï¿½?")

                # ?ï¿½ìŒ ?ï¿½ì´ì§€ï¿½??ï¿½ë™
                if not self.go_to_next_page():
                    print(f"    ?ï¿½ï¸ ë§ˆï¿½?ï¿½??ï¿½ì´ì§€ ?ï¿½ë‹¬")
                    break

                current_page += 1

                # ëª©í‘œ ?ï¿½ì§‘???ï¿½ì¸
                if len(posts) >= Config.MAX_TOTAL_POSTS:
                    print(f"    ?ï¿½ï¿½ ëª©í‘œ ?ï¿½ì§‘??{Config.MAX_TOTAL_POSTS}ï¿½??ï¿½ì„±!")
                    break

            return posts[:Config.MAX_TOTAL_POSTS]

        except Exception as e:
            print(f"??ìµœì‹  ê²Œì‹œê¸€ ?ï¿½ì§‘ ï¿½??ï¿½ë¥˜: {e}")
            return posts

    def extract_posts(self):
        """?ï¿½ì¬ ?ï¿½ì´ì§€?ï¿½ì„œ ê²Œì‹œê¸€ ëª©ë¡ ì¶”ì¶œ"""
        try:
            posts = []

            # ê¸°ì¡´ ê²Œì‹œê¸€ ì¶”ì¶œ ë¡œì§ ?ï¿½ìš©
            post_elements = self.find_post_elements()

            if post_elements:
                print(f"      ?ï¿½ï¿½ {len(post_elements)}ï¿½?ê²Œì‹œê¸€ ?ï¿½ì†Œ ë°œê²¬")

                for i, element in enumerate(post_elements):
                    try:
                        post_info = self.extract_single_post_info(element, i)
                        if post_info:
                            posts.append(post_info)

                        # ?ï¿½ì§‘ ?ï¿½í•œ ?ï¿½ì¸
                        if len(posts) >= Config.MAX_POSTS_PER_PAGE:
                            break

                    except Exception as e:
                        continue

            return posts

        except Exception as e:
            print(f"      ??ê²Œì‹œê¸€ ì¶”ì¶œ ?ï¿½ë¥˜: {e}")
            return []

    def advanced_multi_search(self, keyword):
        """?ï¿½ï¿½ ê³ ê¸‰ ?ï¿½ì¤‘ ê²€???ï¿½ëµ - ëª¨ë“  ê²€???ï¿½ì…˜ ?ï¿½ìš©"""
        try:
            print(f"?? ê³ ê¸‰ ?ï¿½ì¤‘ ê²€???ï¿½ì‘: '{keyword}'")
            all_posts = []
            search_metadata = {
                'keyword': keyword,
                'strategies_used': [],
                'results_per_strategy': {},
                'total_unique_posts': 0
            }

            # ?ï¿½ì¤‘ ê²€??ë²”ìœ„ ?ï¿½ìš©
            if Config.MULTI_SCOPE_SEARCH:
                print("?ï¿½ï¿½ ?ï¿½ì¤‘ ê²€??ë²”ìœ„ ?ï¿½ëµ ?ï¿½í–‰...")
                for scope in Config.SEARCH_SCOPES_TO_USE:
                    posts = self.search_with_scope(keyword, scope)
                    if posts:
                        all_posts.extend(posts)
                        search_metadata['strategies_used'].append(f'scope_{scope}')
                        search_metadata['results_per_strategy'][f'scope_{scope}'] = len(posts)
                        print(f"   ??{scope} ë²”ìœ„: {len(posts)}ï¿½??ï¿½ì§‘")

            # ?ï¿½ì¤‘ ?ï¿½ë ¬ ë°©ì‹ ?ï¿½ìš©
            if Config.MULTI_SORT_SEARCH:
                print("?ï¿½ï¿½ ?ï¿½ì¤‘ ?ï¿½ë ¬ ë°©ì‹ ?ï¿½ëµ ?ï¿½í–‰...")
                for sort_method in Config.SORT_METHODS_TO_USE:
                    posts = self.search_with_sort(keyword, sort_method)
                    if posts:
                        all_posts.extend(posts)
                        search_metadata['strategies_used'].append(f'sort_{sort_method}')
                        search_metadata['results_per_strategy'][f'sort_{sort_method}'] = len(posts)
                        print(f"   ??{sort_method} ?ï¿½ë ¬: {len(posts)}ï¿½??ï¿½ì§‘")

            # ?ï¿½ì¤‘ ê¸°ê°„ ê²€??(?ï¿½íƒ??
            if Config.MULTI_DATE_SEARCH:
                print("?ï¿½ï¿½ ?ï¿½ì¤‘ ê¸°ê°„ ?ï¿½í„° ?ï¿½ëµ ?ï¿½í–‰...")
                for date_filter in Config.DATE_FILTERS_TO_USE:
                    posts = self.search_with_date_filter(keyword, date_filter)
                    if posts:
                        all_posts.extend(posts)
                        search_metadata['strategies_used'].append(f'date_{date_filter}')
                        search_metadata['results_per_strategy'][f'date_{date_filter}'] = len(posts)
                        print(f"   ??{date_filter} ê¸°ê°„: {len(posts)}ï¿½??ï¿½ì§‘")

            # ì¤‘ë³µ ?ï¿½ê±°
            if Config.REMOVE_DUPLICATES and all_posts:
                unique_posts = self.remove_duplicate_posts(all_posts)
                removed_count = len(all_posts) - len(unique_posts)
                print(f"?ï¿½ï¿½ ì¤‘ë³µ ?ï¿½ê±°: {removed_count}ï¿½??ï¿½ê±°, {len(unique_posts)}ï¿½??ï¿½ìŒ")
                all_posts = unique_posts

            # ?ï¿½ì§ˆ ?ï¿½í„° ?ï¿½ìš©
            if Config.QUALITY_FILTER and all_posts:
                filtered_posts = self.apply_quality_filter(all_posts)
                filtered_count = len(all_posts) - len(filtered_posts)
                print(f"?ï¿½ï¿½ ?ï¿½ì§ˆ ?ï¿½í„°: {filtered_count}ï¿½??ï¿½í„°ï¿½? {len(filtered_posts)}ï¿½??ï¿½ìŒ")
                all_posts = filtered_posts

            search_metadata['total_unique_posts'] = len(all_posts)
            print(f"?ï¿½ï¿½ ê³ ê¸‰ ?ï¿½ì¤‘ ê²€???ï¿½ë£Œ: ï¿½?{len(all_posts)}ï¿½?ê³ í’ˆï¿½?ê²Œì‹œê¸€ ?ï¿½ì§‘")

            return all_posts, search_metadata

        except Exception as e:
            print(f"??ê³ ê¸‰ ?ï¿½ì¤‘ ê²€???ï¿½ë¥˜: {e}")
            return [], {}

    # =====================================================================
    # Phase 7E: ë°±ì—… ï¿½??ï¿½ë¹„ê²Œì´??ë©”ì„œ??(8ï¿½?
    # =====================================================================

    def fallback_keyword_search(self, keyword):
        """ê²€???ï¿½íŒ¨??ë°±ì—… ë°©ì‹: ?ï¿½ë°˜ ê²Œì‹œê¸€ ?ï¿½í„°ï¿½?""
        try:
            print(f"    ?ï¿½ï¿½ ë°±ì—… ê²€??ë°©ì‹ ?ï¿½ì‘: '{keyword}'")

            # ?ï¿½ì²´ê¸€ ?ï¿½ì´ì§€ï¿½??ï¿½ë™
            if not self.navigate_to_all_posts():
                print("    ???ï¿½ì²´ê¸€ ?ï¿½ì´ì§€ ?ï¿½ë™ ?ï¿½íŒ¨")
                return []

            collected_posts = []
            current_page = 1
            max_pages = min(Config.MAX_PAGES, 10)

            while current_page <= max_pages and len(collected_posts) < Config.MAX_TOTAL_POSTS:
                print(f"      ?ï¿½ï¿½ ë°±ì—… ?ï¿½ì´ì§€ {current_page} ì²˜ë¦¬ ï¿½?..")

                # ?ï¿½ì¬ ?ï¿½ì´ì§€??ê²Œì‹œê¸€ ì¶”ì¶œ
                page_posts = self.extract_posts()

                if not page_posts:
                    print("      ??ê²Œì‹œê¸€ ì¶”ì¶œ ?ï¿½íŒ¨")
                    break

                # ?ï¿½ì›Œ??ë§¤ì¹­?ï¿½ëŠ” ê²Œì‹œê¸€ ?ï¿½í„°ï¿½?                matched_posts = []
                for post in page_posts:
                    if self.check_keyword_match(post.get('title', ''), post.get('content', ''), keyword):
                        matched_posts.append(post)
                        collected_posts.append(post)

                        if len(collected_posts) >= Config.MAX_TOTAL_POSTS:
                            break

                print(f"      ???ï¿½ì´ì§€ {current_page}: {len(matched_posts)}ï¿½?ë§¤ì¹­")

                # ?ï¿½ìŒ ?ï¿½ì´ì§€ï¿½??ï¿½ë™
                if not self.go_to_next_page():
                    print("      ???ï¿½ìŒ ?ï¿½ì´ì§€ ?ï¿½ë™ ?ï¿½íŒ¨")
                    break

                current_page += 1
                self.adaptive_delay()

            print(f"    ??ë°±ì—… ê²€???ï¿½ë£Œ: {len(collected_posts)}ï¿½??ï¿½ì§‘")
            return collected_posts

        except Exception as e:
            print(f"    ??ë°±ì—… ê²€???ï¿½ë¥˜: {e}")
            return []

    def perform_advanced_search(self, keyword):
        """ê³ ê¸‰ ê²€???ï¿½í–‰ (ê¸°ì¡´ search_posts ë©”ì„œ?ï¿½ï¿½? ?ï¿½ê³„)"""
        try:
            print(f"    ?ï¿½ï¿½ ê³ ê¸‰ ê²€???ï¿½ì‘: '{keyword}'")

            # ê¸°ì¡´ search_posts ë©”ì„œ???ï¿½ìš©
            posts = self.search_posts(keyword, max_pages=Config.MAX_PAGES)

            if posts:
                print(f"    ??ê³ ê¸‰ ê²€???ï¿½ê³µ: {len(posts)}ï¿½?ê²Œì‹œê¸€ ë°œê²¬")
                return posts
            else:
                print(f"    ?ï¿½ï¸ ê³ ê¸‰ ê²€??ê²°ê³¼ ?ï¿½ìŒ")
                return []

        except Exception as e:
            print(f"    ??ê³ ê¸‰ ê²€???ï¿½ë¥˜: {e}")
            return []

    def extract_search_result_posts_simple(self):
        """ê²€??ê²°ê³¼ ?ï¿½ì´ì§€?ï¿½ì„œ ê²Œì‹œê¸€ ì¶”ì¶œ (ê°„ë‹¨ ë²„ì „)"""
        try:
            # ê¸°ì¡´ extract_posts ë©”ì„œ???ï¿½ìš©
            posts = self.extract_posts()

            if posts:
                print(f"      ?ï¿½ï¿½ ê²€??ê²°ê³¼: {len(posts)}ï¿½?ê²Œì‹œê¸€ ì¶”ì¶œ")
            else:
                print("      ?ï¿½ï¸ ê²€??ê²°ê³¼ ?ï¿½ìŒ")

            return posts

        except Exception as e:
            print(f"      ??ê²€??ê²°ê³¼ ì¶”ì¶œ ?ï¿½ë¥˜: {e}")
            return []

    def extract_search_results_with_metadata(self, keyword, strategy):
        """ê²€??ê²°ê³¼ ì¶”ì¶œ (ë©”ï¿½??ï¿½ì´???ï¿½í•¨)"""
        try:
            from datetime import datetime

            posts = []

            # ê¸°ì¡´ ì¶”ì¶œ ë©”ì„œ???ï¿½ìš©
            page_posts = self.extract_search_result_posts(keyword)

            if page_posts:
                for post in page_posts:
                    if isinstance(post, dict):
                        # ë©”ï¿½??ï¿½ì´??ì¶”ï¿½?
                        post['search_strategy'] = strategy
                        post['search_keyword'] = keyword
                        post['collection_timestamp'] = datetime.now().isoformat()

                        # ?ï¿½ì§ˆ ê²€??                        if self.passes_quality_check(post):
                            posts.append(post)
                    else:
                        # ê¸°ë³¸ ?ï¿½ì…”?ï¿½ë¦¬ ?ï¿½íƒœï¿½?ë³€??                        post_dict = {
                            'title': str(post) if post else '',
                            'search_strategy': strategy,
                            'search_keyword': keyword,
                            'collection_timestamp': datetime.now().isoformat()
                        }
                        if self.passes_quality_check(post_dict):
                            posts.append(post_dict)

            return posts

        except Exception as e:
            print(f"         ??ê²€??ê²°ê³¼ ì¶”ì¶œ ?ï¿½ë¥˜: {e}")
            return []

    def remove_duplicate_posts(self, posts):
        """ì¤‘ë³µ ê²Œì‹œê¸€ ?ï¿½ê±°"""
        try:
            if not posts:
                return posts

            seen_urls = set()
            seen_titles = set()
            unique_posts = []

            for post in posts:
                if not isinstance(post, dict):
                    continue

                post_url = post.get('url', '')
                post_title = post.get('title', '')

                # URL ê¸°ë°˜ ì¤‘ë³µ ?ï¿½ê±°
                if post_url and post_url not in seen_urls:
                    seen_urls.add(post_url)
                    unique_posts.append(post)
                # ?ï¿½ëª© ê¸°ë°˜ ì¤‘ë³µ ?ï¿½ê±° (URL???ï¿½ê±°???ï¿½ë¥¸ ê²½ìš°)
                elif post_title and post_title not in seen_titles:
                    seen_titles.add(post_title)
                    unique_posts.append(post)

            return unique_posts

        except Exception as e:
            print(f"??ì¤‘ë³µ ?ï¿½ê±° ?ï¿½ë¥˜: {e}")
            return posts

    def apply_quality_filter(self, posts):
        """?ï¿½ì§ˆ ?ï¿½í„° ?ï¿½ìš©"""
        try:
            if not posts:
                return posts

            filtered_posts = []

            for post in posts:
                if isinstance(post, dict) and self.passes_quality_check(post):
                    filtered_posts.append(post)

            return filtered_posts

        except Exception as e:
            print(f"???ï¿½ì§ˆ ?ï¿½í„° ?ï¿½ë¥˜: {e}")
            return posts

    def passes_quality_check(self, post):
        """ê²Œì‹œê¸€ ?ï¿½ì§ˆ ê²€??""
        try:
            if not isinstance(post, dict):
                return False

            title = post.get('title', '')
            content = post.get('content', '')

            # ìµœì†Œ ê¸¸ì´ ê²€??            if len(title) < Config.MIN_TITLE_LENGTH:
                return False

            if content and len(content) < Config.MIN_CONTENT_LENGTH:
                return False

            # ê³µï¿½??ï¿½í•­ ?ï¿½ì™¸
            if Config.EXCLUDE_NOTICE_POSTS:
                notice_keywords = ['ê³µï¿½?', 'notice', '?ï¿½ë¦¼', '?ï¿½ë‚´', 'Notice']
                if any(keyword in title.lower() for keyword in notice_keywords):
                    return False

            # ê´‘ê³ ??ê²Œì‹œê¸€ ?ï¿½ì™¸
            if Config.EXCLUDE_AD_POSTS:
                ad_keywords = ['ê´‘ê³ ', '?ï¿½ë³´', '?ï¿½ë§¤', 'êµ¬ë§¤', 'ë§ˆï¿½???, 'AD', '?ï¿½ë²¤??]
                if any(keyword in title.lower() for keyword in ad_keywords):
                    return False

            return True

        except Exception as e:
            print(f"???ï¿½ì§ˆ ê²€???ï¿½ë¥˜: {e}")
            return True  # ?ï¿½ë¥˜??ê¸°ë³¸?ï¿½ìœ¼ï¿½??ï¿½ê³¼

    def extract_posts_from_page(self, keyword=None):
        """?ï¿½ì´ì§€?ï¿½ì„œ ê²Œì‹œê¸€ ì¶”ì¶œ (?ï¿½ì›Œ??ë§¤ì¹­ ?ï¿½í•¨)"""
        try:
            posts = []

            # ê¸°ì¡´ find_post_elements ?ï¿½ìš©
            post_elements = self.find_post_elements()

            if not post_elements:
                print("      ?ï¿½ï¸ ê²Œì‹œê¸€ ?ï¿½ì†Œï¿½?ì°¾ì„ ???ï¿½ìŒ")
                return posts

            print(f"      ?ï¿½ï¿½ {len(post_elements)}ï¿½?ê²Œì‹œê¸€ ?ï¿½ì†Œ ë°œê²¬")

            for i, element in enumerate(post_elements):
                try:
                    post_info = self.extract_single_post_info(element, i)
                    if post_info and isinstance(post_info, dict):
                        if keyword:
                            title = post_info.get('title', '')
                            content = post_info.get('content', '')

                            # ?ï¿½ì›Œ??ë§¤ì¹­ ?ï¿½ì¸
                            if self.check_keyword_match(title, content, keyword):
                                post_info['keyword_matched'] = keyword
                                posts.append(post_info)
                        else:
                            posts.append(post_info)

                    # ?ï¿½ì§‘ ?ï¿½í•œ ?ï¿½ì¸
                    if len(posts) >= Config.MAX_POSTS_PER_PAGE:
                        break

                except Exception as e:
                    print(f"      ??ê²Œì‹œê¸€ {i+1} ì¶”ì¶œ ?ï¿½ë¥˜: {e}")
                    continue

            print(f"      ??ìµœì¢… ì¶”ì¶œ: {len(posts)}ï¿½?ê²Œì‹œê¸€")
            return posts

        except Exception as e:
            print(f"      ???ï¿½ì´ì§€ ê²Œì‹œê¸€ ì¶”ì¶œ ?ï¿½ë¥˜: {e}")
            return []

    # =====================================================================
    # Phase 7F: ê³ ê¸‰ ê²€??ï¿½??ï¿½í„°ï¿½?ë©”ì„œ??(10ï¿½?
    # =====================================================================

    def verify_search_results_page_enhanced(self, keyword):
        """ê²€??ê²°ê³¼ ?ï¿½ì´ì§€ ?ï¿½ì¸ (ê°•í™”??ë²„ì „)"""
        try:
            if not self.driver:
                return False

            current_url = self.safe_get_current_url()
            page_source = self.safe_get_page_source()

            print(f"    ?ï¿½ï¿½ ê²€??ê²°ê³¼ ?ï¿½ì´ì§€ ê²€ï¿½?ï¿½?..")
            print(f"      URL: {current_url[:100]}...")

            # 1. URL ?ï¿½í„´ ?ï¿½ì¸
            url_indicators = 0
            if 'ArticleSearchList' in current_url:
                url_indicators += 1
                print(f"      ??URL??ArticleSearchList ?ï¿½í•¨")
            if 'search.query' in current_url:
                url_indicators += 1
                print(f"      ??URL??search.query ?ï¿½í•¨")
            if keyword.lower() in current_url.lower():
                url_indicators += 1
                print(f"      ??URL???ï¿½ì›Œ???ï¿½í•¨")

            # 2. ?ï¿½ì´ì§€ ?ï¿½ìš© ?ï¿½ì¸
            content_indicators = 0
            search_keywords = ['ê²€?ï¿½ê²°ï¿½?, 'ê²€??, 'ï¿½?, 'ï¿½?, 'ê²€?ï¿½ì¡°ï¿½?, 'ArticleSearchList']
            for search_keyword in search_keywords:
                if search_keyword in page_source:
                    content_indicators += 1
                    print(f"      ???ï¿½ì´ì§€??'{search_keyword}' ?ï¿½í•¨")

            # 3. ?ï¿½ì œ ê²Œì‹œê¸€ ë§í¬ ?ï¿½ì¸ (ë©”ë‰´ ë§í¬?ï¿½ êµ¬ë¶„)
            post_links = self.safe_find_elements(By.CSS_SELECTOR, "a[href*='read.nhn'], a[href*='ArticleRead'], a[href*='articleid']")
            menu_links = self.safe_find_elements(By.CSS_SELECTOR, "a[href*='ArticleList.nhn'], a[href*='menuid']")

            print(f"      ?ï¿½ï¿½ ê²Œì‹œê¸€ ë§í¬: {len(post_links)}ï¿½? ë©”ë‰´ ë§í¬: {len(menu_links)}ï¿½?)

            # 4. ?ï¿½ì´ï¿½?êµ¬ì¡° ?ï¿½ì¸
            tables = self.safe_find_elements(By.TAG_NAME, "table")
            board_tables = []
            for table in tables:
                table_class = table.get_attribute('class') or ''
                if 'board' in table_class.lower() or 'article' in table_class.lower():
                    board_tables.append(table)

            print(f"      ?ï¿½ï¿½ï¿½??ï¿½ì²´ ?ï¿½ì´ï¿½? {len(tables)}ï¿½? ê²Œì‹œ???ï¿½ì´ï¿½? {len(board_tables)}ï¿½?)

            # 5. ì¢…í•© ?ï¿½ë‹¨
            total_score = url_indicators + content_indicators
            is_valid_search_page = (
                total_score >= 2 and  # ê¸°ë³¸ ì§€??ë§Œì¡±
                (len(post_links) > 0 or len(board_tables) > 0) and  # ?ï¿½ì œ ì»¨í…ï¿½?ì¡´ì¬
                len(post_links) >= len(menu_links)  # ê²Œì‹œê¸€ ë§í¬ê°€ ë©”ë‰´ ë§í¬ë³´ë‹¤ ë§ê±°??ê°™ìŒ
            )

            print(f"      ?ï¿½ï¿½ ê²€ï¿½??ï¿½ìˆ˜: URLì§€??{url_indicators}, ?ï¿½ìš©ì§€??{content_indicators}, ì´ì ={total_score}")
            print(f"      ?ï¿½ï¿½ ê²€??ê²°ê³¼ ?ï¿½ì´ì§€ ?ï¿½ì •: {'???ï¿½íš¨' if is_valid_search_page else '??ë¬´íš¨'}")

            return is_valid_search_page

        except Exception as e:
            print(f"    ??ê²€??ê²°ê³¼ ?ï¿½ì´ì§€ ê²€ï¿½??ï¿½íŒ¨: {e}")
            return False

    def setup_advanced_search_options(self):
        """ê³ ê¸‰ ê²€???ï¿½ì…˜ ?ï¿½ì •"""
        try:
            if not self.driver:
                return

            from selenium.webdriver.support.select import Select

            # ê²€???ï¿½ì…˜???ï¿½ì •
            search_options = [
                ("select[name='searchBy']", "1"),    # ?ï¿½ëª©+?ï¿½ìš©
                ("select[name='sortBy']", "date"),    # ?ï¿½ì§œ??                ("select[name='option']", "0"),       # ê¸°ë³¸ ?ï¿½ì…˜
            ]

            options_set = 0
            for selector, value in search_options:
                try:
                    elements = self.safe_find_elements(By.CSS_SELECTOR, selector)
                    for element in elements:
                        if element.is_displayed() and element.is_enabled():
                            Select(element).select_by_value(value)
                            options_set += 1
                            break
                except Exception as e:
                    print(f"      ?ï¿½ï¸ ?ï¿½ì…˜ ?ï¿½ì • ?ï¿½íŒ¨ ({selector}): {e}")

            print(f"    ?ï¿½ï¸ ê³ ê¸‰ ê²€???ï¿½ì…˜ ?ï¿½ì • ?ï¿½ë£Œ: {options_set}ï¿½?)

        except Exception as e:
            print(f"    ?ï¿½ï¸ ê³ ê¸‰ ê²€???ï¿½ì…˜ ?ï¿½ì • ï¿½??ï¿½ë¥˜: {e}")

    def use_cafe_search_interface(self, keyword):
        """ì¹´í˜ ê²€???ï¿½í„°?ï¿½ì´???ï¿½ìš© (?ï¿½ìƒ??ë²„ì „)"""
        try:
            if not self.driver:
                return False

            # 1. ê²€?ï¿½ë°•??ì°¾ê¸° (?ï¿½ì¥???ï¿½í„´)
            search_selectors = [
                "input[name='query']", "input[name='search']", "input[name='keyword']",
                "input[name='searchKeyword']", "input[id='searchKeyword']",
                "input[class*='search_input']", "input[class*='searchInput']",
                "input[class*='cafe_search']", "#cafe_main input[type='text']",
                ".search_area input[type='text']", "input[placeholder*='ê²€??]"
            ]

            search_input = None
            print(f"    ?ï¿½ï¿½ {len(search_selectors)}ï¿½?ê²€?ï¿½ë°•???ï¿½í„´?ï¿½ë¡œ ?ï¿½ìƒ‰...")

            for selector in search_selectors:
                try:
                    elements = self.safe_find_elements(By.CSS_SELECTOR, selector)
                    for element in elements:
                        if element.is_displayed() and element.is_enabled():
                            size = element.size
                            if size['width'] > 50 and size['height'] > 15:
                                search_input = element
                                print(f"    ??ê²€?ï¿½ë°•??ë°œê²¬! '{selector}' ({size['width']}x{size['height']})")
                                break
                    if search_input:
                        break
                except Exception:
                    continue

            if not search_input:
                print("    ??ê²€?ï¿½ë°•?ï¿½ï¿½? ì°¾ì„ ???ï¿½ìŠµ?ï¿½ë‹¤")
                return False

            # 2. ê²€?ï¿½ì–´ ?ï¿½ë ¥
            print(f"    ?ï¿½ï¸ ê²€?ï¿½ì–´ '{keyword}' ?ï¿½ë ¥ ï¿½?..")
            search_input.clear()
            self.adaptive_delay(0.5)
            search_input.send_keys(keyword)
            self.adaptive_delay(1)

            # 3. ê²€???ï¿½í–‰
            # ë°©ë²• 1: ?ï¿½í„°???ï¿½ë ¥
            try:
                print("    ???ï¿½í„°?ï¿½ë¡œ ê²€???ï¿½í–‰")
                from selenium.webdriver.common.keys import Keys
                search_input.send_keys(Keys.RETURN)
                self.adaptive_delay(3)
                if self.verify_search_results_page(keyword):
                    return True
            except Exception as e:
                print(f"    ???ï¿½í„°??ê²€???ï¿½íŒ¨: {e}")

            # ë°©ë²• 2: ê²€??ë²„íŠ¼ ?ï¿½ë¦­
            search_btn_selectors = [
                "button[type='submit']", ".search_btn", ".btn-search",
                "button[class*='search']", "a[onclick*='search']"
            ]
            for btn_selector in search_btn_selectors:
                try:
                    elements = self.safe_find_elements(By.CSS_SELECTOR, btn_selector)
                    for search_btn in elements:
                        if search_btn.is_displayed() and search_btn.is_enabled():
                            print(f"    ?ï¿½ï¿½ ê²€??ë²„íŠ¼ ?ï¿½ë¦­: {btn_selector}")
                            self.safe_execute_script("arguments[0].click();", search_btn)
                            self.adaptive_delay(3)
                            if self.verify_search_results_page(keyword):
                                return True
                except Exception:
                    continue

            return False

        except Exception as e:
            print(f"    ??ê²€???ï¿½í„°?ï¿½ì´???ï¿½ìš© ?ï¿½íŒ¨: {e}")
            return False

    def verify_search_results_page(self, keyword):
        """ê²€??ê²°ê³¼ ?ï¿½ì´ì§€ ?ï¿½ì¸"""
        try:
            if not self.driver:
                return False

            # ê²€??ê²°ê³¼ ?ï¿½ì´ì§€ ?ï¿½ì¸???ï¿½í•œ ?ï¿½ëŸ¬ ì§€?ï¿½ë“¤
            indicators = [
                # URL ?ï¿½í„´ ?ï¿½ì¸
                lambda: 'search' in self.safe_get_current_url().lower(),
                lambda: 'query' in self.safe_get_current_url().lower(),
                lambda: keyword.lower() in self.safe_get_current_url().lower(),

                # ?ï¿½ì´ì§€ ?ï¿½ì†Œ ?ï¿½ì¸
                lambda: len(self.safe_find_elements(By.CSS_SELECTOR, ".search-result")) > 0,
                lambda: len(self.safe_find_elements(By.CSS_SELECTOR, ".article-list")) > 0,
                lambda: len(self.safe_find_elements(By.CSS_SELECTOR, "[class*='search']")) > 0,

                # ?ï¿½ìŠ¤???ï¿½ìš© ?ï¿½ì¸
                lambda: 'ê²€?ï¿½ê²°ï¿½? in self.safe_get_page_source(),
                lambda: 'ê²€?? in self.safe_get_page_source(),
                lambda: keyword in self.safe_get_page_source(),
            ]

            positive_indicators = 0
            for indicator in indicators:
                try:
                    if indicator():
                        positive_indicators += 1
                except:
                    continue

            # ?ï¿½ë°˜ ?ï¿½ìƒ??ì§€?ï¿½ï¿½? ë§Œì¡±?ï¿½ë©´ ê²€??ê²°ê³¼ ?ï¿½ì´ì§€ï¿½??ï¿½ë‹¨
            is_search_page = positive_indicators >= len(indicators) // 2

            print(f"    ?ï¿½ï¿½ ê²€??ê²°ê³¼ ê²€ï¿½? {positive_indicators}/{len(indicators)} ì§€??ë§Œì¡± = {'???ï¿½íš¨' if is_search_page else '??ë¬´íš¨'}")
            return is_search_page

        except Exception as e:
            print(f"    ??ê²€??ê²°ê³¼ ?ï¿½ì´ì§€ ?ï¿½ì¸ ?ï¿½ë¥˜: {e}")
            return False

    def search_with_sort(self, keyword, sort_method):
        """?ï¿½ì • ?ï¿½ë ¬ ë°©ì‹?ï¿½ë¡œ ê²€??""
        try:
            print(f"      ?ï¿½ï¿½ {sort_method} ?ï¿½ë ¬ ê²€??ï¿½?..")

            search_by = Config.SEARCH_SCOPE_OPTIONS.get(Config.DEFAULT_SEARCH_SCOPE, 1)
            sort_by = Config.SORT_OPTIONS.get(sort_method, 'date')

            # ê²€??URL êµ¬ì„±
            search_url = self.build_advanced_search_url(
                keyword=keyword,
                search_by=search_by,
                sort_by=sort_by,
                date_filter=Config.DEFAULT_DATE_FILTER,
                media_filter=Config.DEFAULT_MEDIA_FILTER
            )

            if not search_url:
                return []

            # ê²€???ï¿½í–‰
            if self.navigate_to_search_url(search_url):
                posts = self.extract_search_results_with_metadata(keyword, sort_method)
                return posts

            return []

        except Exception as e:
            print(f"      ??{sort_method} ?ï¿½ë ¬ ê²€???ï¿½ë¥˜: {e}")
            return []

    def search_with_date_filter(self, keyword, date_filter):
        """?ï¿½ì • ê¸°ê°„ ?ï¿½í„°ï¿½?ê²€??""
        try:
            print(f"      ?ï¿½ï¿½ {date_filter} ê¸°ê°„ ê²€??ï¿½?..")

            search_by = Config.SEARCH_SCOPE_OPTIONS.get(Config.DEFAULT_SEARCH_SCOPE, 1)
            sort_by = Config.SORT_OPTIONS.get(Config.DEFAULT_SORT_METHOD, 'date')
            date_value = Config.DATE_FILTER_OPTIONS.get(date_filter, 'all')

            # ê²€??URL êµ¬ì„±
            search_url = self.build_advanced_search_url(
                keyword=keyword,
                search_by=search_by,
                sort_by=sort_by,
                date_filter=date_value,
                media_filter=Config.DEFAULT_MEDIA_FILTER
            )

            if not search_url:
                return []

            # ê²€???ï¿½í–‰
            if self.navigate_to_search_url(search_url):
                posts = self.extract_search_results_with_metadata(keyword, date_filter)
                return posts

            return []

        except Exception as e:
            print(f"      ??{date_filter} ê¸°ê°„ ê²€???ï¿½ë¥˜: {e}")
            return []

    def build_advanced_search_url(self, keyword, search_by=1, sort_by='date',
                                 date_filter='all', media_filter='all',
                                 include_words='', exclude_words='', exact_phrase=''):
        """ê³ ê¸‰ ê²€??URL êµ¬ì„±"""
        try:
            import urllib.parse

            # ?ï¿½ì›Œ???ï¿½ì½”??            encoded_keyword = urllib.parse.quote(keyword)
            encoded_include = urllib.parse.quote(include_words) if include_words else ''
            encoded_exclude = urllib.parse.quote(exclude_words) if exclude_words else ''
            encoded_exact = urllib.parse.quote(exact_phrase) if exact_phrase else ''

            # Club ID ê°€?ï¿½ì˜¤ï¿½?            club_id = self.get_cafe_club_id()
            if not club_id:
                print("         ??Club IDï¿½?ê°€?ï¿½ì˜¬ ???ï¿½ìŒ")
                return None

            # ê³ ê¸‰ ê²€??URL ?ï¿½ë¼ë¯¸í„° êµ¬ì„±
            params = {
                'search.clubid': club_id,
                'search.query': encoded_keyword,
                'search.searchBy': search_by,
                'search.sortBy': sort_by,
                'search.option': 0,
                'search.defaultValue': 1,
                'search.includeAll': 'off',
                'search.exclude': encoded_exclude,
                'search.include': encoded_include,
                'search.exact': encoded_exact,
                'search.searchdate': date_filter,
                'search.media': media_filter,
                'search.searchType': 'post',
                'search.page.currentpage': 1
            }

            # URL êµ¬ì„±
            base_url = f"https://cafe.naver.com/ArticleSearchList.nhn"
            param_string = '&'.join([f"{k}={v}" for k, v in params.items()])
            search_url = f"{base_url}?{param_string}"

            print(f"         ?ï¿½ï¿½ ê³ ê¸‰ ê²€??URL êµ¬ì„± ?ï¿½ë£Œ: {search_url[:100]}...")
            return search_url

        except Exception as e:
            print(f"         ??ê³ ê¸‰ ê²€??URL êµ¬ì„± ?ï¿½ë¥˜: {e}")
            return None

    def perform_integrated_search(self, keyword):
        """?ï¿½í•© ê²€???ï¿½í–‰"""
        try:
            print(f"    ?ï¿½ï¿½ ?ï¿½í•© ê²€???ï¿½í–‰: '{keyword}'")

            # ê¸°ì¡´ advanced_multi_search ?ï¿½ìš©
            posts, metadata = self.advanced_multi_search(keyword)

            return {
                'strategy': 'integrated',
                'keyword': keyword,
                'posts': posts,
                'post_count': len(posts),
                'success': len(posts) > 0,
                'metadata': metadata
            }
        except Exception as e:
            print(f"    ???ï¿½í•© ê²€???ï¿½íŒ¨: {e}")
            return {
                'strategy': 'integrated',
                'keyword': keyword,
                'posts': [],
                'post_count': 0,
                'success': False,
                'error': str(e)
            }

    def perform_scope_specific_search(self, keyword, scope):
        """?ï¿½ì • ë²”ìœ„ ê²€???ï¿½í–‰"""
        try:
            print(f"    ?ï¿½ï¿½ ë²”ìœ„ï¿½?ê²€?? '{keyword}' in {scope}")

            scope_mapping = {
                'title_content': '1',  # ?ï¿½ëª©+?ï¿½ìš©
                'title': '2',          # ?ï¿½ëª©ï¿½?                'content': '3',        # ?ï¿½ìš©ï¿½?                'author': '4',         # ?ï¿½ì„±??                'comment': '5',        # ?ï¿½ï¿½?
                'tag': '6',           # ?ï¿½ê·¸
                'file_name': '7'      # ?ï¿½ì¼ï¿½?            }

            search_scope = scope_mapping.get(scope, '1')

            # ê³ ê¸‰ ê²€??URL êµ¬ì„±
            search_url = self.build_advanced_search_url(
                keyword=keyword,
                search_by=search_scope
            )

            if not search_url:
                posts = []
            elif self.navigate_to_search_url(search_url):
                posts = self.extract_search_results_with_metadata(keyword, f'scope_{scope}')
            else:
                posts = []

            return {
                'strategy': f'scope_{scope}',
                'keyword': keyword,
                'scope': scope,
                'posts': posts,
                'post_count': len(posts),
                'success': len(posts) > 0
            }

        except Exception as e:
            print(f"    ??ë²”ìœ„ï¿½?ê²€???ï¿½íŒ¨ ({scope}): {e}")
            return {
                'strategy': f'scope_{scope}',
                'keyword': keyword,
                'posts': [],
                'post_count': 0,
                'success': False,
                'error': str(e)
            }

    def perform_sort_specific_search(self, keyword, sort_method):
        """?ï¿½ì • ?ï¿½ë ¬ ë°©ì‹ ê²€???ï¿½í–‰"""
        try:
            print(f"    ?ï¿½ï¿½ ?ï¿½ë ¬ï¿½?ê²€?? '{keyword}' by {sort_method}")

            sort_mapping = {
                'date_desc': 'date',      # ìµœì‹ ??                'date_asc': 'date_asc',   # ?ï¿½ë˜?ï¿½ìˆœ
                'relevance': 'sim',       # ?ï¿½í™•?ï¿½ìˆœ
                'views': 'view',          # ì¡°íšŒ?ï¿½ìˆœ
                'comments': 'comment',    # ?ï¿½ï¿½??ï¿½ìˆœ
                'likes': 'like',          # ì¶”ì²œ??                'replies': 'reply'        # ?ï¿½ï¿½???            }

            sort_value = sort_mapping.get(sort_method, 'date')
            posts = self.search_with_sort(keyword, sort_method)

            return {
                'strategy': f'sort_{sort_method}',
                'keyword': keyword,
                'sort': sort_method,
                'posts': posts,
                'post_count': len(posts),
                'success': len(posts) > 0
            }

        except Exception as e:
            print(f"    ???ï¿½ë ¬ï¿½?ê²€???ï¿½íŒ¨ ({sort_method}): {e}")
            return {
                'strategy': f'sort_{sort_method}',
                'keyword': keyword,
                'posts': [],
                'post_count': 0,
                'success': False,
                'error': str(e)
            }

    # =====================================================================
    # Phase 7G: ê²Œì‹œ???ï¿½ï¿½? ï¿½??ï¿½í‹¸ë¦¬í‹° ë©”ì„œ??(15ï¿½?
    # =====================================================================

    def find_dynamic_menus(self):
        """?ï¿½ì  ë©”ë‰´ ï¿½?iframe ?ï¿½ìƒ‰"""
        boards = []

        try:
            # JavaScriptï¿½??ï¿½ê²¨ï¿½?ë©”ë‰´ ?ï¿½ì¥ ?ï¿½ë„
            expand_scripts = [
                "document.querySelectorAll('.menu-toggle, .expand-btn, [data-toggle]').forEach(el => {try{el.click()}catch(e){}});",
                "document.querySelectorAll('[style*=\"display:none\"], [style*=\"visibility:hidden\"]').forEach(el => {el.style.display='block'; el.style.visibility='visible';});",
                "window.scrollTo(0, document.body.scrollHeight);"  # ?ï¿½í¬ë¡¤ë¡œ lazy loading ?ï¿½ë¦¬ï¿½?            ]

            for script in expand_scripts:
                try:
                    self.safe_execute_script(script)
                    self.adaptive_delay(1)
                except:
                    continue

            # iframe ?ï¿½ï¿½? ê²€??            try:
                iframes = self.safe_find_elements(By.TAG_NAME, "iframe")
                for iframe in iframes[:3]:  # ìµœï¿½? 3ï¿½?iframeï¿½?ê²€??                    try:
                        self.driver.switch_to.frame(iframe)

                        # iframe ?ï¿½ï¿½??ï¿½ì„œ ê²Œì‹œ??ë§í¬ ì°¾ê¸°
                        iframe_links = self.safe_find_elements(By.CSS_SELECTOR, "a[href*='cafe.naver.com']")
                        for link in iframe_links:
                            try:
                                name = link.text.strip()
                                href = link.get_attribute("href")
                                if self.is_valid_board(name, href):
                                    boards.append((name, href))
                            except:
                                continue

                        self.driver.switch_to.default_content()
                    except:
                        try:
                            self.driver.switch_to.default_content()
                        except:
                            pass
                        continue
            except:
                pass

            if boards:
                print(f"    ?ï¿½ï¿½ ?ï¿½ì  ë©”ë‰´?ï¿½ì„œ {len(boards)}ï¿½?ê²Œì‹œ??ë°œê²¬")

        except Exception as e:
            print(f"    ?ï¿½ï¸ ?ï¿½ì  ë©”ë‰´ ê²€???ï¿½ë¥˜: {e}")

        return boards

    def get_priority(self, board_name):
        """ê²Œì‹œ???ï¿½ì„ ?ï¿½ìœ„ ê³„ì‚°"""
        try:
            priority_keywords = ['?ï¿½ì²´', '?ï¿½ìœ ', '?ï¿½ë°˜', 'ê³µï¿½?', '?ï¿½ë³´', 'ì§ˆë¬¸', '?ï¿½ê¸°']
            name_lower = board_name.lower()

            for i, keyword in enumerate(priority_keywords):
                if keyword in name_lower:
                    return i
            return len(priority_keywords)

        except:
            return 999

    def fallback_detection(self):
        """ê¸°ë³¸ ?ï¿½ìƒ‰ ëª¨ë“œ (fallback)"""
        try:
            print("  ?ï¿½ï¿½ ê¸°ë³¸ ëª¨ë“œï¿½??ï¿½í™˜...")

            # ê°€??ê¸°ë³¸?ï¿½ì¸ ë§í¬??ê²€??            all_links = self.safe_find_elements(By.CSS_SELECTOR, "a[href]")
            boards = []

            for link in all_links[:200]:  # ìµœï¿½? 200ï¿½?ë§í¬ ê²€??                try:
                    text = link.text.strip()
                    href = link.get_attribute("href")

                    if href and 'cafe.naver.com' in href and len(text) > 0:
                        if self.is_valid_board(text, href):
                            boards.append((text, href))

                    if len(boards) >= 10:  # 10ï¿½?ì°¾ìœ¼ï¿½?ì¶©ë¶„
                        break
                except:
                    pass

            return boards if boards else [("?ï¿½ì²´ê¸€ë³´ê¸°", Config.DEFAULT_CAFE_URL)]

        except:
            return [("?ï¿½ì²´ê¸€ë³´ê¸°", Config.DEFAULT_CAFE_URL)]

    def search_in_current_board(self, keyword, max_pages):
        """?ï¿½ì¬ ê²Œì‹œ?ï¿½ì—???ï¿½ì›Œ??ê²€??- ?ï¿½ë§ˆ???ï¿½ë¹„ê²Œì´???ï¿½í•¨"""
        posts_found = []

        try:
            print(f"    ?ï¿½ï¿½ ê²Œì‹œ???ï¿½ë™ ?ï¿½ìƒ‰ ï¿½??ï¿½ì›Œ??'{keyword}' ê²€???ï¿½ì‘...")

            # 1. ?ï¿½ì´ì§€ ?ï¿½íƒœ ë¶„ì„
            self.analyze_current_page()

            # 2. ìµœì ??ë³´ê¸° ëª¨ë“œï¿½??ï¿½ë™ ?ï¿½í™˜
            self.optimize_view_mode()

            # 3. ?ï¿½ë§ˆ???ï¿½ì´ì§€ ?ï¿½ë¹„ê²Œì´??            self.smart_page_navigation("all_posts")

            # 4. ?ï¿½ì´ì§€ï¿½??ï¿½ë¡¤ï¿½?(?ï¿½ìƒ??ë°©ì‹)
            for page in range(1, max_pages + 1):
                print(f"    ?ï¿½ï¿½ ?ï¿½ì´ì§€ {page}/{max_pages} ë¶„ì„ ï¿½?.. (?ï¿½ì›Œ?? '{keyword}')")

                # ?ï¿½ì´ì§€ ë¡œë”© ?ï¿½ë£Œ ?ï¿½ï¿½?                self.wait_for_page_load()

                # ê²Œì‹œê¸€ ì¶”ì¶œ
                page_posts = self.extract_posts_from_page(keyword)
                posts_found.extend(page_posts)

                print(f"      ???ï¿½ì´ì§€ {page}?ï¿½ì„œ {len(page_posts)}ï¿½?ë§¤ì¹­ ê²Œì‹œê¸€ ë°œê²¬")

                # ?ï¿½ìŒ ?ï¿½ì´ì§€ ?ï¿½ë™ (?ï¿½ë§ˆ??ë°©ì‹)
                if page < max_pages:
                    if not self.smart_next_page():
                        print("      ?ï¿½ï¿½ ë§ˆï¿½?ï¿½??ï¿½ì´ì§€ ?ï¿½ë‹¬")
                        break

                # ?ï¿½ì‘???ï¿½ë ˆ??(?ï¿½ì´ì§€ ë¡œë”© ?ï¿½íƒœ???ï¿½ë¼)
                self.adaptive_delay()

        except Exception as e:
            print(f"    ??ê²Œì‹œ??ê²€???ï¿½ë¥˜: {e}")

        return posts_found

    def find_main_menu_boards(self):
        """ë©”ì¸ ë©”ë‰´?ï¿½ì„œ ê²Œì‹œ??ì°¾ê¸°"""
        boards = []
        try:
            # ë©”ì¸ ë©”ë‰´ ?ï¿½íƒ?ï¿½ë“¤
            menu_selectors = [
                '.cafe-menu a', '.menu-list a', '.main-menu a',
                '[class*="menu"] a', '[class*="nav"] a',
                '.cafe-nav a', '.navigation a'
            ]

            for selector in menu_selectors:
                try:
                    elements = self.safe_find_elements(By.CSS_SELECTOR, selector)
                    for element in elements:
                        board_info = self.extract_board_info(element)
                        if board_info and self.is_valid_board_link(board_info):
                            boards.append(board_info)
                except:
                    continue

        except Exception as e:
            print(f"    ?ï¿½ï¸ ë©”ì¸ ë©”ë‰´ ê²€???ï¿½ë¥˜: {e}")

        return boards

    def find_sidebar_boards(self):
        """?ï¿½ì´?ï¿½ë°”?ï¿½ì„œ ê²Œì‹œ??ì°¾ê¸°"""
        boards = []
        try:
            sidebar_selectors = [
                '.sidebar a', '.side-menu a', '.left-menu a',
                '.right-menu a', '[class*="side"] a'
            ]

            for selector in sidebar_selectors:
                try:
                    elements = self.safe_find_elements(By.CSS_SELECTOR, selector)
                    for element in elements:
                        board_info = self.extract_board_info(element)
                        if board_info and self.is_valid_board_link(board_info):
                            boards.append(board_info)
                except:
                    continue

        except Exception as e:
            print(f"    ?ï¿½ï¸ ?ï¿½ì´?ï¿½ë°” ê²€???ï¿½ë¥˜: {e}")

        return boards

    def find_dropdown_boards(self):
        """?ï¿½ë¡­?ï¿½ìš´ ë©”ë‰´?ï¿½ì„œ ê²Œì‹œ??ì°¾ê¸°"""
        boards = []
        try:
            # ?ï¿½ë¡­?ï¿½ìš´ ?ï¿½ë¦¬ï¿½??ï¿½ë¦­ ?ï¿½ë„
            dropdown_triggers = [
                '.dropdown-toggle', '.menu-toggle',
                '[class*="dropdown"]', '[class*="toggle"]'
            ]

            for trigger_selector in dropdown_triggers:
                try:
                    triggers = self.safe_find_elements(By.CSS_SELECTOR, trigger_selector)
                    for trigger in triggers:
                        if trigger.is_displayed():
                            trigger.click()
                            self.adaptive_delay(1)

                            # ?ï¿½ë¡­?ï¿½ìš´ ë©”ë‰´?ï¿½ì„œ ë§í¬ ì°¾ê¸°
                            dropdown_links = self.safe_find_elements(By.CSS_SELECTOR, '.dropdown-menu a, .submenu a')
                            for link in dropdown_links:
                                board_info = self.extract_board_info(link)
                                if board_info and self.is_valid_board_link(board_info):
                                    boards.append(board_info)

                            # ?ï¿½ë¡­?ï¿½ìš´ ?ï¿½ê¸°
                            try:
                                trigger.click()
                            except:
                                continue
                except:
                    pass

        except Exception as e:
            print(f"    ?ï¿½ï¸ ?ï¿½ë¡­?ï¿½ìš´ ê²€???ï¿½ë¥˜: {e}")

        return boards

    def find_hidden_boards(self):
        """?ï¿½ê²¨ï¿½?ê²Œì‹œ??ì°¾ê¸°"""
        boards = []
        try:
            if not Config.EXPLORE_HIDDEN_BOARDS:
                return boards

            # ?ï¿½ê²¨ï¿½?ë©”ë‰´ ?ï¿½ï¿½?
            hidden_selectors = [
                'a[style*="display:none"]',
                '.hidden a', '.hide a',
                '[class*="hidden"] a',
                'li[style*="display:none"] a'
            ]

            for selector in hidden_selectors:
                try:
                    elements = self.safe_find_elements(By.CSS_SELECTOR, selector)
                    for element in elements:
                        board_info = self.extract_board_info(element)
                        if board_info and self.is_valid_board_link(board_info):
                            board_info['is_hidden'] = True
                            boards.append(board_info)
                except:
                    continue

        except Exception as e:
            print(f"    ?ï¿½ï¸ ?ï¿½ê²¨ï¿½?ê²Œì‹œ??ê²€???ï¿½ë¥˜: {e}")

        return boards

    def find_category_boards(self):
        """ì¹´í…Œê³ ë¦¬ï¿½?ê²Œì‹œ??ì°¾ê¸°"""
        boards = []
        try:
            # ì¹´í…Œê³ ë¦¬ ë§í¬ ì°¾ê¸°
            category_selectors = [
                '.category a', '.cat a', '[class*="category"] a',
                '.board-category a', '.menu-category a'
            ]

            for selector in category_selectors:
                try:
                    elements = self.safe_find_elements(By.CSS_SELECTOR, selector)
                    for element in elements:
                        board_info = self.extract_board_info(element)
                        if board_info and self.is_valid_board_link(board_info):
                            board_info['board_type'] = 'category'
                            boards.append(board_info)
                except:
                    continue

        except Exception as e:
            print(f"    ?ï¿½ï¸ ì¹´í…Œê³ ë¦¬ ê²Œì‹œ??ê²€???ï¿½ë¥˜: {e}")

        return boards

    def find_special_boards(self):
        """?ï¿½ë³„ ê²Œì‹œ??ì°¾ê¸° (ê³µï¿½?, ?ï¿½ë²¤????"""
        boards = []
        try:
            if not Config.FIND_SPECIAL_BOARDS:
                return boards

            # ?ï¿½ë³„ ê²Œì‹œ???ï¿½ì›Œ??            special_keywords = [
                'ê³µï¿½?', '?ï¿½ë²¤??, '?ï¿½ë‚´', '?ï¿½ë¦¼', '?ï¿½ì†Œ??,
                'ê³µï¿½??ï¿½í•­', '?ï¿½ë²¤??, 'ê°€?ï¿½ë“œ', '?ï¿½ï¿½?ï¿½?,
                'notice', 'event', 'announcement', 'news'
            ]

            # ëª¨ë“  ë§í¬?ï¿½ì„œ ?ï¿½ë³„ ê²Œì‹œ??ì°¾ê¸°
            all_links = self.safe_find_elements(By.TAG_NAME, 'a')

            for link in all_links[:100]:  # ìµœï¿½? 100ê°œë§Œ ê²€??                try:
                    link_text = link.text.lower()
                    href = link.get_attribute('href') or ''

                    # ?ï¿½ë³„ ?ï¿½ì›Œ???ï¿½í•¨ ?ï¿½ï¿½? ?ï¿½ì¸
                    for keyword in special_keywords:
                        if keyword.lower() in link_text or keyword.lower() in href.lower():
                            board_info = self.extract_board_info(link)
                            if board_info and self.is_valid_board_link(board_info):
                                board_info['board_type'] = 'special'
                                board_info['special_type'] = keyword
                                boards.append(board_info)
                            break
                except:
                    continue

        except Exception as e:
            print(f"    ?ï¿½ï¸ ?ï¿½ë³„ ê²Œì‹œ??ê²€???ï¿½ë¥˜: {e}")

        return boards

    def extract_board_info(self, element):
        """ê²Œì‹œ???ï¿½ë³´ ì¶”ì¶œ"""
        try:
            href = element.get_attribute('href')
            text = element.text.strip()

            if not href or not text or len(text) < 2:
                return None

            board_info = {
                'name': text,
                'url': href,
                'board_type': 'unknown',
                'is_hidden': False,
                'menu_id': '',
                'description': ''
            }

            # menu_id ì¶”ì¶œ ?ï¿½ë„
            if 'menuid=' in href:
                try:
                    menu_id = href.split('menuid=')[1].split('&')[0]
                    board_info['menu_id'] = menu_id
                except:
                    pass

            return board_info

        except Exception as e:
            return None

    def is_valid_board_link(self, board_info):
        """ê²Œì‹œ??ë§í¬ ?ï¿½íš¨??ê²€??""
        try:
            if not board_info or not isinstance(board_info, dict):
                return False

            name = board_info.get('name', '')
            href = board_info.get('url', '')

            if not name or not href or len(name.strip()) < 2:
                return False

            # ì¹´í˜ URL ?ï¿½í•¨ ?ï¿½ì¸
            if 'cafe.naver.com' not in href:
                return False

            # ?ï¿½ì™¸???ï¿½ì›Œ?ï¿½ë“¤
            exclude_keywords = [
                'login', 'logout', 'search', 'write', 'modify', 'delete',
                'reply', 'comment', 'profile', 'member', 'setting', 'admin'
            ]

            name_lower = name.lower()
            href_lower = href.lower()

            for keyword in exclude_keywords:
                if keyword in name_lower or keyword in href_lower:
                    return False

            # ?ï¿½ë¬´ ê¸¸ê±°??ì§§ï¿½? ?ï¿½ë¦„ ?ï¿½ì™¸
            if len(name) > 50 or len(name) < 1:
                return False

            return True

        except:
            return False

    def deduplicate_posts(self, posts):
        """ê²Œì‹œê¸€ ì¤‘ë³µ ?ï¿½ê±°"""
        try:
            seen_urls = set()
            seen_titles = set()
            unique_posts = []

            for post in posts:
                post_url = post.get('url', '')
                post_title = post.get('title', '')

                # URL ê¸°ë°˜ ì¤‘ë³µ ?ï¿½ê±°
                if post_url and post_url not in seen_urls:
                    seen_urls.add(post_url)
                    unique_posts.append(post)
                # ?ï¿½ëª© ê¸°ë°˜ ì¤‘ë³µ ?ï¿½ê±° (URL???ï¿½ê±°???ï¿½ë¥¸ ê²½ìš°)
                elif post_title and post_title not in seen_titles:
                    seen_titles.add(post_title)
                    unique_posts.append(post)

            return unique_posts

        except Exception as e:
            print(f"    ??ì¤‘ë³µ ?ï¿½ê±° ?ï¿½ë¥˜: {e}")
            return posts

    def save_results_to_excel(self, results, filename_prefix="complete_exploration"):
        """ê²°ê³¼ï¿½??ï¿½ï¿½?ï¿½??ï¿½??""
        try:
            if hasattr(CafeDataExporter, 'save_all'):
                filename = f"{filename_prefix}_{datetime.now().strftime('%Y%m%d')}.xlsx"
                return CafeDataExporter.save_all(results, filename)
            else:
                print("    ?ï¿½ï¸ CafeDataExporterï¿½??ï¿½ìš©?????ï¿½ìŒ")
                return False
        except Exception as e:
            print(f"    ???ï¿½ï¿½? ?ï¿½???ï¿½ë¥˜: {e}")
            return False

    def create_comments_sheet(self, writer, comments):
        """?ï¿½ï¿½? ?ï¿½íŠ¸ ?ï¿½ì„±"""
        try:
            comment_data = []

            for comment in comments:
                comment_data.append([
                    comment.get('post_title', ''),
                    comment.get('author', ''),
                    comment.get('date', ''),
                    comment.get('content', ''),
                    comment.get('reply_level', 0),
                    comment.get('post_url', ''),
                    comment.get('board_name', '')
                ])

            # pandasï¿½??ï¿½ìš©?????ï¿½ëŠ” ê²½ìš°?ï¿½ë§Œ ?ï¿½íŠ¸ ?ï¿½ì„±
            try:
                import pandas as pd
                df_comments = pd.DataFrame(comment_data, columns=[
                    'ê²Œì‹œê¸€?ï¿½ëª©', '?ï¿½ï¿½??ï¿½ì„±??, '?ï¿½ï¿½??ï¿½ì„±??, '?ï¿½ï¿½??ï¿½ìš©', '?ï¿½ï¿½?ê¹Šì´', 'ê²Œì‹œê¸€URL', 'ê²Œì‹œ?ï¿½ëª…'
                ])
                df_comments.to_excel(writer, sheet_name='?ï¿½ï¿½?ï¿½ï¿½?ëª©ë¡', index=False)
                print(f"    ???ï¿½ï¿½?ëª©ë¡ ?ï¿½íŠ¸ ?ï¿½ì„± ({len(comments)}ï¿½?")
            except ImportError:
                print("    ?ï¿½ï¸ pandasï¿½??ï¿½ìš©?????ï¿½ì–´ ?ï¿½ï¿½? ?ï¿½íŠ¸ï¿½??ï¿½ì„±?????ï¿½ìŒ")

        except Exception as e:
            print(f"    ???ï¿½ï¿½?ëª©ë¡ ?ï¿½íŠ¸ ?ï¿½ë¥˜: {e}")

    def collect_all_posts_from_results(self, results):
        """ê²°ê³¼?ï¿½ì„œ ëª¨ë“  ê²Œì‹œê¸€ ?ï¿½ì§‘"""
        all_posts = []

        try:
            # ê²€??ê²°ê³¼?ï¿½ì„œ ê²Œì‹œê¸€ ?ï¿½ì§‘
            search_results = results.get('search_results', {})
            if search_results.get('all_posts'):
                all_posts.extend(search_results['all_posts'])

            # ê²Œì‹œ?ï¿½ë³„ ê²°ê³¼?ï¿½ì„œ ê²Œì‹œê¸€ ?ï¿½ì§‘
            board_results = results.get('board_results', {})
            for board_name, board_data in board_results.items():
                if board_data.get('posts'):
                    all_posts.extend(board_data['posts'])

            # ì¤‘ë³µ ?ï¿½ê±°
            return self.deduplicate_posts(all_posts)

        except Exception as e:
            print(f"    ??ê²Œì‹œê¸€ ?ï¿½ì§‘ ?ï¿½ë¥˜: {e}")
            return all_posts


# ê¸°ì¡´ ì½”ë“œ?ï¿½???ï¿½í™˜?ï¿½ì„ ?ï¿½í•œ alias
CafeCrawler = CafeCrawlerMigrated

if __name__ == "__main__":
    # ?ï¿½ìš© ?ï¿½ì‹œ - ê¸°ì¡´ ì½”ë“œ?ï¿½ ?ï¿½ì¼?ï¿½ê²Œ ?ï¿½ìš© ê°€??    print("?? CafeCrawler Migration Version ?ï¿½ìŠ¤??)
    print(f"?ï¿½ë¡œ??ëª¨ë“ˆ ?ï¿½ìš© ê°€?? {NEW_MODULES_AVAILABLE}")

    # ì»¨í…?ï¿½íŠ¸ ë§¤ë‹ˆ?ï¿½ ?ï¿½ï¿½????ï¿½ìš© (ê¶Œì¥)
    try:
        with CafeCrawlerMigrated() as crawler:
            # ë¡œê·¸??            if crawler.login_naver():
                # ì¹´í˜ ?ï¿½ë™
                cafe_url = "https://cafe.naver.com/your-cafe"
                crawler.navigate_to_cafe(cafe_url)

                # ê²€??                results = crawler.search_posts("?ï¿½ìŠ¤??, max_pages=2)
                print(f"ê²€??ê²°ê³¼: {len(results)}ï¿½?)

                # ?ï¿½??                if results:
                    crawler.save_to_excel()

    except Exception as e:
        print(f"???ï¿½ìŠ¤???ï¿½í–‰ ï¿½??ï¿½ë¥˜: {e}")

    # ê¸°ì¡´ ?ï¿½ï¿½????ï¿½ìš©??ê°€??    crawler = CafeCrawlerMigrated()
    try:
        crawler.setup_driver()
        print("??ê¸°ì¡´ ?ï¿½ï¿½????ï¿½ë¼?ï¿½ë²„ ?ï¿½ì • ?ï¿½ë£Œ")
    except Exception as e:
        print(f"??ê¸°ì¡´ ?ï¿½ï¿½????ï¿½ë¥˜: {e}")
    finally:
        crawler.__exit__(None, None, None)
